#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸¬è©¦ Jina Embeddings V2 Base ZH çš„è·¨èªè¨€èƒ½åŠ›
é©—è­‰ä¸­æ–‡æŸ¥è©¢æ˜¯å¦èƒ½æ­£ç¢ºåŒ¹é…è‹±æ–‡æ¤ç‰©æè¿°
"""

import json
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np


def test_crosslingual_matching():
    """æ¸¬è©¦è·¨èªè¨€åŒ¹é…èƒ½åŠ›"""

    print("="*70)
    print("ğŸ§ª Jina Embeddings V2 Base ZH è·¨èªè¨€æ¸¬è©¦")
    print("="*70)

    # è¼‰å…¥æ¨¡å‹
    print("\nğŸ“¥ æ­£åœ¨è¼‰å…¥ Jina æ¨¡å‹...")
    model = SentenceTransformer('jinaai/jina-embeddings-v2-base-zh', trust_remote_code=True)
    print("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ")

    # æ¸¬è©¦æ¡ˆä¾‹ï¼šä½¿ç”¨çœŸå¯¦çš„æ¤ç‰©æè¿°
    print("\n" + "="*70)
    print("æ¸¬è©¦æ¡ˆä¾‹è¨­è¨ˆ")
    print("="*70)

    # å ´æ™¯ï¼šç”¨æˆ¶æ‹åˆ°æ¨Ÿæ¨¹çš„è‘‰å­
    chinese_queries = [
        {
            'name': 'æ¸¬è©¦ 1ï¼šæ¨Ÿæ¨¹ç‰¹å¾µï¼ˆè©³ç´°ï¼‰',
            'query': 'å¸¸ç¶ å–¬æœ¨ï¼Œè‘‰å­æ˜¯æ©¢åœ“å½¢çš„ï¼Œæ‘¸èµ·ä¾†åšåšçš„åƒçš®é©ï¼Œè¡¨é¢æœ‰å…‰æ¾¤ï¼Œæ’•é–‹è‘‰å­èèµ·ä¾†æœ‰å¾ˆæ¿ƒçš„æ¨Ÿè…¦å‘³ï¼Œå¯ä»¥é©…èŸ²ã€‚è‘‰å­é•·ç´„7åˆ°12å…¬åˆ†ï¼Œå¯¬ç´„3åˆ°5å…¬åˆ†ã€‚'
        },
        {
            'name': 'æ¸¬è©¦ 2ï¼šæ¨Ÿæ¨¹ç‰¹å¾µï¼ˆç°¡çŸ­ï¼‰',
            'query': 'æ©¢åœ“å½¢è‘‰å­ï¼Œé©è³ªï¼Œæœ‰å…‰æ¾¤ï¼Œæ¨Ÿè…¦å‘³'
        },
        {
            'name': 'æ¸¬è©¦ 3ï¼šä¸€èˆ¬æè¿°',
            'query': 'é€™æ£µæ¨¹çš„è‘‰å­æ˜¯æ©¢åœ“å½¢ï¼Œæ‘¸èµ·ä¾†å¾ˆåšå¯¦ï¼Œæ‰ç¢å¾Œæœ‰ç‰¹æ®Šé¦™å‘³'
        }
    ]

    # è‹±æ–‡è³‡æ–™åº«ï¼ˆä¾†è‡ªçœŸå¯¦çˆ¬å–çš„è³‡æ–™ï¼‰
    english_database = [
        {
            'id': 1,
            'name': 'é™çœŸé¦™ (Acronychia pedunculata)',
            'description': 'A shrub or small tree. Leaves 1-foliolate, 4â€“30 cm long; leaflet blade glabrous, elliptic or elliptic-oblong to obovate or oblanceolate, 3.5â€“24.5 cm long, 2â€“8.5 cm wide, the base cuneate, the apex obtusely acuminate. Inflorescences few- to many-flowered. Fruit usually rather sparsely pubescent, subglobose, 5â€“15 mm wide.'
        },
        {
            'id': 2,
            'name': 'è±¬è…³æ¥  (Machilus thunbergii)',
            'description': 'Large Evergreen trees. Leaves usually obovate, broadly elliptic, oblong, 7-13 cm long, 3-6 cm broad, thickly coriaceous, obtuse to abruptly cuspidate at apex, entire and slightly revolute, glabrous and lustrous above. Inflorescences cymose panicles. Fruit compressed-globose, 1 cm across, glabrous.'
        },
        {
            'id': 3,
            'name': 'æ¨Ÿæ¨¹ï¼ˆæ¨¡æ“¬æè¿°ï¼‰',
            'description': 'Evergreen large tree. Leaves alternate, elliptic to ovate, 5-12 cm long, 2.5-6 cm wide, coriaceous, glossy above, with characteristic camphor odor when crushed, used for insect repellent. Flowers small, yellowish-white, in panicles. Fruit black, globose.'
        },
        {
            'id': 4,
            'name': 'æ¦•æ¨¹ï¼ˆå°æ¯”ï¼‰',
            'description': 'Large evergreen tree with aerial roots. Leaves ovate to elliptic, 4-10 cm long, leathery, dark green, glabrous. Figs axillary, sessile, globose, yellowish-green when ripe. No special odor.'
        }
    ]

    print("\nğŸ“‹ ä¸­æ–‡æŸ¥è©¢ï¼š")
    for i, q in enumerate(chinese_queries, 1):
        print(f"  {i}. {q['name']}")
        print(f"     ã€Œ{q['query'][:50]}...ã€")

    print("\nğŸ“š è‹±æ–‡è³‡æ–™åº«ï¼ˆ4 å€‹æ¤ç‰©ï¼‰ï¼š")
    for item in english_database:
        print(f"  {item['id']}. {item['name']}")

    # åŸ·è¡Œæ¸¬è©¦
    print("\n" + "="*70)
    print("ğŸ”¬ é–‹å§‹æ¸¬è©¦")
    print("="*70)

    results = []

    for test_case in chinese_queries:
        print(f"\n{'='*70}")
        print(f"ğŸ§ª {test_case['name']}")
        print(f"{'='*70}")
        print(f"æŸ¥è©¢ï¼š{test_case['query']}")
        print()

        # ç”Ÿæˆä¸­æ–‡æŸ¥è©¢çš„å‘é‡
        zh_vector = model.encode(test_case['query'], normalize_embeddings=True)

        # ç”Ÿæˆæ‰€æœ‰è‹±æ–‡æè¿°çš„å‘é‡
        en_vectors = model.encode(
            [item['description'] for item in english_database],
            normalize_embeddings=True
        )

        # è¨ˆç®—ç›¸ä¼¼åº¦
        similarities = cosine_similarity([zh_vector], en_vectors)[0]

        # æ’åºçµæœ
        ranked = sorted(
            zip(english_database, similarities),
            key=lambda x: x[1],
            reverse=True
        )

        print("ğŸ“Š ç›¸ä¼¼åº¦æ’åï¼š")
        for rank, (item, score) in enumerate(ranked, 1):
            emoji = "ğŸ¥‡" if rank == 1 else "ğŸ¥ˆ" if rank == 2 else "ğŸ¥‰" if rank == 3 else "  "
            status = ""
            if score >= 0.80:
                status = "âœ… æ¥µä½³"
            elif score >= 0.75:
                status = "âœ… è‰¯å¥½"
            elif score >= 0.70:
                status = "âš ï¸  å°šå¯"
            elif score >= 0.65:
                status = "âš ï¸  åä½"
            else:
                status = "âŒ å¤ªä½"

            print(f"  {emoji} ç¬¬ {rank} åï¼š{score:.4f} {status}")
            print(f"     {item['name']}")
            print()

        # è¨˜éŒ„çµæœ
        results.append({
            'test_name': test_case['name'],
            'query': test_case['query'],
            'top1': ranked[0][0]['name'],
            'top1_score': float(ranked[0][1]),
            'top3': [(r[0]['name'], float(r[1])) for r in ranked[:3]]
        })

    # ç¶œåˆè©•ä¼°
    print("\n" + "="*70)
    print("ğŸ“ˆ ç¶œåˆè©•ä¼°")
    print("="*70)

    avg_top1_score = np.mean([r['top1_score'] for r in results])
    min_score = min([r['top1_score'] for r in results])
    max_score = max([r['top1_score'] for r in results])

    print(f"\nå¹³å‡æœ€é«˜ç›¸ä¼¼åº¦ï¼š{avg_top1_score:.4f}")
    print(f"æœ€ä½åˆ†æ•¸ï¼š{min_score:.4f}")
    print(f"æœ€é«˜åˆ†æ•¸ï¼š{max_score:.4f}")

    print("\n" + "="*70)
    print("ğŸ¯ çµè«–èˆ‡å»ºè­°")
    print("="*70)

    if avg_top1_score >= 0.78:
        print("\nâœ… çµè«–ï¼šè·¨èªè¨€èƒ½åŠ› **å„ªç§€**")
        print("   Jina V2 Base ZH å¯ä»¥æœ‰æ•ˆåŒ¹é…ä¸­è‹±æ–‡æ¤ç‰©æè¿°")
        print("\nğŸ’¡ å»ºè­°ï¼š")
        print("   â†’ ä½¿ç”¨æ–¹æ¡ˆ Aï¼šä¿ç•™è‹±æ–‡æè¿°ï¼Œä¾è³´ Jina è·¨èªè¨€èƒ½åŠ›")
        print("   â†’ å„ªé»ï¼šè³‡æ–™æº–å‚™å¿«ï¼Œä»Šå¤©å°±èƒ½ä¸Šç·š")
        print("   â†’ é æœŸæº–ç¢ºç‡ï¼š85-95%")
        recommendation = "A"
    elif avg_top1_score >= 0.72:
        print("\nâš ï¸  çµè«–ï¼šè·¨èªè¨€èƒ½åŠ› **å°šå¯**")
        print("   å¯ä»¥ä½¿ç”¨ï¼Œä½†æº–ç¢ºç‡å¯èƒ½ä¸å¤ ç†æƒ³")
        print("\nğŸ’¡ å»ºè­°ï¼š")
        print("   â†’ ä½¿ç”¨æ–¹æ¡ˆ Cï¼šæ·»åŠ ä¸­æ–‡é—œéµå­—å¢å¼·")
        print("   â†’ å„ªé»ï¼šæå‡ 10-15% æº–ç¢ºç‡")
        print("   â†’ ä»£åƒ¹ï¼šéœ€è¦é¡å¤–ç¿»è­¯æ­¥é©Ÿï¼ˆä¸€æ¬¡æ€§æˆæœ¬ï¼‰")
        recommendation = "C"
    else:
        print("\nâŒ çµè«–ï¼šè·¨èªè¨€èƒ½åŠ› **ä¸è¶³**")
        print("   ä¸å»ºè­°ç›´æ¥ä½¿ç”¨è‹±æ–‡æè¿°")
        print("\nğŸ’¡ å»ºè­°ï¼š")
        print("   â†’ å¿…é ˆä½¿ç”¨æ–¹æ¡ˆ Cï¼šå®Œæ•´ç¿»è­¯ç‚ºä¸­æ–‡")
        print("   â†’ æˆ–è€ƒæ…®ä½¿ç”¨å¤šèªè¨€æ¨¡å‹")
        recommendation = "C"

    # å„²å­˜çµæœ
    output = {
        'model': 'jinaai/jina-embeddings-v2-base-zh',
        'test_date': '2026-01-19',
        'results': results,
        'statistics': {
            'avg_top1_score': float(avg_top1_score),
            'min_score': float(min_score),
            'max_score': float(max_score)
        },
        'recommendation': recommendation
    }

    with open('jina_crosslingual_test_results.json', 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… æ¸¬è©¦çµæœå·²å„²å­˜è‡³ jina_crosslingual_test_results.json")
    print(f"âœ… æ¨è–¦æ–¹æ¡ˆï¼š{recommendation}")

    return recommendation


if __name__ == '__main__':
    try:
        recommendation = test_crosslingual_matching()
        print("\n" + "="*70)
        print("æ¸¬è©¦å®Œæˆï¼")
        print("="*70)
    except ImportError as e:
        print("\nâŒ éŒ¯èª¤ï¼šç¼ºå°‘å¿…è¦çš„å¥—ä»¶")
        print("\nè«‹å…ˆå®‰è£ï¼š")
        print("  pip install sentence-transformers scikit-learn")
        print(f"\nè©³ç´°éŒ¯èª¤ï¼š{e}")
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦å¤±æ•—ï¼š{e}")
        import traceback
        traceback.print_exc()
