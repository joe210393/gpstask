#!/usr/bin/env python3
"""
Trait Tokenizer - å°‡ key_features è½‰æ›ç‚ºæ¨™æº–åŒ–çš„ trait_tokens

åŠŸèƒ½ï¼š
1. å¾ key_featuresï¼ˆä¸­æ–‡ï¼‰æ˜ å°„åˆ°æ¨™æº–åŒ–çš„ trait_tokensï¼ˆk=v æ ¼å¼ï¼‰
2. å»ºç«‹åå‘æ˜ å°„è¡¨ï¼ˆzh -> (trait, canonical)ï¼‰
3. æä¾›è¦å‰‡åŒ¹é…å’Œå»ºè­°åŠŸèƒ½
"""

import json
import re
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Set

# è¼‰å…¥è©å½™è¡¨
VOCAB_PATH = Path(__file__).parent / "trait_vocab.json"
with VOCAB_PATH.open("r", encoding="utf-8") as f:
    TRAIT_VOCAB = json.load(f)

# å»ºç«‹åå‘æ˜ å°„è¡¨ï¼šzh token -> (trait, canonical)
REVERSE_MAP: Dict[str, Tuple[str, str]] = {}
for trait, values in TRAIT_VOCAB.items():
    for canon, data in values.items():
        for zh in data.get("zh", []):
            REVERSE_MAP[zh] = (trait, canon)


def normalize_token(t: str) -> str:
    """æ­£è¦åŒ– tokenï¼ˆå»é™¤æ¨™é»ã€ç©ºç™½ï¼‰"""
    if not t:
        return ""
    t = re.sub(r"[ï¼ˆï¼‰()ã€,ï¼Œ;ï¼›ã€‚\.]+", "", t)
    t = re.sub(r"\s+", "", t)
    return t.strip()


def heuristic_map(tok: str) -> Optional[Tuple[str, str, str]]:
    """
    å•Ÿç™¼å¼æ˜ å°„ï¼šdirect -> strip -> contains
    
    Returns:
        (trait, canonical, method) æˆ– None
    """
    tok = normalize_token(tok)
    if not tok:
        return None
    
    # 1. Direct match
    if tok in REVERSE_MAP:
        trait, canon = REVERSE_MAP[tok]
        return trait, canon, "direct"
    
    # 2. Strip common suffixes
    stripped = re.sub(r"(è‘‰åº|è‘‰ç·£|è‘‰é‚Š|è‘‰ç‰‡|è‘‰|èŠ±åº|æœå¯¦|èŠ±|æœ)$", "", tok)
    stripped = re.sub(r"^å°", "", stripped)  # å°å–¬æœ¨ -> å–¬æœ¨
    if stripped != tok and stripped in REVERSE_MAP:
        trait, canon = REVERSE_MAP[stripped]
        return trait, canon, f"strip:{stripped}"
    
    # 3. Contains matchï¼ˆç‰¹åˆ¥é‡å°ã€Œäº’ç”Ÿè‘‰åºã€ã€Œå°ç”Ÿè‘‰ã€é€™ç¨®ï¼‰
    leaf_arr_subs = {
        "alternate": ["äº’ç”Ÿ"],
        "opposite": ["å°ç”Ÿ"],
        "whorled": ["è¼ªç”Ÿ"],
        "basal": ["åŸºç”Ÿ", "è“®åº§", "å¢ç”Ÿ"]
    }
    for canon, subs in leaf_arr_subs.items():
        for s in subs:
            if s in tok:
                return "leaf_arrangement", canon, f"contains:{s}"
    
    return None


def suggest_rule(tok: str) -> Optional[Tuple[str, str, str]]:
    """
    è¦å‰‡å»ºè­°ï¼šæ ¹æ“šå¸¸è¦‹æ¨¡å¼æ¨æ–· trait é¡åˆ¥
    
    Returns:
        (trait, canonical, method) æˆ– None
    """
    tok = normalize_token(tok)
    if not tok:
        return None
    
    # leaf margin variants
    if "å…¨ç·£" in tok:
        return "leaf_margin", "entire", "rule:margin"
    if "é‹¸é½’" in tok:
        return "leaf_margin", "serrate", "rule:margin"
    if "æ³¢ç‹€" in tok:
        return "leaf_margin", "wavy", "rule:margin"
    if "è£‚" in tok and "è‘‰" in tok:
        return "leaf_margin", "lobed", "rule:margin"
    
    # texture
    if "é©è³ª" in tok:
        return "leaf_texture", "coriaceous", "rule:texture"
    if "ç´™è³ª" in tok:
        return "leaf_texture", "papery", "rule:texture"
    if "è‚‰è³ª" in tok:
        return "leaf_texture", "succulent", "rule:texture"
    
    # phenology
    if tok in ("è½è‘‰", "è½è‘‰æ€§"):
        return "phenology", "deciduous", "rule:phenology"
    if tok in ("å¸¸ç¶ ", "å¸¸ç¶ æ€§"):
        return "phenology", "evergreen", "rule:phenology"
    if tok == "åŠå¸¸ç¶ ":
        return "phenology", "semi_evergreen", "rule:phenology"
    
    # endemism
    if "ç‰¹æœ‰" in tok:
        return "endemism", "endemic", "rule:endemism"
    
    # reproductive system
    repro_map = {
        "é›Œé›„ç•°æ ª": "dioecious",
        "é›Œé›„åŒæ ª": "monoecious",
        "å…©æ€§èŠ±": "bisexual_flower",
        "å–®æ€§èŠ±": "unisexual_flower"
    }
    if tok in repro_map:
        return "reproductive_system", repro_map[tok], "rule:repro"
    
    # inflorescence
    if "èŠ±åº" in tok or tok in ("å–®ç”ŸèŠ±", "å–®ç”Ÿ"):
        if "ç¸½ç‹€" in tok:
            return "inflorescence", "raceme", "rule:infl"
        if "åœ“éŒ" in tok:
            return "inflorescence", "panicle", "rule:infl"
        if "èšç¹–" in tok or "èšå‚˜" in tok:
            return "inflorescence", "cyme", "rule:infl"
        if "ç¹–å½¢" in tok or "å‚˜å½¢" in tok:
            return "inflorescence", "umbel", "rule:infl"
        if "ç©—ç‹€" in tok:
            return "inflorescence", "spike", "rule:infl"
        if "é ­ç‹€" in tok:
            return "inflorescence", "capitulum", "rule:infl"
        if "ç¹–æˆ¿" in tok:
            return "inflorescence", "corymb", "rule:infl"
        if "ä½›ç„°" in tok:
            return "inflorescence", "spadix", "rule:infl"
        if "å–®ç”Ÿ" in tok:
            return "inflorescence", "solitary", "rule:infl"
    
    # fruit shape
    if "æœ" in tok:
        if "çƒå½¢" in tok:
            return "fruit_shape", "globose", "rule:fruit"
        if "åµå½¢" in tok and "æœ" in tok:
            return "fruit_shape", "ovoid", "rule:fruit"
        if "æ©¢åœ“" in tok and "æœ" in tok:
            return "fruit_shape", "ellipsoid", "rule:fruit"
    
    # leaf base
    if "åŸºéƒ¨" in tok:
        if "æ¥”å½¢" in tok:
            return "leaf_base", "cuneate", "rule:base"
        if "å¿ƒå½¢" in tok:
            return "leaf_base", "cordate", "rule:base"
        if "åœ“å½¢" in tok:
            return "leaf_base", "rounded", "rule:base"
    
    # flower color (ç°¡å–®åŒ¹é…ï¼Œå› ç‚º trait_vocab ä¸­å·²æœ‰å®Œæ•´æ˜ å°„)
    if "èŠ±" in tok and ("ç™½" in tok or tok.startswith("ç™½")):
        return "flower_color", "white", "rule:flower_color"
    if "èŠ±" in tok and ("é»ƒ" in tok or tok.startswith("é»ƒ")):
        return "flower_color", "yellow", "rule:flower_color"
    if "èŠ±" in tok and ("ç´…" in tok or tok.startswith("ç´…")):
        return "flower_color", "red", "rule:flower_color"
    if "èŠ±" in tok and ("ç´«" in tok or tok.startswith("ç´«")):
        return "flower_color", "purple", "rule:flower_color"
    if "èŠ±" in tok and ("ç²‰" in tok or tok.startswith("ç²‰")):
        return "flower_color", "pink", "rule:flower_color"
    if "èŠ±" in tok and ("æ©™" in tok or tok.startswith("æ©™")):
        return "flower_color", "orange", "rule:flower_color"
    
    # special features
    if "æ°£ç”Ÿæ ¹" in tok or "æ°£æ ¹" in tok:
        return "special_features", "aerial_root", "rule:special"
    if "æ¿æ ¹" in tok:
        return "special_features", "buttress", "rule:special"
    if "èƒç”Ÿ" in tok:
        return "special_features", "viviparous", "rule:special"
    if "ç´…è‹" in tok or "è‹è‘‰" in tok:
        return "special_features", "bract_red", "rule:special"
    
    return None


def key_features_to_trait_tokens(key_features: List[str]) -> List[str]:
    """
    å°‡ key_featuresï¼ˆä¸­æ–‡åˆ—è¡¨ï¼‰è½‰æ›ç‚ºæ¨™æº–åŒ–çš„ trait_tokens
    
    Args:
        key_features: ä¸­æ–‡ç‰¹å¾µåˆ—è¡¨ï¼Œå¦‚ ["çŒæœ¨", "äº’ç”Ÿ", "åµå½¢", "é‹¸é½’ç·£"]
    
    Returns:
        trait_tokens: æ¨™æº–åŒ– token åˆ—è¡¨ï¼Œå¦‚ ["life_form=shrub", "leaf_arrangement=alternate", ...]
    """
    trait_tokens = []
    seen = set()  # é¿å…é‡è¤‡
    
    for kf in key_features:
        if not kf or kf in ("æœªè¦‹æè¿°", "æœªè¦‹", "ä¸æ˜"):
            continue
        
        # å…ˆå˜—è©¦å•Ÿç™¼å¼æ˜ å°„
        result = heuristic_map(kf)
        if result is None:
            # å†å˜—è©¦è¦å‰‡å»ºè­°
            result = suggest_rule(kf)
        
        if result:
            trait, canon, method = result
            token = f"{trait}={canon}"
            if token not in seen:
                trait_tokens.append(token)
                seen.add(token)
        # else: unmappedï¼Œæš«æ™‚è·³éï¼ˆå¾ŒçºŒå¯ä»¥çµ±è¨ˆï¼‰
    
    return trait_tokens


def traits_json_to_trait_tokens(traits_json: Dict) -> List[str]:
    """
    å°‡ Vision AI ç”¢å‡ºçš„ traits JSON è½‰æ›ç‚º trait_tokens
    
    Args:
        traits_json: {
            "life_form": {"value": "shrub", "confidence": 0.9, ...},
            "leaf_arrangement": {"value": "alternate", ...},
            ...
        }
    
    Returns:
        trait_tokens: åªåŒ…å« confidence >= 0.55 çš„ç‰¹å¾µ
    """
    trait_tokens = []
    MIN_CONFIDENCE = 0.55

    # ğŸ”’ åš´æ ¼å¯è¦‹æ€§è¦å‰‡ï¼š
    # - è‹¥ visible_parts æœªåŒ…å« "flower"ï¼Œå‰‡ä¸€å¾‹å¿½ç•¥æ‰€æœ‰ flower_* é¡å‹ç‰¹å¾µ
    # - è‹¥ visible_parts æœªåŒ…å« "fruit"ï¼Œå‰‡ä¸€å¾‹å¿½ç•¥æ‰€æœ‰ fruit_* é¡å‹ç‰¹å¾µ
    visible_parts = traits_json.get("visible_parts") or []
    if isinstance(visible_parts, dict):
        visible_parts = visible_parts.get("value") or []
    if not isinstance(visible_parts, list):
        visible_parts = []
    visible_set: Set[str] = set(str(x).lower() for x in visible_parts)

    def _is_flower_trait(k: str) -> bool:
        return k.startswith("flower_") or k in {"inflorescence", "flower_inflo", "flower_position", "inflorescence_orientation"}

    def _is_fruit_trait(k: str) -> bool:
        return k.startswith("fruit_") or k in {"fruit_type", "fruit_color", "fruit_cluster", "fruit_surface"}

    for trait_key, trait_data in traits_json.items():
        if not isinstance(trait_data, dict):
            continue

        # åš´æ ¼å¯è¦‹æ€§ï¼šçœ‹ä¸åˆ°èŠ±/æœå°±ç›´æ¥è·³éç›¸é—œç‰¹å¾µï¼ˆå³ä½¿ LM çµ¦äº†é«˜ä¿¡å¿ƒå€¼ï¼‰
        if _is_flower_trait(trait_key) and "flower" not in visible_set:
            continue
        if _is_fruit_trait(trait_key) and "fruit" not in visible_set:
            continue

        value = trait_data.get("value")
        confidence = trait_data.get("confidence", 0.0)

        if value in ("unknown", None, "") or confidence < MIN_CONFIDENCE:
            continue

        # ç›´æ¥ä½¿ç”¨ canonical valueï¼ˆå·²ç¶“æ˜¯è‹±æ–‡æ¨™æº–å€¼ï¼‰
        token = f"{trait_key}={value}"
        trait_tokens.append(token)

    return trait_tokens


def get_trait_tokens_zh(trait_tokens: List[str]) -> List[str]:
    """
    å°‡ trait_tokens è½‰æ›ç‚ºä¸­æ–‡ç‰ˆæœ¬ï¼ˆç”¨æ–¼å¯è®€æ€§/debugï¼‰
    
    Args:
        trait_tokens: ["life_form=shrub", "leaf_arrangement=alternate", ...]
    
    Returns:
        trait_tokens_zh: ["ç”Ÿæ´»å‹=çŒæœ¨", "è‘‰åº=äº’ç”Ÿ", ...]
    """
    tokens_zh = []
    
    for token in trait_tokens:
        if "=" not in token:
            continue
        
        trait, canon = token.split("=", 1)
        
        # å¾è©å½™è¡¨å–å¾—ä¸­æ–‡
        if trait in TRAIT_VOCAB and canon in TRAIT_VOCAB[trait]:
            zh_list = TRAIT_VOCAB[trait][canon].get("zh", [])
            if zh_list:
                tokens_zh.append(f"{trait}={zh_list[0]}")
    
    return tokens_zh


# æ¸¬è©¦
if __name__ == "__main__":
    # æ¸¬è©¦ key_features è½‰æ›
    test_key_features = ["çŒæœ¨", "äº’ç”Ÿ", "åµå½¢", "é‹¸é½’ç·£", "ç¸½ç‹€èŠ±åº", "ç™½èŠ±"]
    tokens = key_features_to_trait_tokens(test_key_features)
    print("Key features:", test_key_features)
    print("Trait tokens:", tokens)
    print("Trait tokens (ZH):", get_trait_tokens_zh(tokens))
    
    # æ¸¬è©¦ traits JSON è½‰æ›
    test_traits = {
        "life_form": {"value": "shrub", "confidence": 0.9},
        "leaf_arrangement": {"value": "alternate", "confidence": 0.8},
        "flower_color": {"value": "unknown", "confidence": 0.3}
    }
    tokens2 = traits_json_to_trait_tokens(test_traits)
    print("\nTraits JSON:", test_traits)
    print("Trait tokens:", tokens2)
