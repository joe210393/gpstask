#!/usr/bin/env python3
"""
æª¢æŸ¥è³‡æ–™å“è³ªè…³æœ¬
é©—è­‰ plants-forest-gov-tw-enhanced.jsonl çš„è³‡æ–™å®Œæ•´æ€§
"""

import json
from pathlib import Path
from collections import defaultdict

DATA_FILE = Path(__file__).parent.parent / "data" / "plants-forest-gov-tw-enhanced.jsonl"

def check_data_quality():
    """æª¢æŸ¥è³‡æ–™å“è³ª"""
    print("=" * 60)
    print("ğŸ“Š è³‡æ–™å“è³ªæª¢æŸ¥")
    print("=" * 60)
    
    if not DATA_FILE.exists():
        print(f"âŒ æ‰¾ä¸åˆ°è³‡æ–™æª”æ¡ˆ: {DATA_FILE}")
        return False
    
    stats = {
        "total": 0,
        "has_trait_tokens": 0,
        "has_key_features_norm": 0,
        "has_query_text_zh": 0,
        "has_must_traits": 0,
        "format_errors": [],
        "missing_data": []
    }
    
    source_stats = defaultdict(int)
    
    with open(DATA_FILE, 'r', encoding='utf-8') as f:
        for i, line in enumerate(f, 1):
            line = line.strip()
            if not line:
                continue
            
            try:
                plant = json.loads(line)
                stats["total"] += 1
                
                name = plant.get('chinese_name', 'æœªçŸ¥')
                source = plant.get('source', 'æœªçŸ¥')
                source_stats[source] += 1
                
                ident = plant.get('identification', {})
                
                # æª¢æŸ¥å¿…è¦æ¬„ä½
                has_tokens = bool(ident.get('trait_tokens'))
                has_norm = bool(ident.get('key_features_norm'))
                has_query = bool(ident.get('query_text_zh'))
                has_must = bool(ident.get('must_traits'))
                
                if has_tokens:
                    stats["has_trait_tokens"] += 1
                if has_norm:
                    stats["has_key_features_norm"] += 1
                if has_query:
                    stats["has_query_text_zh"] += 1
                if has_must:
                    stats["has_must_traits"] += 1
                
                # è¨˜éŒ„ç¼ºå°‘çš„è³‡æ–™
                missing = []
                if not has_tokens:
                    missing.append('trait_tokens')
                if not has_norm:
                    missing.append('key_features_norm')
                if not has_query:
                    missing.append('query_text_zh')
                
                if missing:
                    stats["missing_data"].append({
                        "line": i,
                        "name": name,
                        "source": source,
                        "missing": missing
                    })
                
                # æª¢æŸ¥æ ¼å¼
                trait_tokens = ident.get('trait_tokens', [])
                for token in trait_tokens:
                    if not isinstance(token, str) or '=' not in token:
                        stats["format_errors"].append({
                            "line": i,
                            "name": name,
                            "error": f"trait_token æ ¼å¼éŒ¯èª¤: {token}"
                        })
                        break
                
            except json.JSONDecodeError as e:
                stats["format_errors"].append({
                    "line": i,
                    "name": "æœªçŸ¥",
                    "error": f"JSON è§£æéŒ¯èª¤: {str(e)[:50]}"
                })
    
    # è¼¸å‡ºçµ±è¨ˆ
    print(f"\nğŸ“ˆ çµ±è¨ˆè³‡æ–™")
    print(f"  ç¸½ç­†æ•¸: {stats['total']}")
    print(f"  æœ‰ trait_tokens: {stats['has_trait_tokens']} ({stats['has_trait_tokens']/stats['total']*100:.1f}%)")
    print(f"  æœ‰ key_features_norm: {stats['has_key_features_norm']} ({stats['has_key_features_norm']/stats['total']*100:.1f}%)")
    print(f"  æœ‰ query_text_zh: {stats['has_query_text_zh']} ({stats['has_query_text_zh']/stats['total']*100:.1f}%)")
    print(f"  æœ‰ must_traits: {stats['has_must_traits']} ({stats['has_must_traits']/stats['total']*100:.1f}%)")
    
    print(f"\nğŸ“‚ è³‡æ–™ä¾†æºåˆ†å¸ƒ")
    for source, count in sorted(source_stats.items(), key=lambda x: -x[1]):
        print(f"  {source}: {count} ç­†")
    
    if stats["missing_data"]:
        print(f"\nâš ï¸  ç¼ºå°‘è³‡æ–™çš„æ¤ç‰© ({len(stats['missing_data'])} ç­†)")
        # æŒ‰ä¾†æºåˆ†é¡
        missing_by_source = defaultdict(list)
        for item in stats["missing_data"]:
            missing_by_source[item["source"]].append(item)
        
        for source, items in sorted(missing_by_source.items(), key=lambda x: -len(x[1])):
            print(f"  {source}: {len(items)} ç­†")
            for item in items[:5]:  # åªé¡¯ç¤ºå‰ 5 å€‹
                print(f"    - {item['name']} (ç¼ºå°‘: {', '.join(item['missing'])})")
            if len(items) > 5:
                print(f"    ... é‚„æœ‰ {len(items) - 5} ç­†")
    
    if stats["format_errors"]:
        print(f"\nâŒ æ ¼å¼éŒ¯èª¤ ({len(stats['format_errors'])} ç­†)")
        for error in stats["format_errors"][:10]:
            print(f"  ç¬¬ {error['line']} ç­† ({error['name']}): {error['error']}")
    else:
        print(f"\nâœ… æ ¼å¼æª¢æŸ¥é€šéï¼Œæ²’æœ‰ç™¼ç¾æ ¼å¼éŒ¯èª¤")
    
    # ç¸½çµ
    print(f"\n{'=' * 60}")
    if stats["format_errors"]:
        print("âŒ è³‡æ–™æœ‰æ ¼å¼éŒ¯èª¤ï¼Œéœ€è¦ä¿®å¾©")
        return False
    elif len(stats["missing_data"]) > stats["total"] * 0.1:  # è¶…é 10% ç¼ºå°‘è³‡æ–™
        print("âš ï¸  è¶…é 10% çš„è³‡æ–™ç¼ºå°‘å¿…è¦æ¬„ä½ï¼Œå»ºè­°è£œé½Š")
        return False
    else:
        print("âœ… è³‡æ–™å“è³ªè‰¯å¥½ï¼Œå¯ä»¥ä½¿ç”¨")
        return True

if __name__ == "__main__":
    import sys
    success = check_data_quality()
    sys.exit(0 if success else 1)
