#!/usr/bin/env python3
"""
æ¤ç‰©è³‡æ–™å‘é‡åŒ–è…³æœ¬
ä½¿ç”¨ JINA Embeddings v3 + Qdrant

ä½¿ç”¨æ–¹å¼ï¼š
1. å®‰è£ä¾è³´ï¼špip install -r requirements.txt
2. å•Ÿå‹• Qdrantï¼šdocker run -p 6333:6333 qdrant/qdrant
3. åŸ·è¡Œï¼špython embed_plants.py
"""

import json
import os
import sys
from pathlib import Path
from typing import List, Dict, Any
from tqdm import tqdm

from sentence_transformers import SentenceTransformer
from qdrant_client import QdrantClient
from qdrant_client.models import (
    Distance,
    VectorParams,
    PointStruct,
    OptimizersConfigDiff,
)

# è¨­å®š
QDRANT_URL = os.environ.get("QDRANT_URL", "http://localhost:6333")
QDRANT_API_KEY = os.environ.get("QDRANT_API_KEY", None)  # Zeabur Qdrant API Key
COLLECTION_NAME = "taiwan_plants"

def get_qdrant_client():
    """å»ºç«‹ Qdrant å®¢æˆ¶ç«¯ï¼Œè‡ªå‹•è™•ç† HTTP/HTTPS"""
    from urllib.parse import urlparse
    parsed = urlparse(QDRANT_URL)

    is_https = parsed.scheme == 'https'
    host = parsed.hostname or 'localhost'
    port = parsed.port or (443 if is_https else 6333)

    if QDRANT_API_KEY:
        return QdrantClient(
            host=host,
            port=port,
            api_key=QDRANT_API_KEY,
            https=is_https,
            prefer_grpc=False,
            timeout=120
        )
    else:
        return QdrantClient(
            host=host,
            port=port,
            https=is_https,
            prefer_grpc=False,
            timeout=120
        )
EMBEDDING_MODEL = "jinaai/jina-embeddings-v3"
BATCH_SIZE = 32  # æ¯æ‰¹è™•ç†çš„è³‡æ–™æ•¸é‡
EMBEDDING_DIM = 1024  # jina-embeddings-v3 ç¶­åº¦

# è³‡æ–™è·¯å¾‘
SCRIPT_DIR = Path(__file__).parent
DATA_FILE = SCRIPT_DIR.parent / "data" / "plants-enriched.jsonl"
PROGRESS_FILE = SCRIPT_DIR / "embed_progress.json"


def load_progress() -> set:
    """è¼‰å…¥å·²è™•ç†çš„æ¤ç‰©ä»£ç¢¼"""
    if PROGRESS_FILE.exists():
        with open(PROGRESS_FILE, "r") as f:
            data = json.load(f)
            return set(data.get("processed", []))
    return set()


def save_progress(processed: set):
    """å„²å­˜é€²åº¦"""
    with open(PROGRESS_FILE, "w") as f:
        json.dump({"processed": list(processed)}, f)


def create_plant_text(plant: Dict[str, Any]) -> str:
    """
    å°‡æ¤ç‰©è³‡æ–™è½‰æ›ç‚ºç”¨æ–¼ embedding çš„æ–‡å­—
    åŒ…å«ï¼šåç¨±ã€åˆ†é¡ã€ç‰¹å¾µã€åˆ†å¸ƒç­‰è³‡è¨Š
    """
    parts = []

    # åç¨±
    names = plant.get("names", {})
    if names.get("chinese"):
        parts.append(f"ä¸­æ–‡åï¼š{names['chinese']}")
    if names.get("scientific"):
        parts.append(f"å­¸åï¼š{names['scientific']}")

    # ä¿—å
    common_names = names.get("common_names", {})
    if common_names.get("chinese"):
        parts.append(f"åˆ¥åï¼š{'ã€'.join(common_names['chinese'])}")

    # åˆ†é¡
    classification = plant.get("classification", {})
    if classification.get("chfamily"):
        parts.append(f"ç§‘ï¼š{classification['chfamily']} ({classification.get('family', '')})")
    if classification.get("chgenus"):
        parts.append(f"å±¬ï¼š{classification['chgenus']} ({classification.get('genus', '')})")

    # ç‰¹å¾µæè¿°
    features = plant.get("features", {})
    if features.get("life_form"):
        parts.append(f"ç”Ÿæ´»å‹ï¼š{features['life_form']}")

    if features.get("morphology"):
        morphology_text = " ".join(features["morphology"][:5])  # å–å‰5æ¢
        parts.append(f"å½¢æ…‹ç‰¹å¾µï¼š{morphology_text}")

    # AI æå–çš„è­˜åˆ¥ç‰¹å¾µ
    identification = plant.get("identification", {})
    if identification:
        # è‘‰ç‰¹å¾µ
        leaf = identification.get("morphology", {}).get("leaf", {})
        leaf_parts = []
        if leaf.get("shape"):
            leaf_parts.append(leaf["shape"])
        if leaf.get("arrangement"):
            leaf_parts.append(leaf["arrangement"])
        if leaf.get("margin"):
            leaf_parts.append(leaf["margin"])
        if leaf_parts:
            parts.append(f"è‘‰ï¼š{'ï¼Œ'.join(leaf_parts)}")

        # èŠ±ç‰¹å¾µ
        flower = identification.get("morphology", {}).get("flower", {})
        flower_parts = []
        if flower.get("color"):
            flower_parts.append(flower["color"])
        if flower.get("shape"):
            flower_parts.append(flower["shape"])
        if flower.get("season"):
            flower_parts.append(f"èŠ±æœŸ{flower['season']}")
        if flower_parts:
            parts.append(f"èŠ±ï¼š{'ï¼Œ'.join(flower_parts)}")

        # æœç‰¹å¾µ
        fruit = identification.get("morphology", {}).get("fruit", {})
        fruit_parts = []
        if fruit.get("type"):
            fruit_parts.append(fruit["type"])
        if fruit.get("color"):
            fruit_parts.append(fruit["color"])
        if fruit_parts:
            parts.append(f"æœï¼š{'ï¼Œ'.join(fruit_parts)}")

        # ç”Ÿæ…‹
        ecology = identification.get("ecology", {})
        if ecology.get("habitat"):
            parts.append(f"ç”Ÿé•·ç’°å¢ƒï¼š{ecology['habitat']}")
        if ecology.get("elevation"):
            parts.append(f"æµ·æ‹”ï¼š{ecology['elevation']}")

        # é—œéµè­˜åˆ¥ç‰¹å¾µ
        key_features = identification.get("identification", {}).get("key_features", [])
        if key_features:
            parts.append(f"è­˜åˆ¥è¦é»ï¼š{'ã€'.join(key_features[:3])}")

    # åˆ†å¸ƒ
    distribution = plant.get("distribution", {})
    locations = distribution.get("locations", [])
    if locations:
        districts = list(set([loc.get("district", "").split()[0] for loc in locations[:10] if loc.get("district")]))
        if districts:
            parts.append(f"åˆ†å¸ƒï¼š{', '.join(districts[:5])}")

    return "\n".join(parts)


def load_plants() -> List[Dict[str, Any]]:
    """è¼‰å…¥æ¤ç‰©è³‡æ–™"""
    plants = []
    with open(DATA_FILE, "r", encoding="utf-8") as f:
        for line in f:
            if line.strip():
                plants.append(json.loads(line))
    return plants


def init_qdrant(client: QdrantClient):
    """åˆå§‹åŒ– Qdrant collection"""
    collections = client.get_collections().collections
    collection_names = [c.name for c in collections]

    if COLLECTION_NAME not in collection_names:
        print(f"å»ºç«‹ collection: {COLLECTION_NAME}")
        client.create_collection(
            collection_name=COLLECTION_NAME,
            vectors_config=VectorParams(
                size=EMBEDDING_DIM,
                distance=Distance.COSINE,
            ),
            optimizers_config=OptimizersConfigDiff(
                indexing_threshold=0,  # ç«‹å³å»ºç«‹ç´¢å¼•
            ),
        )
    else:
        print(f"Collection {COLLECTION_NAME} å·²å­˜åœ¨")


def main():
    print("=" * 60)
    print("ğŸŒ¿ æ¤ç‰©è³‡æ–™å‘é‡åŒ–")
    print("=" * 60)

    # é€£æ¥ Qdrant
    print(f"\né€£æ¥ Qdrant: {QDRANT_URL}")
    if QDRANT_API_KEY:
        print("  ä½¿ç”¨ API Key èªè­‰")
    try:
        client = get_qdrant_client()
        client.get_collections()  # æ¸¬è©¦é€£æ¥
        print("âœ… Qdrant é€£æ¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ ç„¡æ³•é€£æ¥ Qdrant: {e}")
        print("\nè«‹ç¢ºèª Qdrant å·²å•Ÿå‹•ï¼š")
        print("  docker run -p 6333:6333 qdrant/qdrant")
        sys.exit(1)

    # åˆå§‹åŒ– collection
    init_qdrant(client)

    # è¼‰å…¥ embedding æ¨¡å‹
    print(f"\nè¼‰å…¥ embedding æ¨¡å‹: {EMBEDDING_MODEL}")
    print("ï¼ˆé¦–æ¬¡åŸ·è¡Œæœƒä¸‹è¼‰æ¨¡å‹ï¼Œç´„ 2GBï¼‰")
    model = SentenceTransformer(EMBEDDING_MODEL, trust_remote_code=True)
    print("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ")

    # è¼‰å…¥æ¤ç‰©è³‡æ–™
    print(f"\nè¼‰å…¥æ¤ç‰©è³‡æ–™: {DATA_FILE}")
    plants = load_plants()
    print(f"ç¸½å…± {len(plants)} ç­†è³‡æ–™")

    # è¼‰å…¥é€²åº¦
    processed = load_progress()
    print(f"å·²è™•ç†: {len(processed)} ç­†")

    # ç¯©é¸æœªè™•ç†çš„
    plants_to_process = [p for p in plants if p["code"] not in processed]
    print(f"å¾…è™•ç†: {len(plants_to_process)} ç­†")

    if not plants_to_process:
        print("\nâœ… æ‰€æœ‰è³‡æ–™å·²è™•ç†å®Œæˆï¼")
        return

    # æ‰¹æ¬¡è™•ç†
    print(f"\né–‹å§‹å‘é‡åŒ–ï¼ˆæ‰¹æ¬¡å¤§å°: {BATCH_SIZE}ï¼‰")

    for i in tqdm(range(0, len(plants_to_process), BATCH_SIZE), desc="è™•ç†ä¸­"):
        batch = plants_to_process[i:i + BATCH_SIZE]

        # ç”¢ç”Ÿæ–‡å­—
        texts = [create_plant_text(p) for p in batch]

        # ç”¢ç”Ÿ embeddings
        embeddings = model.encode(texts, show_progress_bar=False)

        # å»ºç«‹ points
        points = []
        for j, (plant, embedding) in enumerate(zip(batch, embeddings)):
            point = PointStruct(
                id=hash(plant["code"]) & 0x7FFFFFFFFFFFFFFF,  # æ­£æ•´æ•¸ ID
                vector=embedding.tolist(),
                payload={
                    "code": plant["code"],
                    "chinese_name": plant.get("names", {}).get("chinese", ""),
                    "scientific_name": plant.get("names", {}).get("scientific", ""),
                    "family": plant.get("classification", {}).get("chfamily", ""),
                    "family_en": plant.get("classification", {}).get("family", ""),
                    "genus": plant.get("classification", {}).get("chgenus", ""),
                    "life_form": plant.get("features", {}).get("life_form", ""),
                    "has_features": plant.get("features", {}).get("has_data", False),
                    "location_count": len(plant.get("distribution", {}).get("locations", [])),
                    # ç”¨æ–¼é¡¯ç¤ºçš„æ‘˜è¦æ–‡å­—
                    "summary": texts[j][:500],  # æˆªå–å‰500å­—
                }
            )
            points.append(point)

        # å¯«å…¥ Qdrant
        client.upsert(collection_name=COLLECTION_NAME, points=points)

        # æ›´æ–°é€²åº¦
        for plant in batch:
            processed.add(plant["code"])

        # æ¯ 10 æ‰¹å„²å­˜ä¸€æ¬¡é€²åº¦
        if (i // BATCH_SIZE) % 10 == 0:
            save_progress(processed)

    # æœ€çµ‚å„²å­˜é€²åº¦
    save_progress(processed)

    # çµ±è¨ˆ
    collection_info = client.get_collection(COLLECTION_NAME)
    print(f"\n{'=' * 60}")
    print("âœ… å‘é‡åŒ–å®Œæˆï¼")
    print(f"   Collection: {COLLECTION_NAME}")
    print(f"   å‘é‡æ•¸é‡: {collection_info.points_count}")
    print(f"   å‘é‡ç¶­åº¦: {EMBEDDING_DIM}")
    print(f"\nQdrant Dashboard: {QDRANT_URL.replace(':6333', ':6333')}/dashboard")


if __name__ == "__main__":
    main()
