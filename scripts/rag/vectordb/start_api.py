#!/usr/bin/env python3
"""
æ¤ç‰©å‘é‡æœå°‹ API æœå‹™
æä¾› REST API çµ¦ Node.js server å‘¼å«

åŠŸèƒ½ï¼š
1. è‡ªå‹•åˆ¤æ–·æŸ¥è©¢é¡å‹ï¼ˆæ¤ç‰©/å‹•ç‰©/äººé€ ç‰©/å…¶ä»–ï¼‰
2. åªæœ‰æ¤ç‰©ç›¸é—œæŸ¥è©¢æ‰é€²è¡Œ RAG æœå°‹

å•Ÿå‹•æ–¹å¼ï¼š
  python start_api.py
  (Trigger redeploy: 2026-02-02)

API ç«¯é»ï¼š
  POST /search
  Body: { "query": "ç´…è‰²çš„èŠ±", "top_k": 5 }

  POST /classify
  Body: { "query": "é€™æ˜¯ä»€éº¼" }

  GET /health
"""

import os
import sys
import json
import threading
import numpy as np
import time
from http.server import HTTPServer, BaseHTTPRequestHandler
from socketserver import ThreadingMixIn
from urllib.parse import urlparse, parse_qs
from qdrant_client.models import Filter, FieldCondition, MatchValue, MatchAny, MatchText

# å»¶é²è¼‰å…¥é‡é‡ç´šæ¨¡çµ„
SentenceTransformer = None
QdrantClient = None
FeatureWeightCalculator = None
get_vision_prompt = None
FEATURE_INDEX = {}

QDRANT_URL = os.environ.get("QDRANT_URL", "http://localhost:6333")
QDRANT_API_KEY = os.environ.get("QDRANT_API_KEY", None)  # Zeabur Qdrant API Key
COLLECTION_NAME = "taiwan_plants"
# å…è¨±ç”¨ç’°å¢ƒè®Šæ•¸è¦†è“‹æ¨¡å‹ï¼Œé¿å…åœ¨ Zeabur ä¸Šå› ç‚ºè¨˜æ†¶é«”ä¸è¶³é€ æˆåè¦†é‡å•Ÿ
EMBEDDING_MODEL = os.environ.get("EMBEDDING_MODEL", "jinaai/jina-embeddings-v3")
_default_dim = 1024 if "jina-embeddings-v3" in EMBEDDING_MODEL else 768
EMBEDDING_DIM = int(os.environ.get("EMBEDDING_DIM", str(_default_dim)))
JINA_API_KEY = os.environ.get("JINA_API_KEY", None)  # Jina AI API Key
# å¯é¸ï¼šæŒ‡å®šç‰¹å¾µæ¬Šé‡è¨ˆç®—ç”¨çš„è³‡æ–™æª”è·¯å¾‘ï¼ˆåªå½±éŸ¿ df/idf çµ±è¨ˆï¼Œä¸å½±éŸ¿ Qdrant å‘é‡ï¼‰
FEATURE_DATA_PATH = os.environ.get("FEATURE_DATA_PATH", "").strip()
# USE_JINA_API:
# - "true": å¼·åˆ¶ä½¿ç”¨ Jina API
# - "false": å¼·åˆ¶æœ¬åœ°æ¨¡å‹
# - "auto": è‹¥æœ‰ JINA_API_KEY å‰‡ä½¿ç”¨ Jina APIï¼ˆé¿å…å¿˜äº†è¨­å®šï¼‰
_use_jina_env = os.environ.get("USE_JINA_API", "auto").lower()
FORCE_JINA_API = (_use_jina_env == "true")
AUTO_JINA_API = (_use_jina_env == "auto")
USE_JINA_API = FORCE_JINA_API or (AUTO_JINA_API and bool(JINA_API_KEY))
# Zeabur ç”¨ PORTï¼Œæœ¬åœ°é–‹ç™¼ç”¨ EMBEDDING_API_PORT
API_PORT = int(os.environ.get("PORT", os.environ.get("EMBEDDING_API_PORT", "8100")))

def get_qdrant_client():
    """å»ºç«‹ Qdrant å®¢æˆ¶ç«¯ï¼Œè‡ªå‹•è™•ç† HTTP/HTTPS"""
    import warnings
    from urllib.parse import urlparse
    parsed = urlparse(QDRANT_URL)

    is_https = parsed.scheme == 'https'
    host = parsed.hostname or 'localhost'
    port = parsed.port or (443 if is_https else 6333)

    # å¦‚æœæ˜¯å…§éƒ¨ç¶²è·¯ HTTP é€£ç·šï¼Œä¸ä½¿ç”¨ API Key
    use_api_key = QDRANT_API_KEY if is_https else None

    if use_api_key:
        return QdrantClient(
            host=host,
            port=port,
            api_key=use_api_key,
            https=is_https,
            prefer_grpc=False,
            timeout=30
        )
    else:
        # å…§éƒ¨é€£ç·šä¸éœ€è¦ API Keyï¼Œå¿½ç•¥è­¦å‘Š
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            return QdrantClient(
                host=host,
                port=port,
                https=is_https,
                prefer_grpc=False,
            timeout=30
            )

# åˆ†é¡é–¾å€¼
PLANT_THRESHOLD = 0.40  # èˆ‡ã€Œæ¤ç‰©ã€ç›¸ä¼¼åº¦è¶…éæ­¤å€¼æ‰èªç‚ºæ˜¯æ¤ç‰©æŸ¥è©¢ï¼ˆé™ä½ä»¥æ¸›å°‘èª¤åˆ¤ï¼‰

# å…¨åŸŸè®Šæ•¸ï¼ˆå•Ÿå‹•æ™‚è¼‰å…¥ï¼‰
model = None
qdrant_client = None
category_embeddings = None  # é è¨ˆç®—çš„é¡åˆ¥å‘é‡
feature_calculator = None  # ç‰¹å¾µæ¬Šé‡è¨ˆç®—å™¨

# æ··åˆè©•åˆ†æ¬Šé‡ï¼ˆåˆå§‹é è¨­ï¼šembedding ç¨é«˜ï¼Œç‰¹å¾µç‚ºè¼”ï¼‰
EMBEDDING_WEIGHT = 0.78  # embedding ç‚ºä¸»ï¼Œé¿å…ç‰¹å¾µä¸»å°æ’åº
FEATURE_WEIGHT = 0.22    # ç‰¹å¾µåªåš gate + æœ‰é™åŠ åˆ†
KEYWORD_BONUS_WEIGHT = 0.18  # é—œéµå­—åŒ¹é…åŠ åˆ†ï¼ˆVision çŒœçš„ç‰©ç¨®åæ˜¯å¼·è¨Šè™Ÿï¼Œæé«˜ä»¥å°æŠ— feature è³‡æ–™ä¸å…¨ï¼‰

# å¸¸éŒ¯ç•¶ Top1 çš„ã€Œè¬ç”¨æ¢ç›®ã€ï¼šè¼•åº¦é™æ¬Šï¼Œé™ä½éœ¸æ¦œæ©Ÿç‡
# æ³¨æ„ï¼šé€™æ˜¯çŸ­æœŸæ­¢è¡€ï¼Œä¸æ˜¯é•·æœŸè§£æ³•ï¼ˆé•·æœŸæ‡‰æ”¹å–„è³‡æ–™/ç‰¹å¾µ/æ¬Šé‡ï¼‰
GENERIC_TOP1_BLACKLIST = frozenset({"å†‡æ‹±", "å—äºå­”é›€è‹”", "é­ææ‡¸è‹”", "æ ªè‹”", "å…«è§’è“®", "è‰æµ·æ¡", "ç™½æª€"})
GENERIC_TOP1_PENALTY = float(os.environ.get("GENERIC_TOP1_PENALTY", "0.80"))


def apply_generic_top1_penalty(rows: list[dict], penalty: float = GENERIC_TOP1_PENALTY) -> list[dict]:
    """å°è¬ç”¨æ¢ç›®åšè¼•åº¦é™æ¬Šï¼ˆå°±åœ°ä¿®æ”¹ + å›å‚³ï¼Œæ–¹ä¾¿ chainï¼‰ã€‚"""
    if not rows:
        return rows
    try:
        p = float(penalty)
    except Exception:
        p = 0.88
    # å¤¾ä½ï¼Œé¿å…ç’°å¢ƒè®Šæ•¸è¨­éŒ¯é€ æˆæ¥µç«¯çµæœ
    if p <= 0:
        p = 0.01
    if p > 1:
        p = 1.0

    for item in rows:
        try:
            name = (item.get("chinese_name") or "").strip()
            if name in GENERIC_TOP1_BLACKLIST:
                item["score"] = float(item.get("score") or 0.0) * p
        except Exception:
            continue
    return rows


def encode_text(text):
    """
    ç·¨ç¢¼æ–‡å­—ç‚ºå‘é‡ï¼Œæ ¹æ“šè¨­å®šé¸æ“‡ä½¿ç”¨æœ¬åœ°æ¨¡å‹æˆ– Jina API

    Args:
        text: å–®ä¸€æ–‡å­—å­—ä¸²æˆ–æ–‡å­—åˆ—è¡¨

    Returns:
        numpy array æˆ– list of numpy arrays
    """
    # å¼·åˆ¶ Jina æ¨¡å¼ï¼šå³ä½¿ key æ²’æœ‰è¨­ï¼Œä¹Ÿä¸æ‡‰å˜—è©¦å›é€€åˆ°æœ¬åœ°æ¨¡å‹ï¼ˆé¿å… Zeabur OOM/ä¸‹è¼‰æ¨¡å‹ï¼‰
    if FORCE_JINA_API and not JINA_API_KEY:
        raise RuntimeError("USE_JINA_API=true ä½†æœªè¨­å®š JINA_API_KEYï¼ˆå·²ç¦æ­¢å›é€€åˆ°æœ¬åœ°æ¨¡å‹ï¼‰")

    if USE_JINA_API and JINA_API_KEY:
        # ä½¿ç”¨ Jina API
        import requests

        is_batch = isinstance(text, list)
        texts = text if is_batch else [text]
        
        # è¨˜éŒ„æ¯æ¬¡ API èª¿ç”¨ï¼ˆç”¨æ–¼è¿½è¹¤ token æ¶ˆè€—ï¼‰
        print(f"[Jina API] èª¿ç”¨ embedding: batch={is_batch}, texts_count={len(texts)}, sample={texts[0][:20] if texts else 'empty'}...")
        sys.stdout.flush()

        try:
            response = requests.post(
                "https://api.jina.ai/v1/embeddings",
                headers={
                    "Authorization": f"Bearer {JINA_API_KEY}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": "jina-embeddings-v3",
                    "task": "retrieval.query",
                    "dimensions": 1024,
                    "input": texts
                },
                timeout=30
            )
            response.raise_for_status()
            data = response.json()
            
            # è¨˜éŒ„ tokens ä½¿ç”¨é‡ï¼ˆå¦‚æœ API æœ‰å›å‚³ï¼‰
            usage = data.get("usage", {})
            if usage:
                print(f"[Jina API] âœ… æˆåŠŸ: tokens={usage.get('total_tokens', 'unknown')}")
            else:
                print(f"[Jina API] âœ… æˆåŠŸ: {len(data.get('data', []))} å€‹ embeddings")
            sys.stdout.flush()

            embeddings = [item["embedding"] for item in data["data"]]

            if is_batch:
                return [np.array(emb) for emb in embeddings]
            else:
                return np.array(embeddings[0])

        except Exception as e:
            print(f"âš ï¸ Jina API éŒ¯èª¤: {e}")
            sys.stdout.flush()
            # å¼·åˆ¶ Jina æ¨¡å¼æ™‚ï¼Œä¸å›é€€åˆ°æœ¬åœ°æ¨¡å‹ï¼ˆé¿å… OOM/ä¸‹è¼‰æ¨¡å‹ï¼‰
            if FORCE_JINA_API:
                raise RuntimeError(f"Jina API å¤±æ•—ï¼ˆä¸” USE_JINA_API=true ç¦æ­¢å›é€€æœ¬åœ°æ¨¡å‹ï¼‰: {e}")
            # éå¼·åˆ¶æ™‚ï¼Œæ‰å…è¨±å›é€€åˆ°æœ¬åœ°æ¨¡å‹ï¼ˆè‹¥å¯ç”¨ï¼‰
            if model:
                return model.encode(text)
            raise RuntimeError("Jina API å’Œæœ¬åœ°æ¨¡å‹éƒ½ä¸å¯ç”¨")

    elif model:
        # ä½¿ç”¨æœ¬åœ°æ¨¡å‹
        return model.encode(text)

    else:
        raise RuntimeError("æ²’æœ‰å¯ç”¨çš„ embedding æ–¹æ³•ï¼ˆéœ€è¦è¨­å®š USE_JINA_API=true æˆ–è¼‰å…¥æœ¬åœ°æ¨¡å‹ï¼‰")


def init_background():
    """èƒŒæ™¯åˆå§‹åŒ–æ¨¡å‹å’Œé€£æ¥ï¼ˆåœ¨ç¨ç«‹ç·šç¨‹ä¸­åŸ·è¡Œï¼‰"""
    global model, qdrant_client, category_embeddings, feature_calculator
    global SentenceTransformer, QdrantClient, FeatureWeightCalculator, get_vision_prompt, FEATURE_INDEX

    try:
        print("ğŸš€ é–‹å§‹èƒŒæ™¯åˆå§‹åŒ–...")
        sys.stdout.flush()
        _init_background_impl()
    except Exception as e:
        print(f"âŒ èƒŒæ™¯åˆå§‹åŒ–å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        sys.stdout.flush()


def _init_background_impl():
    """å¯¦éš›çš„èƒŒæ™¯åˆå§‹åŒ–å¯¦ä½œï¼ˆç”± init_background åŒ…è£ï¼‰"""
    global model, qdrant_client, category_embeddings, feature_calculator
    global SentenceTransformer, QdrantClient, FeatureWeightCalculator, get_vision_prompt, FEATURE_INDEX

    # 1. è¼‰å…¥ Qdrant å®¢æˆ¶ç«¯æ¨¡çµ„
    try:
        print("  è¼‰å…¥ qdrant_client æ¨¡çµ„...")
        sys.stdout.flush()
        from qdrant_client import QdrantClient as QC
        QdrantClient = QC
    except Exception as e:
        print(f"  âš ï¸ ç„¡æ³•è¼‰å…¥ qdrant_client: {e}")
        sys.stdout.flush()

    # 2. é€£æ¥ Qdrant
    print(f"  é€£æ¥ Qdrant: {QDRANT_URL}")
    if QDRANT_API_KEY:
        print("    API Key å·²è¨­å®š")
    sys.stdout.flush()

    try:
        qdrant_client = get_qdrant_client()
        collections = qdrant_client.get_collections()
        print(f"  âœ… Qdrant é€£ç·šæˆåŠŸï¼Œå…± {len(collections.collections)} å€‹ collections")
        
        # æª¢æŸ¥ collection ç¶­åº¦æ˜¯å¦åŒ¹é…
        if COLLECTION_NAME in [c.name for c in collections.collections]:
            collection_info = qdrant_client.get_collection(COLLECTION_NAME)
            existing_dim = collection_info.config.params.vectors.size
            
            # ä¾æ¨¡å‹è¨­å®šçš„ç¶­åº¦ï¼Œé¿å…æœ¬æ©Ÿæ¨¡å‹èˆ‡ Jina v3 ä¸ä¸€è‡´
            expected_dim = EMBEDDING_DIM
            
            if existing_dim != expected_dim:
                print(f"  âš ï¸ Collection '{COLLECTION_NAME}' ç¶­åº¦ä¸åŒ¹é…ï¼")
                print(f"     ç¾æœ‰ç¶­åº¦: {existing_dim}")
                print(f"     æœŸæœ›ç¶­åº¦: {expected_dim}")
                print(f"  âš ï¸ é€™æœƒå°è‡´æœå°‹å¤±æ•—ï¼Œè«‹é‡æ–°å‘é‡åŒ–è³‡æ–™æˆ–æ›´æ–° collection")
                print(f"     å»ºè­°ï¼šé‹è¡Œ embed_plants_forest.py é‡æ–°å‘é‡åŒ–ï¼ˆæœƒè‡ªå‹•è™•ç†ç¶­åº¦ï¼‰")
    except Exception as e:
        print(f"  âš ï¸ Qdrant é€£ç·šå¤±æ•—: {e}")
        print(f"    æ‡‰ç”¨å°‡ç¹¼çºŒé‹è¡Œï¼Œä½†æœå°‹åŠŸèƒ½ä¸å¯ç”¨")
        qdrant_client = None
    sys.stdout.flush()

    # 3. è¼‰å…¥ embedding æ¨¡å‹ï¼ˆå¦‚æœä¸ä½¿ç”¨ Jina APIï¼‰
    # FORCE_JINA_API=true æ™‚ï¼Œå°±ç®— key ç¼ºå¤±ä¹Ÿä¸è¼‰æœ¬åœ°æ¨¡å‹ï¼ˆé¿å… Zeabur ä¸‹è¼‰/è¨˜æ†¶é«”å•é¡Œï¼‰
    if FORCE_JINA_API or (USE_JINA_API and JINA_API_KEY):
        print(f"  ä½¿ç”¨ Jina AI API: {EMBEDDING_MODEL}")
        print(f"    API Key: {'*' * 20}{JINA_API_KEY[-4:] if JINA_API_KEY else 'None'}")
        print("  â© è·³éæœ¬åœ°æ¨¡å‹è¼‰å…¥")
        model = None
    else:
        try:
            print(f"  è¼‰å…¥æœ¬åœ° embedding æ¨¡å‹: {EMBEDDING_MODEL}")
            print("    é€™å¯èƒ½éœ€è¦å¹¾åˆ†é˜...")
            sys.stdout.flush()

            from sentence_transformers import SentenceTransformer as ST
            SentenceTransformer = ST

            print("    æ­£åœ¨ä¸‹è¼‰/è¼‰å…¥æ¨¡å‹æ¬Šé‡...")
            sys.stdout.flush()

            model = SentenceTransformer(EMBEDDING_MODEL, trust_remote_code=True)

            print("  âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ")
        except MemoryError as e:
            print(f"  âŒ è¨˜æ†¶é«”ä¸è¶³ï¼Œç„¡æ³•è¼‰å…¥æ¨¡å‹: {e}")
            import traceback
            traceback.print_exc()
            model = None
        except Exception as e:
            print(f"  âš ï¸ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            model = None
    sys.stdout.flush()

    # 4. è¼‰å…¥ç‰¹å¾µæ¬Šé‡è¨ˆç®—å™¨
    try:
        print("  è¼‰å…¥ç‰¹å¾µæ¬Šé‡è¨ˆç®—å™¨...")
        sys.stdout.flush()
        from feature_weights import FeatureWeightCalculator as FWC, get_vision_prompt as gvp, FEATURE_INDEX as FI
        FeatureWeightCalculator = FWC
        get_vision_prompt = gvp
        FEATURE_INDEX = FI
    except Exception as e:
        print(f"  âš ï¸ ç‰¹å¾µæ¬Šé‡è¨ˆç®—å™¨è¼‰å…¥å¤±æ•—: {e}")
    sys.stdout.flush()

    # 5. è¼‰å…¥ç‰¹å¾µè³‡æ–™
    import os.path
    # å„ªå…ˆé †åºï¼štaxonomy-v2ï¼ˆæœ€æ–°ï¼Œå·²è£œé½Š taxonomyï¼‰> enriched-embed-dedup > enriched > dedup > clean > final-4302
    taxonomy_v2_paths = [
        "/app/data/plants-forest-gov-tw-enriched-embed-dedup.taxonomy-v2.jsonl",
        os.path.join(os.path.dirname(__file__), "..", "data", "plants-forest-gov-tw-enriched-embed-dedup.taxonomy-v2.jsonl"),
        os.path.join(os.path.dirname(__file__), "data", "plants-forest-gov-tw-enriched-embed-dedup.taxonomy-v2.jsonl"),
    ]
    embed_dedup_paths = [
        "/app/data/plants-forest-gov-tw-enriched-embed-dedup.jsonl",
        os.path.join(os.path.dirname(__file__), "..", "data", "plants-forest-gov-tw-enriched-embed-dedup.jsonl"),
        os.path.join(os.path.dirname(__file__), "data", "plants-forest-gov-tw-enriched-embed-dedup.jsonl"),
    ]
    enriched_paths = [
        "/app/data/plants-forest-gov-tw-enriched.jsonl",
        os.path.join(os.path.dirname(__file__), "..", "data", "plants-forest-gov-tw-enriched.jsonl"),
        os.path.join(os.path.dirname(__file__), "data", "plants-forest-gov-tw-enriched.jsonl"),
    ]
    dedup_paths = [
        "/app/data/plants-forest-gov-tw-dedup.jsonl",
        os.path.join(os.path.dirname(__file__), "..", "data", "plants-forest-gov-tw-dedup.jsonl"),
        os.path.join(os.path.dirname(__file__), "data", "plants-forest-gov-tw-dedup.jsonl"),
    ]
    final_4302_paths = [
        "/app/data/plants-forest-gov-tw-final-4302.jsonl",
        os.path.join(os.path.dirname(__file__), "..", "data", "plants-forest-gov-tw-final-4302.jsonl"),
        os.path.join(os.path.dirname(__file__), "data", "plants-forest-gov-tw-final-4302.jsonl"),
    ]
    clean_paths = [
        "/app/data/plants-forest-gov-tw-clean.jsonl",
        os.path.join(os.path.dirname(__file__), "..", "data", "plants-forest-gov-tw-clean.jsonl"),
        os.path.join(os.path.dirname(__file__), "data", "plants-forest-gov-tw-clean.jsonl"),
    ]
    
    enhanced_paths = [
        "/app/data/plants-forest-gov-tw-enhanced.jsonl",  # Docker å®¹å™¨ä¸­çš„è·¯å¾‘ï¼ˆå‚™ç”¨ï¼‰
        os.path.join(os.path.dirname(__file__), "..", "data", "plants-forest-gov-tw-enhanced.jsonl"),
        os.path.join(os.path.dirname(__file__), "data", "plants-forest-gov-tw-enhanced.jsonl"),
    ]
    
    # å‚™ç”¨è·¯å¾‘ï¼šåŸå§‹è³‡æ–™ï¼ˆå¦‚æœ enhanced ä¸å­˜åœ¨æ™‚ä½¿ç”¨ï¼‰
    fallback_paths = [
        "/app/data/plants-forest-gov-tw.jsonl",
        os.path.join(os.path.dirname(__file__), "..", "data", "plants-forest-gov-tw.jsonl"),
        os.path.join(os.path.dirname(__file__), "data", "plants-forest-gov-tw.jsonl"),
    ]
    
    # èˆŠæª”æ¡ˆè·¯å¾‘ï¼ˆä¸å»ºè­°ä½¿ç”¨ï¼‰
    old_paths = [
        os.path.join(os.path.dirname(__file__), "..", "data", "plants-enriched.jsonl"),
        os.path.join(os.path.dirname(__file__), "data", "plants-enriched.jsonl"),
        "/app/data/plants-enriched.jsonl",
    ]
    
    data_path = None
    # è‹¥æœ‰æŒ‡å®š FEATURE_DATA_PATHï¼Œå„ªå…ˆä½¿ç”¨ï¼ˆåªå½±éŸ¿ç‰¹å¾µæ¬Šé‡çµ±è¨ˆï¼‰
    if FEATURE_DATA_PATH:
        exists = os.path.exists(FEATURE_DATA_PATH)
        print(f"  FEATURE_DATA_PATH æŒ‡å®šæª”æ¡ˆ: {FEATURE_DATA_PATH} -> {'âœ… å­˜åœ¨' if exists else 'âŒ ä¸å­˜åœ¨'}")
        if exists:
            data_path = FEATURE_DATA_PATH
    # å¦å‰‡ä¾é è¨­å„ªå…ˆé †åºï¼štaxonomy-v2 > enriched-embed-dedup > P0.6 å¼·åŒ– > P0.5 å»é‡ > P0 clean > final-4302
    if not data_path:
        print(f"  æœå°‹è³‡æ–™æª”æ¡ˆï¼ˆtaxonomy-v2 > enriched-embed-dedup > P0.6 å¼·åŒ– > P0.5 å»é‡ > P0 clean > final-4302ï¼‰...")
        # å„ªå…ˆä½¿ç”¨ taxonomy-v2ï¼ˆå·²è£œé½Š taxonomyï¼‰
        for p in taxonomy_v2_paths:
            exists = os.path.exists(p)
            print(f"    æª¢æŸ¥: {p} -> {'âœ… å­˜åœ¨' if exists else 'âŒ ä¸å­˜åœ¨'}")
            if exists:
                data_path = p
                print(f"    âœ… æ‰¾åˆ° Taxonomy V2 è³‡æ–™ï¼ˆå·²è£œé½Š taxonomyï¼‰: {p}")
                break
    if not data_path:
        # å…¶æ¬¡ä½¿ç”¨ enriched-embed-dedup
        for p in embed_dedup_paths:
            exists = os.path.exists(p)
            print(f"    æª¢æŸ¥: {p} -> {'âœ… å­˜åœ¨' if exists else 'âŒ ä¸å­˜åœ¨'}")
            if exists:
                data_path = p
                print(f"    âœ… æ‰¾åˆ° Enriched-Embed-Dedup è³‡æ–™: {p}")
                break
    if not data_path:
        for p in enriched_paths:
            exists = os.path.exists(p)
            print(f"    æª¢æŸ¥: {p} -> {'âœ… å­˜åœ¨' if exists else 'âŒ ä¸å­˜åœ¨'}")
            if exists:
                data_path = p
                print(f"    âœ… æ‰¾åˆ° P0.6 å¼·åŒ–å¾Œè³‡æ–™: {p}")
                break
    if not data_path:
        for p in dedup_paths:
            exists = os.path.exists(p)
            print(f"    æª¢æŸ¥: {p} -> {'âœ… å­˜åœ¨' if exists else 'âŒ ä¸å­˜åœ¨'}")
            if exists:
                data_path = p
                print(f"    âœ… æ‰¾åˆ° P0.5 å»é‡å¾Œè³‡æ–™: {p}")
                break
    if not data_path:
        for p in clean_paths:
            exists = os.path.exists(p)
            print(f"    æª¢æŸ¥: {p} -> {'âœ… å­˜åœ¨' if exists else 'âŒ ä¸å­˜åœ¨'}")
            if exists:
                data_path = p
                print(f"    âœ… æ‰¾åˆ° P0 æ¸…ç†å¾Œè³‡æ–™: {p}")
                break
    if not data_path:
        for path in final_4302_paths:
            exists = os.path.exists(path)
            print(f"    æª¢æŸ¥: {path} -> {'âœ… å­˜åœ¨' if exists else 'âŒ ä¸å­˜åœ¨'}")
            if exists:
                data_path = path
                print(f"    âœ… æ‰¾åˆ° Final-4302 è³‡æ–™æª”æ¡ˆ: {path}")
                break
    
    # å¦‚æœ clean ä¸å­˜åœ¨ï¼Œæœå°‹ enhanced æª”æ¡ˆ
    if not data_path:
        print(f"  æœå°‹ Enhanced è³‡æ–™æª”æ¡ˆ...")
        for path in enhanced_paths:
            exists = os.path.exists(path)
            print(f"    æª¢æŸ¥: {path} -> {'âœ… å­˜åœ¨' if exists else 'âŒ ä¸å­˜åœ¨'}")
            if exists:
                data_path = path
                print(f"    âœ… æ‰¾åˆ° Enhanced è³‡æ–™æª”æ¡ˆ: {path}")
                break
    
    # å¦‚æœ enhanced æª”æ¡ˆä¸å­˜åœ¨ï¼Œä½¿ç”¨åŸå§‹è³‡æ–™
    if not data_path:
        print(f"  âš ï¸  Enhanced æª”æ¡ˆä¸å­˜åœ¨ï¼Œæœå°‹åŸå§‹è³‡æ–™æª”æ¡ˆ...")
        for path in fallback_paths:
            exists = os.path.exists(path)
            print(f"    æª¢æŸ¥: {path} -> {'âœ… å­˜åœ¨' if exists else 'âŒ ä¸å­˜åœ¨'}")
            if exists:
                data_path = path
                print(f"    âš ï¸  ä½¿ç”¨åŸå§‹è³‡æ–™æª”æ¡ˆ: {path}")
                break
    
    # å¦‚æœåŸå§‹è³‡æ–™ä¹Ÿä¸å­˜åœ¨ï¼Œæ‰ä½¿ç”¨èˆŠæª”æ¡ˆ
    if not data_path:
        print(f"  âš ï¸  æ–°æª”æ¡ˆä¸å­˜åœ¨ï¼Œæœå°‹å‚™ç”¨æª”æ¡ˆ...")
        for path in fallback_paths:
            exists = os.path.exists(path)
            print(f"    æª¢æŸ¥: {path} -> {'âœ… å­˜åœ¨' if exists else 'âŒ ä¸å­˜åœ¨'}")
            if exists:
                data_path = path
                print(f"    âš ï¸  ä½¿ç”¨å‚™ç”¨æª”æ¡ˆ: {path}")
                break
    
    # å¼·åˆ¶æª¢æŸ¥ï¼šå¦‚æœæ‰¾åˆ°èˆŠæª”æ¡ˆä½†æ–°æª”æ¡ˆä¹Ÿæ‡‰è©²å­˜åœ¨ï¼Œç™¼å‡ºè­¦å‘Š
    if data_path and "plants-enriched.jsonl" in data_path:
        new_file_path = "/app/data/plants-forest-gov-tw.jsonl"
        if os.path.exists(new_file_path):
            print(f"  âš ï¸  è­¦å‘Šï¼šæ‰¾åˆ°èˆŠæª”æ¡ˆ {data_path}ï¼Œä½†æ–°æª”æ¡ˆ {new_file_path} ä¹Ÿå­˜åœ¨ï¼")
            print(f"  ğŸ”§ å¼·åˆ¶ä½¿ç”¨æ–°æª”æ¡ˆ: {new_file_path}")
            data_path = new_file_path

    if data_path and FeatureWeightCalculator:
        try:
            print(f"  è³‡æ–™æª”: {data_path}")
            feature_calculator = FeatureWeightCalculator(data_path)
            print("  âœ… ç‰¹å¾µæ¬Šé‡è¨ˆç®—å™¨è¼‰å…¥æˆåŠŸ")
        except Exception as e:
            print(f"  âš ï¸ ç‰¹å¾µæ¬Šé‡è¨ˆç®—å™¨åˆå§‹åŒ–å¤±æ•—: {e}")
            feature_calculator = None
    else:
        print("  âš ï¸ æ‰¾ä¸åˆ°è³‡æ–™æª”æˆ–æ¨¡çµ„ï¼Œä½¿ç”¨ç©ºçš„è¨ˆç®—å™¨")
        feature_calculator = None
    sys.stdout.flush()

    # 6. è¨ˆç®—é¡åˆ¥å‘é‡ï¼ˆå¦‚æœæ¨¡å‹å¯ç”¨æˆ–ä½¿ç”¨ Jina APIï¼‰
    # å„ªåŒ–ï¼šåˆä½µæ‰€æœ‰é—œéµå­—ç‚ºä¸€æ¬¡ batch èª¿ç”¨ï¼Œæ¸›å°‘ Jina API èª¿ç”¨æ¬¡æ•¸ï¼ˆå¾ 5 æ¬¡é™åˆ° 1 æ¬¡ï¼‰
    if model or (USE_JINA_API and JINA_API_KEY):
        try:
            print("  è¨ˆç®—é¡åˆ¥å‘é‡ï¼ˆå„ªåŒ–ï¼šå–®æ¬¡ batch èª¿ç”¨ï¼‰...")
            sys.stdout.flush()
            categories = {
                "plant": ["æ¤ç‰©", "èŠ±", "æ¨¹", "è‰", "è‘‰å­", "æœå¯¦"],
                "animal": ["å‹•ç‰©", "é³¥", "é­š", "èŸ²", "ç¸"],
                "artifact": ["å»ºç¯‰", "æˆ¿å­", "è»Š", "æ©Ÿå™¨", "å·¥å…·"],
                "food": ["é£Ÿç‰©", "æ–™ç†", "èœ", "é£²æ–™"],
                "other": ["é¢¨æ™¯", "å¤©æ°£", "åœ°å½¢", "å±±", "æ²³"]
            }
            
            # æ”¶é›†æ‰€æœ‰é—œéµå­—å’Œå°æ‡‰çš„é¡åˆ¥ç´¢å¼•
            all_keywords = []
            keyword_to_category = {}  # {index: category}
            category_keyword_indices = {}  # {category: [indices]}
            
            idx = 0
            for cat, keywords in categories.items():
                category_keyword_indices[cat] = list(range(idx, idx + len(keywords)))
                for kw in keywords:
                    all_keywords.append(kw)
                    keyword_to_category[idx] = cat
                    idx += 1
            
            # ä¸€æ¬¡æ€§ batch èª¿ç”¨ï¼ˆæ‰€æœ‰é—œéµå­—ä¸€èµ·ï¼‰
            print(f"    æ‰¹æ¬¡è™•ç† {len(all_keywords)} å€‹é—œéµå­—ï¼ˆ5 å€‹é¡åˆ¥ï¼‰...")
            sys.stdout.flush()
            all_embeddings = encode_text(all_keywords)
            
            # è™•ç†å›å‚³çµæœ
            if isinstance(all_embeddings, np.ndarray):
                embeddings_array = all_embeddings  # (N, D)
            elif isinstance(all_embeddings, list):
                embeddings_array = np.array(all_embeddings)  # list[np.ndarray] -> (N, D)
            else:
                embeddings_array = np.array([all_embeddings])
            
            # ç¢ºä¿æ˜¯ (N, D)
            if embeddings_array.ndim == 1:
                embeddings_array = embeddings_array.reshape(1, -1)
            
            # æŒ‰é¡åˆ¥åˆ†çµ„ä¸¦è¨ˆç®—å¹³å‡å‘é‡
            category_embeddings = {}
            for cat, indices in category_keyword_indices.items():
                cat_vectors = embeddings_array[indices]  # (len(keywords), D)
                category_embeddings[cat] = np.mean(cat_vectors, axis=0)  # (D,)
                print(f"    âœ… {cat}: {len(indices)} å€‹é—œéµå­—")
            
            print("  âœ… é¡åˆ¥å‘é‡è¨ˆç®—å®Œæˆï¼ˆåƒ… 1 æ¬¡ API èª¿ç”¨ï¼‰")
        except MemoryError as e:
            print(f"  âŒ è¨˜æ†¶é«”ä¸è¶³ï¼Œç„¡æ³•è¨ˆç®—é¡åˆ¥å‘é‡: {e}")
            import traceback
            traceback.print_exc()
            category_embeddings = None
        except Exception as e:
            print(f"  âš ï¸ é¡åˆ¥å‘é‡è¨ˆç®—å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            category_embeddings = None
    sys.stdout.flush()

    print("ğŸ‰ èƒŒæ™¯åˆå§‹åŒ–å®Œæˆï¼")
    sys.stdout.flush()


def init():
    """å•Ÿå‹•èƒŒæ™¯åˆå§‹åŒ–ç·šç¨‹ï¼Œç«‹å³è¿”å›è®“ HTTP æœå‹™å™¨å•Ÿå‹•"""
    print("=" * 60)
    print("ğŸŒ¿ æ¤ç‰©å‘é‡æœå°‹ API (ç‰ˆæœ¬: NO_MUST_GATE_V2)")
    print("=" * 60)
    sys.stdout.flush()

    # åœ¨èƒŒæ™¯ç·šç¨‹ä¸­åŸ·è¡Œåˆå§‹åŒ–
    init_thread = threading.Thread(target=init_background, daemon=True)
    init_thread.start()

    print("ğŸ“¡ HTTP æœå‹™å™¨æ­£åœ¨å•Ÿå‹•...")
    print("   åˆå§‹åŒ–å°‡åœ¨èƒŒæ™¯åŸ·è¡Œ")
    sys.stdout.flush()


def classify_query(query: str) -> dict:
    """
    åˆ†é¡æŸ¥è©¢é¡å‹
    è¿”å›: { "category": "plant/animal/artifact/food/other", "confidence": 0.xx, "is_plant": true/false }
    """
    if category_embeddings is None:
        return {
            "category": "unknown",
            "confidence": 0,
            "scores": {},
            "is_plant": False,
            "plant_score": 0,
            "error": "æ¨¡å‹å°šæœªè¼‰å…¥å®Œæˆ"
        }

    query_vector = encode_text(query)
    if isinstance(query_vector, list):
        query_vector = np.array(query_vector)
    if isinstance(query_vector, np.ndarray) and query_vector.ndim > 1:
        # ä¿éšªï¼šè‹¥æ„å¤–å›å‚³ (N, D)ï¼Œå–å¹³å‡è®Šæˆ (D,)
        query_vector = np.mean(query_vector, axis=0)

    # è¨ˆç®—èˆ‡å„é¡åˆ¥çš„ç›¸ä¼¼åº¦
    scores = {}
    for cat, cat_vector in category_embeddings.items():
        # é¤˜å¼¦ç›¸ä¼¼åº¦
        similarity = np.dot(query_vector, cat_vector) / (
            np.linalg.norm(query_vector) * np.linalg.norm(cat_vector)
        )
        scores[cat] = float(similarity)

    # æ‰¾å‡ºæœ€é«˜åˆ†çš„é¡åˆ¥
    best_category = max(scores, key=scores.get)
    best_score = scores[best_category]

    # åˆ¤æ–·æ˜¯å¦ç‚ºæ¤ç‰©ç›¸é—œ
    is_plant = scores["plant"] >= PLANT_THRESHOLD

    return {
        "category": best_category,
        "confidence": best_score,
        "scores": scores,
        "is_plant": is_plant,
        "plant_score": scores["plant"]
    }


def search_plants(query: str, top_k: int = 5):
    """æœå°‹æ¤ç‰©ï¼ˆç´” embeddingï¼‰"""
    if qdrant_client is None:
        print("[API] âš ï¸ search_plants: Qdrant æœªé€£ç·š")
        return []  # Qdrant æœªé€£ç·šï¼Œè¿”å›ç©ºçµæœ
        
    try:
        t0 = time.perf_counter()
        query_vector = encode_text(query)
        t1 = time.perf_counter()
        if not isinstance(query_vector, list):
            query_vector = query_vector.tolist()

        # å¢åŠ  timeout è™•ç†
        raw_results = qdrant_client.query_points(
            collection_name=COLLECTION_NAME,
            query=query_vector,
            limit=top_k,
        ).points
        t2 = time.perf_counter()
        print(f"[API] /search encode={(t1 - t0):.3f}s qdrant={(t2 - t1):.3f}s total={(t2 - t0):.3f}s top_k={top_k} results={len(raw_results)}")
        sys.stdout.flush()

        # ç‰©ç¨®å±¤ç´šå»é‡ï¼šåŒä¸€ canonical key åªä¿ç•™ä¸€ç­†å€™é¸ï¼ˆé¿å…åŒç‰©ç¨®é‡è¤‡å‡ºç¾åœ¨ç¬¬ä¸€éšæ®µåˆ—è¡¨ï¼‰
        seen_canonical = set()
        dedup_results = []
        for r in raw_results:
            key = _canonical_name(r.payload or {})
            if not key:
                key = str(r.id)
            if key in seen_canonical:
                continue
            seen_canonical.add(key)
            dedup_results.append(r)
            if len(dedup_results) >= top_k:
                break

        out = [
            {
                "code": r.payload.get("code"),
                "chinese_name": r.payload.get("chinese_name"),
                "scientific_name": r.payload.get("scientific_name"),
                "family": r.payload.get("family"),
                "family_en": r.payload.get("family_en"),
                "genus": r.payload.get("genus"),
                "life_form": r.payload.get("life_form"),
                "score": r.score,
                "summary": r.payload.get("summary", "")[:300],
            }
            for r in dedup_results
        ]
        # è¬ç”¨æ¢ç›®è¼•åº¦é™æ¬Šï¼ˆèˆ‡ hybrid ä¸€è‡´ï¼‰ï¼Œå†ä¾åˆ†æ•¸æ’åº
        apply_generic_top1_penalty(out)
        out.sort(key=lambda x: x["score"], reverse=True)
        return out
    except Exception as e:
        print(f"[API] âŒ search_plants éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        sys.stdout.flush()
        return []


# SOFT çŸ›ç›¾è¦å‰‡ï¼ˆåªå–æœ€åš´é‡ 2 æ¢æ‰£åˆ†ï¼‰
SOFT_RULES = [
    {"id": "S1", "trait": "leaf_arrangement", "conf_min": 0.5, "penalty": 0.20},
    {"id": "S2", "trait": "life_form", "conf_min": 0.6, "penalty": 0.12},
    {"id": "S3", "trait": "leaf_type", "conf_min": 0.7, "penalty": 0.25},
    {"id": "S4", "trait": "flower_color", "conf_min": 0.6, "penalty": 0.18},  # ç´«èŠ±/ç²‰ç´… vs ç´…èŠ±
]
MAX_SOFT_COUNT = 2

# èŠ±è‰²äº’æ–¥ç¾¤çµ„ï¼šç´«/ç²‰ vs ç´…ï¼ˆé‡ç‰¡ä¸¹ç´«èŠ± vs ç«ç­’æ¨¹ç´…èŠ±ï¼‰
FLOWER_COLOR_GROUPS = {
    "purple": "gp", "pink": "gp", "purple_pink": "gp",
    "red": "gr",
    "white": "gw", "yellow": "gy", "orange": "go",
}

# è‘‰åºäº’æ–¥ç¾¤çµ„ï¼šåŒç¾¤çµ„=ä¸€è‡´ï¼Œä¸åŒç¾¤çµ„=çŸ›ç›¾
LEAF_ARRANGEMENT_GROUP_IDS = {
    "alternate": "g1",
    "spiral": "g1",
    "opposite": "g2",
    "whorled": "g3",
    "fascicled": "g4",
    "basal": "g5",
}

LIFE_FORM_GROUPS = {
    "herb": ["è‰æœ¬"],
    "herbaceous": ["è‰æœ¬"],
    "annual_herb": ["è‰æœ¬"],
    "perennial_herb": ["è‰æœ¬"],
    "shrub": ["çŒæœ¨", "äºçŒæœ¨"],
    "subshrub": ["çŒæœ¨", "äºçŒæœ¨"],
    "tree": ["å–¬æœ¨", "å°å–¬æœ¨"],
    "small_tree": ["å–¬æœ¨", "å°å–¬æœ¨"],
    "vine": ["è—¤æœ¬"],
    "climbing_vine": ["è—¤æœ¬"],
    "aquatic": ["æ°´ç”Ÿ", "æ°´ç”Ÿæ¤ç‰©"],
}


def _to_str(v):
    if v is None:
        return ""
    if isinstance(v, list):
        return " ".join(str(x) for x in v if x is not None)
    return str(v)


def _get_plant_leaf_arrangement(payload):
    kf = payload.get("key_features") or []
    kf_norm = payload.get("key_features_norm") or []
    text = " ".join(_to_str(x) for x in kf + kf_norm)
    if "å°ç”Ÿ" in text:
        return "opposite"
    if "è¼ªç”Ÿ" in text:
        return "whorled"
    if "äº’ç”Ÿ" in text or "èºæ—‹" in text:
        return "alternate"
    return None


def _get_plant_life_form_group(payload):
    lf = _to_str(payload.get("life_form", "")).strip()
    if not lf:
        return None
    for en, zh_list in LIFE_FORM_GROUPS.items():
        if any(z in lf for z in zh_list):
            return en
    if "è‰æœ¬" in lf:
        return "herb"
    if "çŒæœ¨" in lf or "äºçŒæœ¨" in lf:
        return "shrub"
    if "å–¬æœ¨" in lf:
        return "tree"
    if "è—¤æœ¬" in lf:
        return "vine"
    if "æ°´ç”Ÿ" in lf:
        return "aquatic"
    return None


def _get_plant_leaf_type(payload):
    """å¾ payload æ¨æ–·è‘‰å‹ï¼šsimple(å–®è‘‰) æˆ– compound(è¤‡è‘‰)ã€‚"""
    raw = payload.get("raw_data") or {}
    ident = raw.get("identification") or {}
    kf = ident.get("key_features") or []
    kf_norm = ident.get("key_features_norm") or []
    text = " ".join(_to_str(x) for x in kf + kf_norm)
    if any(x in text for x in ["ç¾½ç‹€è¤‡è‘‰", "æŒç‹€è¤‡è‘‰", "æŒç‹€", "ä¸‰å‡ºè¤‡", "è¤‡è‘‰"]):
        return "compound"
    if any(x in text for x in ["å–®è‘‰"]):
        return "simple"
    return None


# Gate-Aï¼šæ£•æ«š/è¤‡è‘‰ gate é—œéµå­—ï¼ˆquery æœ‰å‰‡å€™é¸éœ€æœ‰ï¼‰
PALM_COMPOUND_QUERY_TOKENS = frozenset({"ç¾½ç‹€è¤‡è‘‰", "æŒç‹€è¤‡è‘‰", "äºŒå›ç¾½ç‹€", "ä¸‰å‡ºè¤‡è‘‰", "è¤‡è‘‰", "æ£•æ«š"})
# å€™é¸ã€Œæ˜¯å¦ç‚ºæ£•æ«šé¡ã€ï¼šåƒ…ç”¨æ£•æ«šç‰¹æœ‰é—œéµå­—ï¼Œä¸å«ç¾½ç‹€è¤‡è‘‰ï¼ˆéŠ€åˆæ­¡/è±†ç§‘ä¹Ÿæœ‰ç¾½ç‹€è¤‡è‘‰ï¼‰
PALM_SPECIFIC_PLANT_KEYWORDS = ("æ£•æ«š", "æ£•æ«šç§‘", "æ‰‡å½¢", "æ‰‡å½¢è‘‰", "æ¤°å­", "æ‰‡è‘‰")


def _plant_has_palm_compound(payload) -> bool:
    """å€™é¸æ¤ç‰©æ˜¯å¦ç‚ºæ£•æ«šé¡ï¼ˆæ£•æ«šç§‘/æ¤°å­/æ‰‡å½¢è‘‰ç­‰ï¼‰ï¼Œéåƒ…æœ‰ç¾½ç‹€è¤‡è‘‰ã€‚"""
    kf = payload.get("key_features") or []
    kf_norm = payload.get("key_features_norm") or []
    summary = _to_str(payload.get("summary", ""))
    text = " ".join(_to_str(x) for x in kf + kf_norm) + " " + summary
    return any(kw in text for kw in PALM_SPECIFIC_PLANT_KEYWORDS)


def _is_bryophyte_pteridophyte(payload) -> bool:
    """å€™é¸æ˜¯å¦ç‚ºè‹”è˜šè•¨é¡ï¼ˆèˆ‡ç¨®å­æ¤ç‰©åˆ†é–‹ï¼ŒæŸ¥è©¢ç‚ºçŒæœ¨/è‰æœ¬/èŠ±æ™‚å¼·é™æ¬Šï¼‰ã€‚"""
    cname = (payload.get("chinese_name") or "").strip()
    if cname:
        if cname.endswith("è‹”") or cname.endswith("è˜š") or cname.endswith("è•¨"):
            return True
    family = _to_str(payload.get("family", "")).strip()
    if family and ("è‹”" in family or "è˜š" in family or "è•¨" in family):
        return True
    summary = _to_str(payload.get("summary", ""))
    kf = payload.get("key_features") or []
    kf_norm = payload.get("key_features_norm") or []
    text = summary + " " + " ".join(_to_str(x) for x in kf + kf_norm)
    if any(kw in text for kw in ("è‹”ç¶±", "è˜šç¶±", "è•¨é¡", "åœ°éŒ¢", "è§’è‹”", "çœŸè˜š", "æ³¥ç‚­è˜š", "å­”é›€è‹”", "æ‡¸è‹”", "ç´«è¼è‹”")):
        return True
    return False


def compute_soft_contradiction_penalty(traits, payload):
    if not traits or not isinstance(traits, dict):
        return []
    penalties = []
    for rule in SOFT_RULES:
        trait_key = rule["trait"]
        conf_min = rule["conf_min"]
        penalty_val = rule["penalty"]
        t = traits.get(trait_key)
        if not t or not isinstance(t, dict):
            continue
        conf = t.get("confidence", 0) or 0
        if conf < conf_min:
            continue
        q_val = (t.get("value") or "").strip().lower()
        if not q_val:
            continue
        if trait_key == "leaf_arrangement":
            q_gid = LEAF_ARRANGEMENT_GROUP_IDS.get(q_val)
            if not q_gid:
                continue
            plant_val = _get_plant_leaf_arrangement(payload)
            if plant_val is None:
                continue
            plant_gid = LEAF_ARRANGEMENT_GROUP_IDS.get(plant_val)
            if not plant_gid:
                continue
            if q_gid == plant_gid:
                continue
            penalties.append((rule["id"], penalty_val))
        elif trait_key == "life_form":
            q_group = LIFE_FORM_GROUPS.get(q_val)
            if not q_group:
                continue
            plant_group = _get_plant_life_form_group(payload)
            if plant_group is None:
                continue
            if q_val == plant_group:
                continue
            plant_zh = LIFE_FORM_GROUPS.get(plant_group, [])
            if set(q_group) & set(plant_zh):
                continue
            penalties.append((rule["id"], penalty_val))
        elif trait_key == "leaf_type":
            plant_lt = _get_plant_leaf_type(payload)
            if plant_lt is None:
                continue
            q_compound = q_val in ("compound", "pinnate", "pinnately_compound", "palmate", "trifoliate")
            plant_compound = plant_lt == "compound"
            if q_compound == plant_compound:
                continue
            penalties.append((rule["id"], penalty_val))
        elif trait_key == "flower_color":
            plant_fc = _get_plant_flower_color(payload)
            if plant_fc is None:
                continue
            q_gid = FLOWER_COLOR_GROUPS.get(q_val) or FLOWER_COLOR_GROUPS.get(q_val.replace(" ", "_"))
            plant_gid = FLOWER_COLOR_GROUPS.get(plant_fc) or FLOWER_COLOR_GROUPS.get(plant_fc.replace(" ", "_"))
            if not q_gid or not plant_gid:
                continue
            if q_gid == plant_gid:
                continue
            # åƒ…åœ¨ query ç´«/ç²‰ã€plant ç´… æ™‚æ‡²ç½°ï¼ˆé‡ç‰¡ä¸¹ç´«èŠ±â†’ç«ç­’æ¨¹ç´…èŠ±æ‡‰é™æ¬Šï¼›åå‘ä¸æ‡²ç½°ï¼Œé¿å… LM æŠ½éŒ¯ç´…èŠ±æ™‚æ‡²åˆ°æ­£ç¢ºç´«èŠ±ç‰©ç¨®ï¼‰
            if q_gid == "gp" and plant_gid == "gr":
                penalties.append((rule["id"], penalty_val))
    return sorted(penalties, key=lambda x: -x[1])[:MAX_SOFT_COUNT]


def _get_plant_flower_color(payload) -> str | None:
    """å¾ payload æ¨æ–·èŠ±è‰²ï¼ˆè‹±æ–‡ï¼‰ã€‚"""
    kf = payload.get("key_features") or []
    kf_norm = payload.get("key_features_norm") or []
    text = " ".join(_to_str(x) for x in kf + kf_norm)
    if "ç´«èŠ±" in text or "ç´«è‰²" in text:
        return "purple"
    if "ç²‰ç´…èŠ±" in text or "ç²‰ç´…è‰²" in text:
        return "pink"
    if "ç´…èŠ±" in text or "ç´…è‰²" in text:
        return "red"
    if "ç™½èŠ±" in text or "ç™½è‰²" in text:
        return "white"
    if "é»ƒèŠ±" in text or "é»ƒè‰²" in text:
        return "yellow"
    if "æ©™èŠ±" in text or "æ©™è‰²" in text:
        return "orange"
    return None


def resolve_weights(weights):
    if not weights:
        return EMBEDDING_WEIGHT, FEATURE_WEIGHT

    raw_embedding = weights.get("embedding")
    raw_feature = weights.get("feature")

    if isinstance(raw_embedding, (int, float)) and isinstance(raw_feature, (int, float)):
        total = raw_embedding + raw_feature
        if total > 0:
            embedding = raw_embedding / total
            feature = raw_feature / total
            embedding = max(0.1, min(0.9, embedding))
            feature = max(0.1, min(0.9, feature))
            norm_total = embedding + feature
            embedding /= norm_total
            feature /= norm_total
            return float(embedding), float(feature)

    return EMBEDDING_WEIGHT, FEATURE_WEIGHT


def _normalize_scientific_name(sci: str) -> str:
    """æ­£è¦åŒ–å­¸åï¼šç§»é™¤è®Šç¨®æ¨™è¨˜ï¼ˆvar./subsp./f.ï¼‰ä¸¦æ¨™æº–åŒ–æ ¼å¼"""
    if not sci:
        return ""
    sci = sci.strip()
    # ç§»é™¤å¸¸è¦‹çš„è®Šç¨®æ¨™è¨˜ï¼ˆvar. / subsp. / f. / cv. / 'ï¼‰
    import re
    # ç§»é™¤ var. / subsp. / f. / cv. åŠå…¶å¾Œé¢çš„å…§å®¹ï¼ˆä¿ç•™åˆ° species ç‚ºæ­¢ï¼‰
    sci = re.sub(r'\s+(var\.|subsp\.|ssp\.|f\.|cv\.|cultivar)', '', sci, flags=re.IGNORECASE)
    # ç§»é™¤å–®å¼•è™Ÿï¼ˆæ ½åŸ¹ç¨®æ¨™è¨˜ï¼‰
    sci = sci.replace("'", "").replace('"', '')
    # ç§»é™¤å¤šé¤˜ç©ºæ ¼
    sci = " ".join(sci.split())
    return sci.lower()


def _canonical_name(payload: dict) -> str:
    """ä»¥å­¸åå„ªå…ˆå»ºç«‹ç‰©ç¨® canonical keyï¼Œå­¸åç¼ºå¤±æ™‚é€€å›ä¸­æ–‡å+ç§‘+å±¬ã€‚"""
    if not isinstance(payload, dict):
        return ""
    sci = (payload.get("scientific_name") or "").strip()
    if sci:
        # æ­£è¦åŒ–å­¸åï¼ˆç§»é™¤è®Šç¨®æ¨™è¨˜ï¼‰
        sci_normalized = _normalize_scientific_name(sci)
        if sci_normalized:
            parts = sci_normalized.split()
            if len(parts) >= 2:
                # åªå– genus + speciesï¼ˆå¿½ç•¥è®Šç¨®ã€äºç¨®ç­‰ï¼‰
                return f"{parts[0]} {parts[1]}"
            return sci_normalized
    # Fallbackï¼šä¸­æ–‡å + ç§‘ + å±¬ï¼ˆæ­£è¦åŒ–ï¼šç§»é™¤ç©ºæ ¼/æ¨™é»ï¼‰
    cname = (payload.get("chinese_name") or "").strip()
    family = (payload.get("family") or "").strip()
    genus = (payload.get("genus") or "").strip()
    # æ­£è¦åŒ–ä¸­æ–‡åï¼ˆç§»é™¤ç©ºæ ¼ã€æ¨™é»ï¼‰
    if cname:
        import re
        cname = re.sub(r'[\s\-_]+', '', cname)
    key_parts = [p for p in (cname, family, genus) if p]
    return " | ".join(key_parts)


def hybrid_search(query: str, features: list = None, guess_names: list = None, top_k: int = 5, weights: dict | None = None, traits: dict | None = None):
    """
    æ··åˆæœå°‹ï¼šçµåˆ embedding ç›¸ä¼¼åº¦ + ç‰¹å¾µæ¬Šé‡ + é—œéµå­—åŒ¹é…

    Args:
        query: è‡ªç„¶èªè¨€æè¿°
        features: Vision AI æå–çš„çµæ§‹åŒ–ç‰¹å¾µåˆ—è¡¨ï¼Œå¦‚ ["ç¾½ç‹€è¤‡è‘‰", "äº’ç”Ÿ", "ç™½èŠ±"]
        guess_names: Vision AI çŒœæ¸¬çš„æ¤ç‰©åç¨±ï¼Œå¦‚ ["æ¦•æ¨¹", "èŒ„è‹³"]
        top_k: è¿”å›çµæœæ•¸é‡

    Returns:
        æœå°‹çµæœåˆ—è¡¨ï¼ŒåŒ…å«æ··åˆåˆ†æ•¸
    """
    features = features or []
    # æ¸…æ´— guess_namesï¼ˆå†æ¬¡ä¿éšªï¼ŒNode ç«¯å·²åšåˆæ­¥æ¸…æ´—ï¼‰
    raw_guess_names = guess_names or []
    guess_names = []
    bad_descriptive = ("ä¾‹å¦‚", "æ¯”å¦‚", "åƒæ˜¯", "é€™æ˜¯ä¸€æ ª", "é€™ç¨®æ¤ç‰©", "æ•´é«”å‘ˆç¾", "ä½†éœ€è¦æ›´å¤š", "å¦å‘ä¸‹å‚æ›", "ç„¡æ³•å®Œå…¨ç¢ºå®š", "è§£æåº¦æœ‰é™", "é¡ä¼¼")
    bad_markdown = ("*", "#", "_", "`", "[", "]")
    for name in raw_guess_names:
        if not name:
            continue
        n = str(name).strip()
        if not n:
            continue
        if n.lower() == "unknown":
            continue
        if len(n) < 2 or len(n) > 12:
            continue
        if any(bad in n for bad in bad_descriptive):
            continue
        if any(bad in n for bad in bad_markdown):
            continue
        # æ’é™¤é˜¿æ‹‰ä¼¯æ–‡ã€è¥¿é‡Œçˆ¾æ–‡ç­‰æ··åˆèª
        if any("\u0600" <= c <= "\u06FF" or "\u0400" <= c <= "\u04FF" for c in n):
            continue
        guess_names.append(n)
    guess_names = list(dict.fromkeys(guess_names))  # å»é‡ä¿åº
    weights = weights or {}
    embedding_weight = float(weights.get("embedding", EMBEDDING_WEIGHT))
    feature_weight = float(weights.get("feature", FEATURE_WEIGHT))

    # Phase 2ï¼šä¿è­·æ€§ clamp + æ­£è¦åŒ–ï¼Œé¿å…ç‰¹å¾µæ¬Šé‡éé«˜é€ æˆæ“¾äº‚
    if not features:
        feature_weight = 0.0
        embedding_weight = 1.0
    embedding_weight = max(0.65, min(0.95, embedding_weight))
    feature_weight = max(0.05, min(0.35, feature_weight)) if features else 0.0
    total_w = embedding_weight + feature_weight
    if total_w <= 0:
        embedding_weight, feature_weight = 1.0, 0.0
    else:
        embedding_weight = embedding_weight / total_w
        feature_weight = feature_weight / total_w
    print(f"[API] hybrid_search å…¥åƒ: query_len={len(query or '')}, features={len(features)}, guess_names={len(guess_names)}, top_k={top_k}, weights=E:{embedding_weight:.2f}/F:{feature_weight:.2f}")
    sys.stdout.flush()

    if qdrant_client is None:
        print(f"[API] hybrid_search è·³é: Qdrant æœªé€£ç·šï¼Œå›å‚³ç©ºçµæœ")
        sys.stdout.flush()
        return []  # Qdrant æœªé€£ç·šï¼Œè¿”å›ç©ºçµæœ

    # 0. å¦‚æœæœ‰ guess_namesï¼Œå…ˆé€²è¡Œé—œéµå­—åŒ¹é…ï¼ˆè¼”åŠ©æé«˜è¾¨è­˜ç‡ï¼‰
    # æ³¨æ„ï¼šé—œéµå­—åŒ¹é…åªæ˜¯è¼”åŠ©ï¼Œä¸»è¦é‚„æ˜¯ä¾è³´ embedding å’Œç‰¹å¾µåŒ¹é…
    keyword_matched_ids = set()
    if guess_names:
        try:
            # ä½¿ç”¨ scroll å–å¾—æ‰€æœ‰è³‡æ–™ï¼Œç„¶å¾Œåœ¨è¨˜æ†¶é«”ä¸­éæ¿¾
            # é€™å°æ–¼å°è³‡æ–™é›†ï¼ˆ<10Kï¼‰æ˜¯å¯è¡Œçš„
            # åªåŸ·è¡Œä¸€æ¬¡ scrollï¼Œç„¶å¾Œæª¢æŸ¥æ‰€æœ‰ guess_names
            scroll_result = qdrant_client.scroll(
                collection_name=COLLECTION_NAME,
                limit=10000,  # å‡è¨­è³‡æ–™ä¸è¶…é 10K
                with_payload=True,
                with_vectors=False
            )
            
            # åœ¨è¨˜æ†¶é«”ä¸­éæ¿¾åŒ¹é…çš„æ¤ç‰©
            for point in scroll_result[0]:
                chinese_name = point.payload.get("chinese_name", "") or ""
                scientific_name = point.payload.get("scientific_name", "") or ""
                
                # æª¢æŸ¥æ˜¯å¦åŒ¹é…ä»»ä¸€ guess_nameï¼ˆéƒ¨åˆ†åŒ¹é…ï¼‰
                for name in guess_names:
                    if name and name.strip():
                        name_clean = name.strip()
                        # æª¢æŸ¥æ˜¯å¦åŒ…å«è©²åç¨±ï¼ˆéƒ¨åˆ†åŒ¹é…ï¼‰
                        if name_clean in chinese_name or name_clean in scientific_name:
                            keyword_matched_ids.add(point.id)
                            break  # åŒ¹é…åˆ°ä¸€å€‹å°±å¤ äº†
            
            if keyword_matched_ids:
                print(f"[API] é—œéµå­—åŒ¹é…æ‰¾åˆ° {len(keyword_matched_ids)} å€‹å€™é¸ï¼ˆguess_names: {guess_names}ï¼‰")
        except Exception as e:
            print(f"[API] é—œéµå­—åŒ¹é…å¤±æ•—: {e}ï¼Œç¹¼çºŒä½¿ç”¨ embedding æœå°‹")

    # 1. å…ˆç”¨ embedding å–å¾—å€™é¸
    # ğŸ”¥ é—œéµä¿®å¾©ï¼šåªä½¿ç”¨ç°¡çŸ­çš„ query_text_zhï¼Œçµ•å°ä¸è¦ç”¨æ•´æ®µåˆ†ææ–‡å­—
    # å¦‚æœ query å¤ªé•·ï¼ˆ>200 å­—ï¼‰ï¼Œåªå–å‰ 200 å­—
    # å¦‚æœ query åŒ…å«æ­¥é©Ÿæ–‡å­—ï¼ˆç¬¬ä¸€æ­¥ã€ç¬¬äºŒæ­¥...ï¼‰ï¼Œåªæå–å¯¦éš›æè¿°éƒ¨åˆ†
    search_query = (query or "").strip()
    if not search_query and guess_names:
        search_query = " ".join(str(n).strip() for n in guess_names[:3] if n)
    if not search_query and features:
        search_query = " ".join(str(f).strip() for f in features[:15] if f)
    if not search_query:
        print(f"[API] hybrid_search è­¦å‘Š: query ç‚ºç©ºä¸”ç„¡ guess_names/features å¯å…œåº•ï¼Œç„¡æ³• embedding")
        sys.stdout.flush()
        return []

    # ç§»é™¤æ­¥é©Ÿæ–‡å­—å’Œä¸ç¢ºå®šèªå¥
    if "ç¬¬ä¸€æ­¥" in search_query or "ç¬¬äºŒæ­¥" in search_query or "ç¬¬ä¸‰æ­¥" in search_query:
        # å˜—è©¦æå–å¯¦éš›æè¿°éƒ¨åˆ†ï¼ˆåœ¨ <analysis> æ¨™ç±¤å…§ï¼Œæˆ–å»é™¤æ­¥é©Ÿæ–‡å­—ï¼‰
        import re
        # ç§»é™¤æ‰€æœ‰ã€Œç¬¬Xæ­¥ï¼šã€é–‹é ­çš„è¡Œ
        lines = search_query.split('\n')
        clean_lines = []
        for line in lines:
            if not re.match(r'^\s*ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+æ­¥[ï¼š:]', line):
                if not re.match(r'^\s*\*\*ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+æ­¥', line):
                    clean_lines.append(line)
        search_query = '\n'.join(clean_lines).strip()
    
    # é™åˆ¶é•·åº¦ï¼ˆæœ€å¤š 200 å­—å…ƒï¼‰
    if len(search_query) > 200:
        search_query = search_query[:200]
    
    # å¦‚æœæœ‰çŒœæ¸¬åç¨±ï¼ŒåŠ å…¥æŸ¥è©¢ï¼ˆä½†ä¿æŒç°¡çŸ­ï¼‰
    if guess_names:
        guess_text = ' '.join(guess_names[:2])  # æœ€å¤š 2 å€‹åç¨±
        if len(search_query) + len(guess_text) + 1 <= 200:
            search_query = f"{search_query} {guess_text}"
        else:
            # å¦‚æœå¤ªé•·ï¼Œåªä¿ç•™åç¨±
            search_query = guess_text[:200]

    t0 = time.perf_counter()
    try:
        query_vector = encode_text(search_query)
    except Exception as e:
        print(f"[API] âŒ hybrid_search encode_text å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        sys.stdout.flush()
        return []
    t1 = time.perf_counter()
    if not isinstance(query_vector, list):
        query_vector = query_vector.tolist()

    # å–æ›´å¤šå€™é¸å†é‡æ–°æ’åº
    # æ“´å¤§å€™é¸æ± è‡³ 100ï¼Œè®“ embedding æ’åè¼ƒå¾Œçš„ç‰©ç¨®ï¼ˆå¦‚é¢¨éˆ´è‰ï¼‰ä¹Ÿèƒ½é€²å…¥ hybrid é‡æ’
    candidate_limit = max(100, top_k * 10)
    
    try:
        candidates = qdrant_client.query_points(
            collection_name=COLLECTION_NAME,
            query=query_vector,
            limit=candidate_limit,
        ).points
    except Exception as e:
        print(f"[API] âŒ hybrid_search Qdrant æŸ¥è©¢éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        sys.stdout.flush()
        return []
    
    if not candidates:
        print(f"[API] hybrid_search ç©ºå€™é¸: Qdrant å›å‚³ 0 ç­† (query å‰ 50 å­—: {search_query[:50]!r})")
        sys.stdout.flush()
        return []
    
    # B. Fruit-only ç¬¬äºŒè·¯å¬å›ï¼šå»¶é²+é«˜é–€æª»+å°‘é‡è£œå¬å›ï¼Œé¿å…æ±¡æŸ“å€™é¸æ± 
    # å¯è¨­ DISABLE_FRUIT_ONLY_RECALL=1 é—œé–‰ï¼Œç”¨æ–¼ A/B æ¸¬è©¦
    fruit_candidates = []
    disable_fruit = os.environ.get("DISABLE_FRUIT_ONLY_RECALL", "").strip().lower() in ("1", "true", "yes")
    if not disable_fruit and features and FEATURE_INDEX:
        fruit_features = [
            f for f in features
            if (FEATURE_INDEX.get(f) or {}).get("category") in {"fruit_type", "fruit_cluster", "fruit_surface", "calyx_persistent"}
        ]
        # é«˜é–€æª»ï¼šè‡³å°‘ 2 å€‹æœå¯¦ç‰¹å¾µæ‰è§¸ç™¼ï¼ˆé¿å…å–®ä¸€æ¼¿æœèª¤å¬ï¼‰
        if len(fruit_features) >= 2:
            print(f"[API] Fruit-only å¬å›: Query å«æœå¯¦ç‰¹å¾µ {fruit_features}ï¼Œå•Ÿå‹•ç¬¬äºŒè·¯å¬å›")
            fruit_query_text = " ".join(fruit_features)
            try:
                fruit_vector = encode_text(fruit_query_text)
                if not isinstance(fruit_vector, list):
                    fruit_vector = fruit_vector.tolist()
                # å°‘é‡è£œå¬å›ï¼š20 ç­†ï¼ˆåŸ 50 æ˜“æ±¡æŸ“å€™é¸æ± ï¼‰
                fruit_limit = int(os.environ.get("FRUIT_ONLY_LIMIT", "20"))
                fruit_candidates = qdrant_client.query_points(
                    collection_name=COLLECTION_NAME,
                    query=fruit_vector,
                    limit=fruit_limit,
                ).points
                print(f"[API] Fruit-only å¬å›æ‰¾åˆ° {len(fruit_candidates)} å€‹å€™é¸")
            except Exception as e:
                print(f"[API] Fruit-only å¬å›å¤±æ•—: {e}ï¼Œç¹¼çºŒä½¿ç”¨ä¸»è·¯å¬å›")
                fruit_candidates = []
    
    # åˆä½µå…©è·¯å€™é¸ï¼ˆå»é‡ï¼‰
    main_count = len(candidates)
    candidate_dict = {}
    for c in candidates:
        key = _canonical_name(c.payload or {}) or str(c.id)
        candidate_dict[key] = c
    
    for c in fruit_candidates:
        key = _canonical_name(c.payload or {}) or str(c.id)
        if key not in candidate_dict:
            candidate_dict[key] = c
        else:
            # å¦‚æœå·²å­˜åœ¨ï¼Œä¿ç•™ embedding åˆ†æ•¸è¼ƒé«˜çš„ï¼ˆä¸»è·¯å„ªå…ˆï¼‰
            existing_score = candidate_dict[key].score
            if c.score > existing_score:
                candidate_dict[key] = c
    
    candidates = list(candidate_dict.values())
    print(f"[API] åˆä½µå…©è·¯å¬å›: ä¸»è·¯ {main_count} + Fruitè·¯ {len(fruit_candidates)} = ç¸½è¨ˆ {len(candidate_dict)} å€‹å€™é¸")

    # å€™é¸æ± éæ¿¾ï¼šæŸ¥è©¢ç‚ºç¨®å­æ¤ç‰©æ™‚ï¼Œç›´æ¥æ’é™¤è‹”è˜šè•¨é¡ï¼ˆé¿å…æ±¡æŸ“ Top1ï¼‰
    query_has_bryo_fern = bool(search_query and ("è‹”" in search_query or "è˜š" in search_query or "è•¨" in search_query))
    query_features_str = " ".join(features or [])
    if not query_has_bryo_fern and ("è‹”" in query_features_str or "è˜š" in query_features_str or "è•¨" in query_features_str):
        query_has_bryo_fern = True
    if not query_has_bryo_fern:
        before_count = len(candidates)
        candidates = [c for c in candidates if not _is_bryophyte_pteridophyte(c.payload or {})]
        removed = before_count - len(candidates)
        if removed > 0:
            print(f"[API] å€™é¸æ± éæ¿¾: æŸ¥è©¢ç‚ºç¨®å­æ¤ç‰©ï¼Œæ’é™¤ {removed} ç­†è‹”è˜šè•¨é¡å€™é¸ï¼Œå‰© {len(candidates)} ç­†")

    t2 = time.perf_counter()
    print(f"[API] /hybrid-search encode={(t1 - t0):.3f}s qdrant={(t2 - t1):.3f}s total={(t2 - t0):.3f}s top_k={top_k} limit={candidate_limit} candidates={len(candidates)}")
    sys.stdout.flush()

    # é å…ˆè¨ˆç®— query ç‰¹å¾µç¸½æ¬Šé‡ï¼ˆç”¨æ–¼ feature_score æ¨™æº–åŒ–ï¼šmatched/query_total æ‹‰é–‹å·®è·ï¼‰
    query_total_weight = 0.0
    if features and feature_calculator:
        fi = feature_calculator.calculate_feature_score(features)
        query_total_weight = fi.get("total_score", 0) or 0
        if query_total_weight > 0:
            print(f"[API] feature_score æ¨™æº–åŒ–: query_total_weight={query_total_weight:.4f}")

    # A. å‹•æ…‹æ¬Šé‡ï¼šæ ¹æ“š Query ç‰¹å¾µçš„ã€Œé‘‘åˆ¥åŠ›ã€èª¿æ•´ feature_weight
    # å¼·ç‰¹å¾µï¼ˆé«˜é‘‘åˆ¥åŠ›ï¼‰ï¼šflower_shape, flower_colorï¼ˆç‰¹åˆ¥æ˜¯ç´«èŠ±ã€ç²‰ç´…èŠ±ï¼‰, fruit_cluster, fruit_surface, calyx_persistent, compound_leaf, trichome
    STRONG_DISCRIMINATIVE_CATEGORIES = frozenset({
        "flower_shape", "flower_position", "inflorescence_orientation",
        "flower_color",  # èŠ±è‰²ï¼ˆç‰¹åˆ¥æ˜¯ç´«èŠ±ã€ç²‰ç´…èŠ±ï¼‰å°é‡ç‰¡ä¸¹ç­‰æ¤ç‰©é‘‘åˆ¥åŠ›é«˜
        "fruit_type", "fruit_cluster", "fruit_surface", "calyx_persistent",
        "leaf_type",  # è¤‡è‘‰é¡å‹ï¼ˆç¾½ç‹€/æŒç‹€ï¼‰é‘‘åˆ¥åŠ›é«˜
        "trunk_root", "special", "surface_hair"
    })
    # å¼±ç‰¹å¾µï¼ˆé€šç”¨ï¼‰ï¼šlife_form, leaf_arrangement, leaf_margin, flower_infloï¼ˆå®¹æ˜“èª¤åˆ¤ï¼‰
    WEAK_GENERIC_CATEGORIES = frozenset({
        "life_form", "leaf_arrangement", "leaf_margin", "flower_inflo"
    })
    
    # çµ±è¨ˆ Query ä¸­å¼·/å¼±ç‰¹å¾µçš„æ•¸é‡
    strong_count = 0
    weak_count = 0
    if features and FEATURE_INDEX:
        for f in features:
            cat = (FEATURE_INDEX.get(f) or {}).get("category")
            if cat in STRONG_DISCRIMINATIVE_CATEGORIES:
                strong_count += 1
            elif cat in WEAK_GENERIC_CATEGORIES:
                weak_count += 1
    
    # å›ºå®šæ¬Šé‡ï¼šä¸ä»¥å¼·/å¼±ç‰¹å¾µå‹•æ…‹æå‡ featureï¼Œé¿å…ç‰¹å¾µä¸»å°æ’åºï¼ˆå¯§å¯ RAG å°‘å‡ºæ‰‹ï¼‰
    effective_feature_weight = feature_weight
    if weak_count >= 3 and strong_count == 0:
        effective_feature_weight = min(feature_weight, 0.18)
        print(f"[API] å¼±ç‰¹å¾µ Gate: Query åªæœ‰é€šç”¨ç‰¹å¾µï¼ˆ{weak_count} å€‹ï¼‰ï¼Œfeature æ¬Šé‡å£“ä½ç‚º {effective_feature_weight:.2f}")
    else:
        print(f"[API] æ¬Šé‡å›ºå®š E:{embedding_weight:.2f}/F:{effective_feature_weight:.2f}ï¼ˆå¼·ç‰¹å¾µ {strong_count}ã€å¼±ç‰¹å¾µ {weak_count}ï¼‰")

    # 2. è¨ˆç®—æ¯å€‹å€™é¸çš„æ··åˆåˆ†æ•¸ï¼ˆå…ˆåœ¨ç‰©ç¨®å±¤ç´šå»é‡ï¼Œå†æ’åºï¼‰
    results = []
    scored_candidates = []
    seen_canonical = set()
    
    def _is_non_species(payload) -> bool:
        """æ’é™¤ç§‘å/å±¬å/æ›¸åç­‰éç‰©ç¨®æ¢ç›®ï¼ˆå¦‚ è•éº»ç§‘ (æ–½ç‚³éœ–è‘—)ã€æ¡‘ç§‘ (æ—å¿—å¿ è‘—)ã€XXå±¬ï¼‰"""
        import re
        cname = (payload.get("chinese_name") or "").strip()
        if not cname:
            return False
        if "è‘—)" in cname or cname.endswith("è‘—)"):
            return True
        if re.search(r"ç§‘\s*\([^)]*è‘—", cname) or re.search(r"å±¬\s*\([^)]*è‘—", cname):
            return True
        if re.search(r"[ç§‘å±¬]\s*\([^)]*è‘—\s*\)\s*$", cname):
            return True
        # ç§‘/å±¬çµå°¾æˆ–å–®ç¨å‡ºç¾ â†’ éç‰©ç¨®
        if cname.endswith("ç§‘") or cname.endswith("å±¬"):
            return True
        if re.match(r"^[^\s]+\s*ç§‘\s*$", cname) or re.match(r"^[^\s]+\s*å±¬\s*$", cname):
            return True
        return False

    for r in candidates:
        if _is_non_species(r.payload or {}):
            continue
        key = _canonical_name(r.payload or {})
        if not key:
            key = str(r.id)
        if key in seen_canonical:
            continue
        seen_canonical.add(key)
        embedding_score = r.score  # 0~1
        
        # é—œéµå­—åŒ¹é…åŠ åˆ†
        keyword_bonus = 0.0
        if r.id in keyword_matched_ids:
            keyword_bonus = KEYWORD_BONUS_WEIGHT
            print(f"[API] é—œéµå­—åŒ¹é…: {r.payload.get('chinese_name', 'æœªçŸ¥')} (id={r.id}, bonus={keyword_bonus})")

        # è¨ˆç®—ç‰¹å¾µåŒ¹é…åˆ†æ•¸
        feature_score = 0.0
        matched_features = []
        coverage = 1.0
        must_matched = True
        match_result = {}

        if features and feature_calculator:
            # ... (ç‰¹å¾µæå–ä»£ç¢¼çœç•¥ï¼Œä¿æŒä¸è®Š) ...
            # å–å¾—æ¤ç‰©çš„ trait_tokensï¼ˆå„ªå…ˆä½¿ç”¨ï¼‰
            plant_trait_tokens = r.payload.get("trait_tokens", [])
            if not plant_trait_tokens:
                try:
                    from pathlib import Path
                    tokenizer_path = Path(__file__).parent / "trait_tokenizer.py"
                    if tokenizer_path.exists():
                        from trait_tokenizer import key_features_to_trait_tokens
                        key_features = r.payload.get("key_features", [])
                        if key_features and isinstance(key_features, list):
                            plant_trait_tokens = key_features_to_trait_tokens(key_features)
                except (ImportError, Exception):
                    plant_trait_tokens = []
            
            # å–å¾—æ­£è¦åŒ–å¾Œçš„ key_features_normï¼ˆD. åªä¿ç•™åˆæ³• FEATURE_VOCABï¼Œé¿å…äº‚ç¢¼å°è‡´åŒ¹é…å¤±çœŸï¼‰
            plant_key_features_norm = r.payload.get("key_features_norm", [])
            if plant_key_features_norm and FEATURE_INDEX:
                plant_key_features_norm = [
                    x for x in plant_key_features_norm
                    if isinstance(x, str) and x.strip() and x in FEATURE_INDEX and "\ufffd" not in x
                ]
            if not plant_key_features_norm:
                try:
                    from pathlib import Path
                    normalize_path = Path(__file__).parent / "normalize_features.py"
                    if normalize_path.exists():
                        from normalize_features import normalize_features
                        key_features = r.payload.get("key_features", [])
                        if key_features and isinstance(key_features, list):
                            plant_key_features_norm = normalize_features(key_features)
                except (ImportError, Exception):
                    plant_key_features_norm = []
            
            # å–å¾—æ¤ç‰©çš„æè¿°æ–‡å­—ï¼ˆpayload æ¬„ä½å¯èƒ½ç‚º str æˆ– listï¼Œçµ±ä¸€è½‰æˆ strï¼‰
            def _to_str(v):
                if v is None:
                    return ""
                if isinstance(v, list):
                    return " ".join(str(x) for x in v if x is not None)
                return str(v)

            key_features = r.payload.get("key_features", [])
            key_features_text = ""
            if key_features:
                if isinstance(key_features, list):
                    key_features_text = " ".join([str(kf) for kf in key_features])
                else:
                    key_features_text = str(key_features)

            # ç´å…¥ raw_data çš„ morphologyï¼ˆè‹”è˜šé¡ç­‰ payload ç„¡ morphology æ™‚ï¼Œraw å« å…¨ç·£/é‹¸é½’ ç­‰ï¼‰
            raw = r.payload.get("raw_data") or {}
            raw_morph = _to_str(raw.get("raw_data", {}).get("morphology", ""))
            ident = raw.get("identification", {})
            ident_morph = _to_str(ident.get("morphology", []))
            ident_summary = _to_str(ident.get("summary", ""))

            plant_text = " ".join(filter(None, [
                _to_str(r.payload.get("summary")),
                _to_str(r.payload.get("life_form")),
                _to_str(r.payload.get("morphology")),
                key_features_text,
                raw_morph,
                ident_morph,
                ident_summary,
            ]))

            # è¨ˆç®—ç‰¹å¾µåŒ¹é…
            match_result = feature_calculator.match_plant_features(
                features, 
                plant_text=plant_text, 
                plant_trait_tokens=plant_trait_tokens,
                plant_key_features_norm=plant_key_features_norm
            )
            feature_score_raw = match_result["match_score"]
            matched_features = [f["name"] for f in match_result["matched_features"]]
            missing_features = [f["name"] for f in match_result.get("missing_features", [])]
            coverage = match_result.get("coverage", 1.0)
            must_matched = match_result.get("must_matched", True)
            
            # Feature score æ¨™æº–åŒ–ï¼šmatched / query_total æ‹‰é–‹å·®è·ï¼ˆ0~1ï¼‰
            if query_total_weight > 0:
                feature_score = min(1.0, feature_score_raw / query_total_weight)
            else:
                feature_score = feature_score_raw * coverage
            
            # ğŸ”¥ é˜²é£½å’Œæ©Ÿåˆ¶ï¼šç•¶ Query traits å¤ªå°‘æ™‚ï¼Œfeature_score ä¸Šé™å°é ‚
            # é¿å…ã€Œ3 å€‹ç‰¹å¾µå°±æ»¿åˆ†ã€å°è‡´éŒ¯èª¤å€™é¸éœ¸æ¦œï¼ˆå¦‚é¦¬çº“ä¸¹ case ä¸­æ°´æ¼† 100%ï¼‰
            if features:
                trait_count = len(features)
                # å¦‚æœ traits < 4ï¼Œfeature_score ä¸Šé™éæ¸›
                if trait_count < 4:
                    max_feature_score = 0.55 + (trait_count - 1) * 0.15  # 1å€‹â†’0.55, 2å€‹â†’0.70, 3å€‹â†’0.85
                    if feature_score > max_feature_score:
                        feature_score = max_feature_score
                        print(f"[API] é˜²é£½å’Œ: Query åªæœ‰ {trait_count} å€‹ç‰¹å¾µï¼Œfeature_score å°é ‚ç‚º {max_feature_score:.2f}")
                elif trait_count == 4:
                    # 4 å€‹ç‰¹å¾µæ™‚ï¼Œä¸Šé™ç‚º 0.90
                    if feature_score > 0.90:
                        feature_score = 0.90
                # 5 å€‹ä»¥ä¸Šç‰¹å¾µæ™‚ï¼Œå…è¨±é”åˆ° 1.0
        else:
            feature_score = 0.0
            coverage = 0.0
            must_matched = True
            matched_features = []
            match_result = {}

        # æš«å­˜çµæœï¼Œç¨å¾Œé€²è¡Œéæ¿¾å’Œæ’åº
        hard_reject = match_result.get("hard_reject", False)
        scored_candidates.append({
            "point": r,
            "embedding_score": embedding_score,
            "feature_score": feature_score,
            "keyword_bonus": keyword_bonus,
            "coverage": coverage,
            "must_matched": must_matched,
            "hard_reject": hard_reject,
            "match_result": match_result,
            "matched_features": matched_features,
            "plant_name": r.payload.get("chinese_name", "æœªçŸ¥"),
            "scientific_name": r.payload.get("scientific_name", "")
        })

    # Must Gate ç¡¬æ·˜æ±°ï¼šæ’é™¤å¼·å€è¾¨ç‰¹å¾µå®Œå…¨ä¸åŒ¹é…çš„å€™é¸
    before_gate = len(scored_candidates)
    final_candidates = [c for c in scored_candidates if not c.get("hard_reject")]
    rejected = before_gate - len(final_candidates)
    if rejected > 0:
        print(f"[API] Must Gate ç¡¬æ·˜æ±°: æ’é™¤ {rejected} å€‹å€™é¸ï¼ˆå¼·ç‰¹å¾µå®Œå…¨ä¸åŒ¹é…ï¼‰ï¼Œå‰© {len(final_candidates)} å€‹")

    # B. é«˜ embedding æ™‚ç¶­æŒå›ºå®šæ¬Šé‡ï¼Œä¸å†æé«˜ feature æ¯”ä¾‹ï¼ˆè¨­è¨ˆï¼šembedding ç‚ºä¸»ï¼‰
    max_emb = max((c["embedding_score"] for c in final_candidates), default=0)
    if max_emb >= 0.75:
        print(f"[API] é«˜ embedding å€™é¸ max_emb={max_emb:.2f}ï¼Œç¶­æŒ E:{embedding_weight:.2f}/F:{effective_feature_weight:.2f}")

    # éåº¦é€šç”¨ç‰©ç¨®æ‡²ç½°ï¼šåŒ¹é…ç‰¹å¾µæ•¸é é«˜æ–¼ä¸­ä½æ•¸è€…ï¼ˆè³‡æ–™å¯«å¤ªé›œã€ç™¾ç§‘å‹ï¼‰ç•¥é™æ¬Šï¼Œé¿å…éœ¸æ¦œ
    matched_counts = [len(c.get("matched_features") or []) for c in final_candidates]
    median_matched = sorted(matched_counts)[len(matched_counts) // 2] if matched_counts else 0

    # è¨ˆç®—æœ€çµ‚åˆ†æ•¸ä¸¦æ’åº
    for c in final_candidates:
        r = c["point"]
        embedding_score = c["embedding_score"]
        feature_score = c["feature_score"]
        keyword_bonus = c["keyword_bonus"]
        match_result = c["match_result"]
        
        # ç´” Gate æ¨¡å¼ï¼šä»¥ embedding ç‚ºåŸºæº–ï¼Œä¸åšä»»ä½•æ­£å‘åŠ åˆ†
        # è¨­è¨ˆç›®æ¨™ï¼šå¯§å¯å°‘å‡ºæ‰‹ï¼Œä¹Ÿä¸è¦æŠŠéŒ¯çš„ç‰©ç¨®æ¨åˆ° Top1
        hybrid_score = embedding_score
        
        # æ‡‰ç”¨ Must Gate æ‡²ç½°ï¼ˆè»Ÿæ€§é™æ¬Šï¼Œè€Œééæ¿¾ï¼‰
        # å¦‚æœé—œéµç‰¹å¾µä¸åŒ¹é…ï¼Œåˆ†æ•¸æ‰“æŠ˜ï¼Œä½†ä»ç„¶ä¿ç•™åœ¨åˆ—è¡¨ä¸­
        if not c["must_matched"]:
            # ğŸ”¥ é—œéµä¿®å¾©ï¼šåŠ é‡æ‡²ç½°ï¼Œå¾ 0.5 (5æŠ˜) æ”¹ç‚º 0.3 (3æŠ˜)
            # é€™æ¨£å¯ä»¥é¿å…å–¬æœ¨å› ç‚º Embedding ç›¸ä¼¼è€Œæ’åœ¨æ­£ç¢ºè‰æœ¬ï¼ˆä½† Embedding ç¨ä½ï¼‰çš„å‰é¢
            # ä½†ä»ä¿ç•™ã€Œå®Œå…¨æ‰¾ä¸åˆ°æ™‚ï¼Œè‡³å°‘çµ¦å€‹çµæœã€çš„é€€è·¯
            MUST_GATE_PENALTY = 0.3
            hybrid_score *= MUST_GATE_PENALTY
            # åƒ…åœ¨åˆ†æ•¸è¼ƒé«˜æ™‚é¡¯ç¤ºæ—¥èªŒï¼Œé¿å…åˆ·å±
            if hybrid_score > 0.4:
                print(f"[API] âš ï¸ Must Gate æ‡²ç½°: {c['plant_name']} - é—œéµç‰¹å¾µä¸åŒ¹é…ï¼Œåˆ†æ•¸å¤§å¹…é™æ¬Š (x0.3)")

        # Gate-Aï¼šæ£•æ«š/è¤‡è‘‰ gateï¼ˆquery æœ‰è¤‡è‘‰/æ£•æ«šå‰‡å€™é¸éœ€æœ‰ï¼Œå¦å‰‡é™æ¬Šï¼‰
        query_has_palm_compound = (
            (features and any(f in PALM_COMPOUND_QUERY_TOKENS for f in features))
            or ("æ£•æ«š" in (query or ""))
        )
        gate_triggered = query_has_palm_compound
        has_palm = _plant_has_palm_compound(r.payload)
        before_score = hybrid_score
        # P1: å‹•æ…‹å¼·åº¦ - ç¾½ç‹€è¤‡è‘‰+æ£•æ«š ç”¨ 0.25ï¼Œå…¶ä»–å¼·è¤‡è‘‰ 0.35ï¼Œæ³›ç”¨ 0.6
        STRONG_PALM_TOKENS = frozenset({"ç¾½ç‹€è¤‡è‘‰", "æŒç‹€è¤‡è‘‰", "äºŒå›ç¾½ç‹€", "ä¸‰å‡ºè¤‡è‘‰"})
        has_strong = bool(features and any(f in STRONG_PALM_TOKENS for f in features))
        has_palm_in_query = bool(features and "æ£•æ«š" in features)
        if has_strong and has_palm_in_query:
            gate_penalty = 0.25  # é»ƒæ¤°å­ç­‰ï¼šquery æ˜ç¢ºæœ‰ç¾½ç‹€è¤‡è‘‰+æ£•æ«šï¼Œéæ£•æ«šå€™é¸é‡ç½°
        elif has_strong:
            gate_penalty = 0.35
        else:
            gate_penalty = 0.6
        if gate_triggered and not has_palm:
            hybrid_score *= gate_penalty
        if gate_triggered:
            print(f"[API] Gate-A debug {c['plant_name']}: has_palm={has_palm} penalty={gate_penalty} before={before_score:.4f} after={hybrid_score:.4f}")
        if gate_triggered and not has_palm and hybrid_score > 0.3:
            print(f"[API] Gate-A æ£•æ«š/è¤‡è‘‰é™æ¬Š: {c['plant_name']} - ç„¡è¤‡è‘‰/æ£•æ«šæè¿° (x{gate_penalty})")

        # Gate-A é€†é‚è¼¯ï¼šquery ç„¡æ£•æ«š/è¤‡è‘‰è­‰æ“šæ™‚ï¼Œæ£•æ«šå€™é¸é‡ç½°ï¼ˆé¿å…é³¥å°¾èŠ±/ä¹é‡è‘›/è¿·è¿­é¦™ç­‰ä¸€ç›´è¢«æ£•æ¨¹éœ¸æ¦œï¼‰
        if not query_has_palm_compound and has_palm:
            hybrid_score *= 0.18
            if hybrid_score > 0.2:
                print(f"[API] Gate-A é€†ï¼š{c['plant_name']} - æŸ¥è©¢ç„¡æ£•æ«š/è¤‡è‘‰ï¼Œæ£•æ«šå€™é¸é™æ¬Š (x0.18)")

        # SOFT çŸ›ç›¾é‡ç½°ï¼šlife_form / leaf_arrangement / flower_color ä¸ä¸€è‡´æ™‚æ‰£åˆ†ï¼ˆå–æœ€åš´é‡ 2 æ¢ï¼‰
        if traits:
            soft_penalties = compute_soft_contradiction_penalty(traits, r.payload)
            if soft_penalties:
                total_penalty = sum(p for _, p in soft_penalties)
                hybrid_score = max(0.0, hybrid_score - total_penalty)
                if hybrid_score > 0.2:
                    print(f"[API] SOFT çŸ›ç›¾æ‡²ç½°: {c['plant_name']} - {[rid for rid, _ in soft_penalties]}, å…±æ‰£ {total_penalty:.2f}")

        # è•¨è‹”è˜š vs ç¨®å­æ¤ç‰© Gateï¼šæŸ¥è©¢ç‚ºç¨®å­æ¤ç‰©ï¼ˆçŒæœ¨/è‰æœ¬/èŠ±/å–¬æœ¨ï¼‰æ™‚ï¼Œè‹”è˜šè•¨é¡å¼·é™æ¬Šï¼Œåˆ†é–‹å¤§é¡é¿å…èª¤åŒ¹é…
        query_has_bryo_fern = bool(query and ("è‹”" in query or "è˜š" in query or "è•¨" in query))
        query_features_str = " ".join(features or [])
        if not query_has_bryo_fern and ("è‹”" in query_features_str or "è˜š" in query_features_str or "è•¨" in query_features_str):
            query_has_bryo_fern = True
        if not query_has_bryo_fern and _is_bryophyte_pteridophyte(r.payload):
            hybrid_score *= 0.06
            if hybrid_score > 0.15:
                print(f"[API] è•¨è‹”è˜š Gate: {c['plant_name']} - æŸ¥è©¢ç‚ºç¨®å­æ¤ç‰©ï¼Œè‹”è˜šè•¨é¡å¼·é™æ¬Š (x0.06)")

        # è³‡æ–™å“è³ªé™æ¬Šï¼šä½å“è³ªç­†ï¼ˆç¼ºä¹æè¿°ã€æ¨æ¸¬ç­‰ï¼‰ä¹˜ quality_score
        qs = r.payload.get("quality_score")
        if qs is not None and isinstance(qs, (int, float)) and 0 < qs < 1:
            hybrid_score *= qs

        # éåº¦é€šç”¨ç‰©ç¨®æ‡²ç½°ï¼šåŒ¹é…æ•¸é é«˜æ–¼ä¸­ä½æ•¸ï¼ˆç™¾ç§‘å‹æ¢ç›®ï¼‰ç•¥é™æ¬Šï¼Œæ‰“æ‰é’çš®æœ¨å¼éœ¸æ¦œ
        n_matched = len(c.get("matched_features") or [])
        if median_matched and n_matched > max(median_matched * 2, 6):
            hybrid_score *= 0.95
            if hybrid_score > 0.3:
                print(f"[API] éåº¦é€šç”¨æ‡²ç½°: {c['plant_name']} - åŒ¹é…æ•¸ {n_matched} > 2*ä¸­ä½æ•¸ {median_matched} (x0.95)")
        
        # ç¢ºä¿åˆ†æ•¸ä¸è¶…é 1.0
        hybrid_score = min(1.0, hybrid_score)
        
        # è¨˜éŒ„çµæœ
        results.append({
            "code": r.payload.get("code"),
            "chinese_name": r.payload.get("chinese_name"),
            "scientific_name": r.payload.get("scientific_name"),
            "family": r.payload.get("family"),
            "family_en": r.payload.get("family_en"),
            "genus": r.payload.get("genus"),
            "life_form": r.payload.get("life_form"),
            "score": hybrid_score,
            "embedding_score": embedding_score,
            "feature_score": feature_score,
            "coverage": c["coverage"],
            "must_matched": c["must_matched"],
            "matched_features": c["matched_features"],
            "summary": r.payload.get("summary", "")[:300],
        })

    # è¬ç”¨æ¢ç›®è¼•åº¦é™æ¬Šï¼šå¸¸éŒ¯ç•¶ Top1 çš„ç‰©ç¨® Ã—0.88ï¼Œæ¸›å°‘éœ¸æ¦œã€è®“æ­£è§£æœ‰æ©Ÿæœƒè¶…å‰
    apply_generic_top1_penalty(results)

    # 4. æŒ‰æ··åˆåˆ†æ•¸é‡æ–°æ’åº
    results.sort(key=lambda x: x["score"], reverse=True)
    
    # è¨˜éŒ„æœ€çµ‚çµæœï¼ˆTop Kï¼‰
    print(f"\n[API] ğŸ” æ··åˆæœå°‹çµæœï¼ˆTop {top_k}ï¼‰ï¼š")
    for i, result in enumerate(results[:top_k], 1):
        plant_name = result.get("chinese_name", "æœªçŸ¥")
        scientific_name = result.get("scientific_name", "")
        score = result.get("score", 0.0)
        embedding_score = result.get("embedding_score", 0.0)
        feature_score = result.get("feature_score", 0.0)
        matched_features = result.get("matched_features", [])
        print(f"  {i}. {plant_name}" + (f" ({scientific_name})" if scientific_name else "") + f" - ç¸½åˆ†={score:.3f} (embedding={embedding_score:.3f}, feature={feature_score:.3f}), åŒ¹é…ç‰¹å¾µ={matched_features}")
    print()  # ç©ºè¡Œåˆ†éš”
    sys.stdout.flush()

    return results[:top_k]


def smart_search(query: str, top_k: int = 5):
    """
    æ™ºæ…§æœå°‹ï¼šå…ˆåˆ†é¡ï¼Œåªæœ‰æ¤ç‰©ç›¸é—œæ‰æœå°‹
    """
    classification = classify_query(query)

    result = {
        "query": query,
        "classification": classification,
        "results": []
    }

    if classification["is_plant"]:
        result["results"] = search_plants(query, top_k)
        result["message"] = f"è­˜åˆ¥ç‚ºæ¤ç‰©ç›¸é—œæŸ¥è©¢ (ä¿¡å¿ƒåº¦: {classification['plant_score']:.2f})"
    else:
        result["message"] = f"éæ¤ç‰©ç›¸é—œæŸ¥è©¢ï¼Œè­˜åˆ¥ç‚º: {classification['category']} (ä¿¡å¿ƒåº¦: {classification['confidence']:.2f})"

    return result


class RequestHandler(BaseHTTPRequestHandler):
    def _send_json(self, data, status=200):
        self.send_response(status)
        self.send_header("Content-Type", "application/json; charset=utf-8")
        self.send_header("Access-Control-Allow-Origin", "*")
        self.send_header("Access-Control-Allow-Methods", "GET, POST, OPTIONS")
        self.send_header("Access-Control-Allow-Headers", "Content-Type")
        self.end_headers()
        self.wfile.write(json.dumps(data, ensure_ascii=False).encode("utf-8"))

    def do_OPTIONS(self):
        self.send_response(200)
        self.send_header("Access-Control-Allow-Origin", "*")
        self.send_header("Access-Control-Allow-Methods", "GET, POST, OPTIONS")
        self.send_header("Access-Control-Allow-Headers", "Content-Type")
        self.end_headers()

    def do_GET(self):
        parsed = urlparse(self.path)

        if parsed.path == "/health":
            # æª¢æŸ¥ embedding æ˜¯å¦å¯ç”¨ï¼ˆæœ¬åœ°æ¨¡å‹æˆ– Jina APIï¼‰
            embedding_ready = model is not None or (USE_JINA_API and JINA_API_KEY)

            self._send_json({
                "ok": True,
                "status": "ok",
                "model": EMBEDDING_MODEL,
                "use_jina_api": USE_JINA_API,
                "jina_api_configured": JINA_API_KEY is not None,
                "model_loaded": model is not None,
                "qdrant_connected": qdrant_client is not None,
                "qdrant_url": QDRANT_URL,
                "ready": embedding_ready and qdrant_client is not None
            })

        elif parsed.path == "/stats":
            # å›å‚³ Qdrant collection ç‹€æ…‹ï¼Œç¢ºèªå‘é‡ç´¢å¼•æ˜¯å¦çœŸçš„å»ºå¥½äº†
            if qdrant_client is None:
                self._send_json({
                    "ok": False,
                    "error": "Qdrant not connected",
                    "collection": COLLECTION_NAME,
                    "qdrant_url": QDRANT_URL,
                }, 503)
                return

            try:
                info = qdrant_client.get_collection(collection_name=COLLECTION_NAME)
                count = qdrant_client.count(collection_name=COLLECTION_NAME, exact=True)

                # vectors è¨­å®šè³‡è¨Šï¼ˆä¸åŒç‰ˆæœ¬çš„ qdrant_client å¯èƒ½çµæ§‹ç¨ä¸åŒï¼Œé€™è£¡åšä¿å®ˆè™•ç†ï¼‰
                vectors_cfg = getattr(info, "config", None)
                vectors_cfg = getattr(vectors_cfg, "params", None) if vectors_cfg else None
                vectors_cfg = getattr(vectors_cfg, "vectors", None) if vectors_cfg else None

                self._send_json({
                    "ok": True,
                    "collection": COLLECTION_NAME,
                    "points_count": getattr(count, "count", None),
                    "vectors_config": str(vectors_cfg) if vectors_cfg is not None else None,
                    "qdrant_url": QDRANT_URL,
                })
            except Exception as e:
                self._send_json({
                    "ok": False,
                    "error": str(e),
                    "collection": COLLECTION_NAME,
                    "qdrant_url": QDRANT_URL,
                }, 500)

        elif parsed.path == "/vision-prompt":
            # å–å¾— Vision AI ç”¨çš„çµæ§‹åŒ– Prompt
            self._send_json({
                "prompt": get_vision_prompt(),
                "feature_vocab": list(FEATURE_INDEX.keys())
            })

        elif parsed.path == "/search":
            params = parse_qs(parsed.query)
            query = params.get("q", [""])[0]
            top_k = int(params.get("top_k", [5])[0])
            smart = params.get("smart", ["true"])[0].lower() == "true"

            if not query:
                self._send_json({"error": "Missing query parameter 'q'"}, 400)
                return

            if smart:
                result = smart_search(query, top_k)
            else:
                result = {"query": query, "results": search_plants(query, top_k)}

            self._send_json(result)

        elif parsed.path == "/classify":
            params = parse_qs(parsed.query)
            query = params.get("q", [""])[0]

            if not query:
                self._send_json({"error": "Missing query parameter 'q'"}, 400)
                return

            result = classify_query(query)
            result["query"] = query
            self._send_json(result)

        else:
            self._send_json({"error": "Not found"}, 404)

    def do_POST(self):
        parsed = urlparse(self.path)
        content_length = int(self.headers.get("Content-Length", 0))
        body = self.rfile.read(content_length).decode("utf-8")

        try:
            data = json.loads(body) if body else {}
        except json.JSONDecodeError:
            self._send_json({"error": "Invalid JSON"}, 400)
            return

        if parsed.path == "/search":
            query = data.get("query", "")
            top_k = data.get("top_k", 5)
            smart = data.get("smart", True)

            if not query:
                self._send_json({"error": "Missing 'query' field"}, 400)
                return

            if smart:
                result = smart_search(query, top_k)
            else:
                result = {"query": query, "results": search_plants(query, top_k)}

            self._send_json(result)

        elif parsed.path == "/classify":
            query = data.get("query", "")

            if not query:
                self._send_json({"error": "Missing 'query' field"}, 400)
                return

            result = classify_query(query)
            result["query"] = query
            self._send_json(result)

        elif parsed.path == "/hybrid-search":
            # æ··åˆæœå°‹ï¼šçµåˆ embedding + ç‰¹å¾µæ¬Šé‡
            query = data.get("query", "")
            features = data.get("features", []) or []
            guess_names = data.get("guess_names", []) or []
            top_k = data.get("top_k", 5)
            requested_weights = data.get("weights")
            embedding_weight, feature_weight = resolve_weights(requested_weights)
            print(f"[API] POST /hybrid-search æ”¶åˆ°: query_len={len(query) if query else 0}, features={len(features)}, guess_names={len(guess_names)}, top_k={top_k}")
            sys.stdout.flush()

            if not query and not features and not guess_names:
                print(f"[API] POST /hybrid-search 400: ç¼ºå°‘ query/features/guess_names (body keys: {list(data.keys())})")
                sys.stdout.flush()
                self._send_json({"error": "Missing 'query', 'features', or 'guess_names'"}, 400)
                return

            # è¨ˆç®—ç‰¹å¾µç¸½åˆ†ï¼ˆç”¨æ–¼ä¿¡å¿ƒåº¦ï¼‰èˆ‡æ··åˆæœå°‹ï¼›ä»»ä½•ä¾‹å¤–éƒ½å›å‚³ 500 é¿å…é€£ç·š EOF
            feature_info = None
            try:
                if features and feature_calculator:
                    feature_info = feature_calculator.calculate_feature_score(features)

                traits = data.get("traits")
                results = hybrid_search(
                    query=query or " ".join(guess_names),
                    features=features,
                    guess_names=guess_names,
                    top_k=top_k,
                    weights={
                        "embedding": embedding_weight,
                        "feature": feature_weight
                    },
                    traits=traits
                )

                self._send_json({
                    "query": query,
                    "features": features,
                    "guess_names": guess_names,
                    "feature_info": feature_info,
                    "results": results,
                    "weights": {
                        "embedding": embedding_weight,
                        "feature": feature_weight
                    }
                })
            except Exception as e:
                print(f"[API] POST /hybrid-search 500: {e}")
                import traceback
                traceback.print_exc()
                sys.stdout.flush()
                self._send_json({
                    "error": str(e),
                    "query": query,
                    "features": features,
                    "guess_names": guess_names,
                    "feature_info": feature_info,
                    "results": [],
                    "weights": {"embedding": embedding_weight, "feature": feature_weight}
                }, 500)

        else:
            self._send_json({"error": "Not found"}, 404)

    def log_message(self, format, *args):
        # Zeabur æœƒé »ç¹æ‰“ health checkï¼Œé¿å…æ—¥èªŒåˆ·å±è®“äººèª¤ä»¥ç‚ºã€Œç„¡é™å¾ªç’°ã€
        try:
            if getattr(self, "path", "").startswith("/health"):
                return
        except Exception:
            pass
        print(f"[API] {args[0]}")


class ThreadedHTTPServer(ThreadingMixIn, HTTPServer):
    """å¤šåŸ·è¡Œç·’ HTTP æœå‹™ï¼Œé¿å…å–®ä¸€è«‹æ±‚å¡ä½æˆ–å´©æ½°å°è‡´å…¶ä»–é€£ç·š EOF"""
    pass


def main():
    try:
        init()

        server = ThreadedHTTPServer(("0.0.0.0", API_PORT), RequestHandler)
        print(f"\nğŸŒ¿ æ¤ç‰©å‘é‡æœå°‹ API å•Ÿå‹•")
        print(f"   http://localhost:{API_PORT}")
        print(f"\nç«¯é»ï¼š")
        print(f"   GET  /health")
        print(f"   GET  /vision-prompt          - å–å¾— Vision AI çµæ§‹åŒ– Prompt")
        print(f"   GET  /classify?q=ç´…è‰²çš„èŠ±")
        print(f"   GET  /search?q=ç´…è‰²çš„èŠ±&top_k=5&smart=true")
        print(f"   POST /search       {{\"query\": \"...\", \"top_k\": 5, \"smart\": true}}")
        print(f"   POST /classify     {{\"query\": \"...\"}}")
        print(f"   POST /hybrid-search {{\"query\": \"...\", \"features\": [...], \"guess_names\": [...]}}")
        print(f"\nEmbedding æ–¹å¼: {'Jina AI API' if USE_JINA_API else 'æœ¬åœ°æ¨¡å‹'}")
        print(f"æ··åˆæœå°‹æ¬Šé‡: embedding={EMBEDDING_WEIGHT}, feature={FEATURE_WEIGHT}")
        print(f"æ¤ç‰©åˆ¤æ–·é–¾å€¼: {PLANT_THRESHOLD}")
        print(f"\næŒ‰ Ctrl+C åœæ­¢...")
        sys.stdout.flush()

        try:
            server.serve_forever()
        except KeyboardInterrupt:
            print("\nåœæ­¢æœå‹™")
            server.shutdown()

    except Exception as e:
        print(f"âŒ è‡´å‘½éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        sys.stdout.flush()

        # ä¿æŒå®¹å™¨é‹è¡Œï¼Œä¸è¦é€€å‡º
        print("\nâš ï¸  æœå‹™ç™¼ç”ŸéŒ¯èª¤ï¼Œä½†ä¿æŒé‹è¡Œä»¥ä¾¿æª¢æŸ¥æ—¥èªŒ")
        print("   å®¹å™¨å°‡ä¿æŒé‹è¡Œç‹€æ…‹...")
        sys.stdout.flush()

        import time
        while True:
            time.sleep(60)


if __name__ == "__main__":
    main()
