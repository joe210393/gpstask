#!/usr/bin/env python3
"""
ç‚ºè³‡æ–™åº«ç”Ÿæˆ morphology_summary å’Œ trait_tokens

åŠŸèƒ½ï¼š
1. å¾åŸå§‹è³‡æ–™æå–ä¸¦ç”Ÿæˆ morphology_summary_zhï¼ˆä¹¾æ·¨çš„æ‘˜è¦ï¼‰
2. å¾ key_features ç”Ÿæˆ trait_tokensï¼ˆæ¨™æº–åŒ–ï¼‰
3. è¼¸å‡ºæ›´æ–°å¾Œçš„ JSONL æª”æ¡ˆ
"""

import json
import re
from pathlib import Path
from typing import Dict, Any, List
from trait_tokenizer import key_features_to_trait_tokens

# è¼¸å…¥å’Œè¼¸å‡ºæª”æ¡ˆ
INPUT_JSONL = Path(__file__).parent.parent / "data" / "plants-forest-gov-tw.jsonl"
OUTPUT_JSONL = Path(__file__).parent.parent / "data" / "plants-forest-gov-tw-enhanced.jsonl"


def extract_morphology_summary(plant: Dict[str, Any]) -> str:
    """
    å¾æ¤ç‰©è³‡æ–™æå– morphology_summary
    
    ç­–ç•¥ï¼š
    1. å„ªå…ˆä½¿ç”¨ identification.summaryï¼ˆå¦‚æœå­˜åœ¨ä¸”å®Œæ•´ï¼‰
    2. å…¶æ¬¡å¾ identification.morphology æå–é—œéµè³‡è¨Š
    3. æœ€å¾Œå¾ raw_data.morphology æå–
    """
    identification = plant.get("identification", {})
    if not isinstance(identification, dict):
        return ""
    
    # 1. å„ªå…ˆä½¿ç”¨ summary
    summary = identification.get("summary")
    if summary:
        if isinstance(summary, list):
            summary = " ".join(summary)
        # æ¸…ç† summaryï¼šç§»é™¤å†—é•·æè¿°ï¼Œä¿ç•™é—œéµç‰¹å¾µ
        summary = clean_summary(summary)
        if len(summary) > 50:  # ç¢ºä¿æœ‰è¶³å¤ å…§å®¹
            return summary
    
    # 2. å¾ morphology æå–
    morphology = identification.get("morphology")
    if morphology:
        if isinstance(morphology, list):
            morphology_text = " ".join(morphology)
        else:
            morphology_text = str(morphology)
        
        # æå–é—œéµè³‡è¨Š
        summary = extract_key_info(morphology_text)
        if summary:
            return summary
    
    # 3. å¾ raw_data.morphology æå–
    raw_data = plant.get("raw_data", {})
    if isinstance(raw_data, dict):
        raw_morphology = raw_data.get("morphology")
        if raw_morphology:
            summary = extract_key_info(raw_morphology)
            if summary:
                return summary
    
    return ""


def clean_summary(text: str) -> str:
    """æ¸…ç†æ‘˜è¦ï¼šç§»é™¤å†—é•·æè¿°ï¼Œä¿ç•™é—œéµç‰¹å¾µ"""
    if not text:
        return ""
    
    # ç§»é™¤å¸¸è¦‹çš„å†—é•·æè¿°
    text = re.sub(r"å»£æ³›åˆ†å¸ƒæ–¼.*?ã€‚", "", text)
    text = re.sub(r"åŸç”¢æ–¼.*?ã€‚", "", text)
    text = re.sub(r"åˆ†å¸ƒæ–¼.*?ã€‚", "", text)
    text = re.sub(r"å¸¸è¦‹æ–¼.*?ã€‚", "", text)
    
    # ä¿ç•™é—œéµç‰¹å¾µæè¿°
    # æå–ï¼šç”Ÿæ´»å‹ã€è‘‰ã€èŠ±ã€æœå¯¦ç­‰é—œéµè³‡è¨Š
    sentences = text.split("ã€‚")
    key_sentences = []
    
    for sent in sentences:
        sent = sent.strip()
        if not sent:
            continue
        
        # ä¿ç•™åŒ…å«é—œéµç‰¹å¾µçš„å¥å­
        if any(keyword in sent for keyword in [
            "ç”Ÿæ´»å‹", "å–¬æœ¨", "çŒæœ¨", "è‰æœ¬", "è—¤æœ¬",
            "è‘‰", "èŠ±", "æœå¯¦", "èŠ±åº", "è‘‰åº", "è‘‰å½¢", "è‘‰ç·£"
        ]):
            key_sentences.append(sent)
    
    if key_sentences:
        return "ã€‚".join(key_sentences[:5])  # æœ€å¤š 5 å¥
    else:
        return text[:200]  # å¦‚æœæ²’æœ‰é—œéµå¥å­ï¼Œå–å‰ 200 å­—


def extract_key_info(text: str) -> str:
    """å¾åŸå§‹ morphology æ–‡å­—æå–é—œéµè³‡è¨Š"""
    if not text:
        return ""
    
    # æå–é—œéµå¥å­
    sentences = text.split("ã€‚")
    key_sentences = []
    
    for sent in sentences:
        sent = sent.strip()
        if not sent:
            continue
        
        # ä¿ç•™åŒ…å«å½¢æ…‹ç‰¹å¾µçš„å¥å­
        if any(keyword in sent for keyword in [
            "ç”Ÿæ´»å‹", "å–¬æœ¨", "çŒæœ¨", "è‰æœ¬", "è—¤æœ¬",
            "è‘‰", "èŠ±", "æœå¯¦", "èŠ±åº", "è‘‰åº", "è‘‰å½¢", "è‘‰ç·£",
            "äº’ç”Ÿ", "å°ç”Ÿ", "è¼ªç”Ÿ", "åµå½¢", "æ©¢åœ“å½¢", "æŠ«é‡å½¢"
        ]):
            key_sentences.append(sent)
    
    if key_sentences:
        return "ã€‚".join(key_sentences[:5])
    else:
        return text[:200]


def process_plant(plant: Dict[str, Any]) -> Dict[str, Any]:
    """è™•ç†å–®ç­†æ¤ç‰©è³‡æ–™ï¼Œç”Ÿæˆ morphology_summary å’Œ trait_tokens"""
    # ç”Ÿæˆ morphology_summary
    morphology_summary = extract_morphology_summary(plant)
    
    # ç”Ÿæˆ trait_tokens
    identification = plant.get("identification", {})
    key_features = []
    if isinstance(identification, dict):
        kf = identification.get("key_features", [])
        if isinstance(kf, list):
            key_features = kf
        elif kf:
            key_features = [kf]
    
    trait_tokens = key_features_to_trait_tokens(key_features)
    
    # æ›´æ–° identification
    if not isinstance(identification, dict):
        identification = {}
    
    if morphology_summary:
        identification["morphology_summary_zh"] = morphology_summary
    
    if trait_tokens:
        identification["trait_tokens"] = trait_tokens
    
    plant["identification"] = identification
    
    return plant


def main():
    """ä¸»å‡½æ•¸ï¼šè™•ç†æ‰€æœ‰æ¤ç‰©è³‡æ–™"""
    print(f"ğŸ“– è®€å–è³‡æ–™ï¼š{INPUT_JSONL}")
    
    if not INPUT_JSONL.exists():
        print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨ï¼š{INPUT_JSONL}")
        return
    
    processed_count = 0
    total_count = 0
    
    with INPUT_JSONL.open("r", encoding="utf-8") as f_in, \
         OUTPUT_JSONL.open("w", encoding="utf-8") as f_out:
        
        for line in f_in:
            line = line.strip()
            if not line:
                continue
            
            # è™•ç† JSON è¡Œå°¾é€—è™Ÿ
            if line.endswith(","):
                line = line[:-1]
            
            try:
                plant = json.loads(line)
                total_count += 1
                
                # è™•ç†æ¤ç‰©è³‡æ–™
                plant_enhanced = process_plant(plant)
                
                # å¯«å…¥è¼¸å‡ºæª”æ¡ˆ
                f_out.write(json.dumps(plant_enhanced, ensure_ascii=False) + "\n")
                processed_count += 1
                
                if processed_count % 100 == 0:
                    print(f"  å·²è™•ç† {processed_count} ç­†...")
            
            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSON è§£æéŒ¯èª¤ï¼ˆè·³éï¼‰ï¼š{e}")
                continue
    
    print(f"\nâœ… å®Œæˆï¼")
    print(f"   ç¸½æ•¸ï¼š{total_count}")
    print(f"   æˆåŠŸï¼š{processed_count}")
    print(f"   è¼¸å‡ºï¼š{OUTPUT_JSONL}")
    print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥ï¼š")
    print(f"   1. æª¢æŸ¥è¼¸å‡ºæª”æ¡ˆï¼š{OUTPUT_JSONL}")
    print(f"   2. å¦‚æœæ»¿æ„ï¼Œå¯ä»¥æ›¿æ›åŸæª”æ¡ˆæˆ–é‡æ–°å‘é‡åŒ–")


if __name__ == "__main__":
    main()
