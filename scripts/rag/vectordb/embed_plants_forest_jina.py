#!/usr/bin/env python3
"""
æ¤ç‰©è³‡æ–™å‘é‡åŒ–è…³æœ¬ï¼ˆæ”¯æ´ Jina API æˆ–æœ¬æ©Ÿæ¨¡å‹ï¼‰
é©é…æ–°çš„ plants-forest-gov-tw.jsonl æ ¼å¼

**é‡è¦ï¼š**
- USE_JINA_API=true æœƒä½¿ç”¨ Jina APIï¼ˆæœƒæ¶ˆè€— tokenï¼‰
- USE_JINA_API=false æœƒä½¿ç”¨æœ¬æ©Ÿæ¨¡å‹ï¼ˆä¸æ¶ˆè€— tokenï¼‰

**åŸ·è¡Œæ–¹å¼ï¼š**
- ä½¿ç”¨è™›æ“¬ç’°å¢ƒï¼šsource ../../.venv-rag/bin/activate && python embed_plants_forest_jina.py
- æˆ–ç›´æ¥ï¼š../../.venv-rag/bin/python embed_plants_forest_jina.py

ä½¿ç”¨æ–¹å¼ï¼š
1. è¨­å®šç’°å¢ƒè®Šæ•¸ï¼š
   export QDRANT_URL="http://localhost:6333"
   export QDRANT_API_KEY="your_qdrant_api_key"  # è‹¥æœ¬æ©Ÿå¯çœç•¥
   export USE_JINA_API="false"                  # ä½¿ç”¨æœ¬æ©Ÿæ¨¡å‹
   export EMBEDDING_MODEL="jinaai/jina-embeddings-v3"

2. åŸ·è¡Œï¼š
   python embed_plants_forest_jina.py

3. ç”Ÿç”¢ç’°å¢ƒè¨­å®šï¼ˆZeaburï¼‰ï¼š
   - åœ¨ embedding-api æœå‹™ä¸­è¨­å®šï¼šUSE_JINA_API=trueï¼ˆæˆ– autoï¼‰
   - é€™æ¨£ç”Ÿç”¢ç’°å¢ƒä¹Ÿæœƒä½¿ç”¨ Jina APIï¼ˆ1024 ç¶­ï¼‰ï¼Œèˆ‡å‘é‡åŒ–è³‡æ–™åŒ¹é…

Token æ¶ˆè€—ä¼°ç®—ï¼ˆåƒ… Jina API æ¨¡å¼ï¼‰ï¼š
   - ç´„ 4,670 ç­†è³‡æ–™
   - æ¯ç­†ç´„ 200-500 tokens
   - ç¸½è¨ˆç´„ 1,000,000 - 2,000,000 tokensï¼ˆç´„ 10-20% çš„å…è²»é¡åº¦ï¼‰
"""

import json
import os
import sys
import time
import random
import requests

# å»ºè­°ä½¿ç”¨ DEBUG_EMBED=1 æˆ– python -u åŸ·è¡Œï¼Œé¿å…è¼¸å‡ºç·©è¡å°è‡´çµ‚ç«¯æ©Ÿã€Œçœ‹èµ·ä¾†å¡ä½ã€
from pathlib import Path
from typing import List, Dict, Any
from tqdm import tqdm

from qdrant_client import QdrantClient
from qdrant_client.models import (
    Distance,
    VectorParams,
    PointStruct,
    OptimizersConfigDiff,
)

# è¨­å®š
QDRANT_URL = os.environ.get("QDRANT_URL", "http://localhost:6333")
QDRANT_API_KEY = os.environ.get("QDRANT_API_KEY", None)
_use_jina_env = os.environ.get("USE_JINA_API", "true").lower()
USE_JINA_API = _use_jina_env == "true"
JINA_API_KEY = os.environ.get("JINA_API_KEY", None)
EMBEDDING_MODEL = os.environ.get("EMBEDDING_MODEL", "jinaai/jina-embeddings-v3")
_default_dim = 1024 if "jina-embeddings-v3" in EMBEDDING_MODEL else 768
EMBEDDING_DIM = int(os.environ.get("EMBEDDING_DIM", str(_default_dim)))
COLLECTION_NAME = "taiwan_plants"

BATCH_SIZE = 16  # æ¯æ‰¹è™•ç†çš„è³‡æ–™æ•¸é‡ï¼ˆé™ä½ä»¥é¿å…é€Ÿç‡é™åˆ¶ï¼šæ¯åˆ†é˜ 100K tokensï¼‰

# è³‡æ–™è·¯å¾‘
SCRIPT_DIR = Path(__file__).parent
DATA_DIR = SCRIPT_DIR.parent / "data"
# å„ªå…ˆé †åºï¼štaxonomy-v2ï¼ˆæœ€æ–°ï¼Œå·²è£œé½Š taxonomyï¼‰> enriched-embed-dedupï¼ˆèˆŠç‰ˆï¼‰> å…¶ä»–å‚™ç”¨æª”æ¡ˆ
TAXONOMY_V2_FILE = DATA_DIR / "plants-forest-gov-tw-enriched-embed-dedup.taxonomy-v2.jsonl"
EMBED_DEDUP_FILE = DATA_DIR / "plants-forest-gov-tw-enriched-embed-dedup.jsonl"
ENRICHED_FILE = DATA_DIR / "plants-forest-gov-tw-enriched.jsonl"
DEDUP_FILE = DATA_DIR / "plants-forest-gov-tw-dedup.jsonl"
CLEAN_FILE = DATA_DIR / "plants-forest-gov-tw-clean.jsonl"
FINAL_4302_FILE = DATA_DIR / "plants-forest-gov-tw-final-4302.jsonl"
PROGRESS_FILE = SCRIPT_DIR / "embed_plants_forest_jina_progress.json"

if TAXONOMY_V2_FILE.exists():
    DATA_FILE = TAXONOMY_V2_FILE
    print(f"âœ… ä½¿ç”¨ Taxonomy V2 è³‡æ–™ï¼ˆå·²è£œé½Š taxonomyï¼‰: {DATA_FILE}")
elif EMBED_DEDUP_FILE.exists():
    DATA_FILE = EMBED_DEDUP_FILE
    print(f"âœ… ä½¿ç”¨ Enriched-Embed-Dedup è³‡æ–™: {DATA_FILE}")
elif ENRICHED_FILE.exists():
    DATA_FILE = ENRICHED_FILE
    print(f"âœ… ä½¿ç”¨ P0.6 å¼·åŒ–å¾Œè³‡æ–™: {DATA_FILE}")
elif DEDUP_FILE.exists():
    DATA_FILE = DEDUP_FILE
    print(f"âœ… ä½¿ç”¨ P0.5 å»é‡å¾Œè³‡æ–™: {DATA_FILE}")
elif CLEAN_FILE.exists():
    DATA_FILE = CLEAN_FILE
    print(f"âœ… ä½¿ç”¨ P0 æ¸…ç†å¾Œè³‡æ–™: {DATA_FILE}")
elif FINAL_4302_FILE.exists():
    DATA_FILE = FINAL_4302_FILE
    print(f"âœ… ä½¿ç”¨ Final-4302 è³‡æ–™æª”æ¡ˆ: {DATA_FILE}")
else:
    DATA_FILE = TAXONOMY_V2_FILE  # æœƒåœ¨ä¸‹æ–‡æª¢æŸ¥æ™‚å¤±æ•—
    print(f"âŒ è³‡æ–™æª”æ¡ˆä¸å­˜åœ¨ï¼Œè«‹å…ˆåŸ·è¡Œ enrich_taxonomy.js ç”¢ç”Ÿ taxonomy-v2.jsonl")


def get_qdrant_client():
    """å»ºç«‹ Qdrant å®¢æˆ¶ç«¯ï¼Œè‡ªå‹•è™•ç† HTTP/HTTPS"""
    from urllib.parse import urlparse
    parsed = urlparse(QDRANT_URL)

    is_https = parsed.scheme == 'https'
    host = parsed.hostname or 'localhost'
    port = parsed.port or (443 if is_https else 6333)

    if QDRANT_API_KEY:
        return QdrantClient(
            host=host,
            port=port,
            api_key=QDRANT_API_KEY,
            https=is_https,
            prefer_grpc=False,
            timeout=120
        )
    else:
        return QdrantClient(
            host=host,
            port=port,
            https=is_https,
            prefer_grpc=False,
            timeout=120
        )


_local_model = None


def get_local_model():
    global _local_model
    if _local_model is not None:
        return _local_model
    try:
        from sentence_transformers import SentenceTransformer
        _local_model = SentenceTransformer(EMBEDDING_MODEL, trust_remote_code=True)
        return _local_model
    except Exception as e:
        raise RuntimeError(f"æœ¬æ©Ÿæ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")


def encode_text_local(texts: List[str]) -> List[List[float]]:
    model = get_local_model()
    embeddings = model.encode(texts, show_progress_bar=False, convert_to_numpy=True)
    return [emb.tolist() for emb in embeddings]


def encode_text_jina(texts: List[str], max_retries: int = 3) -> List[List[float]]:
    """
    ä½¿ç”¨ Jina API å°‡æ–‡å­—ç·¨ç¢¼ç‚ºå‘é‡ï¼ˆå¸¶é‡è©¦æ©Ÿåˆ¶ï¼‰
    
    Args:
        texts: æ–‡å­—åˆ—è¡¨
        max_retries: æœ€å¤§é‡è©¦æ¬¡æ•¸
        
    Returns:
        å‘é‡åˆ—è¡¨
    """
    if not JINA_API_KEY:
        raise ValueError("JINA_API_KEY æœªè¨­å®š")
    
    # éæ¿¾ç©ºå­—ä¸²ä¸¦æª¢æŸ¥é•·åº¦
    valid_texts = [t for t in texts if t and t.strip()]
    if not valid_texts:
        raise ValueError("æ²’æœ‰æœ‰æ•ˆçš„æ–‡å­—è¼¸å…¥")
    
    # æª¢æŸ¥æ–‡å­—é•·åº¦ï¼ˆJina API å¯èƒ½æœ‰é•·åº¦é™åˆ¶ï¼‰
    for i, text in enumerate(valid_texts):
        if len(text) > 8192:  # Jina API é€šå¸¸é™åˆ¶åœ¨ 8192 tokens
            print(f"âš ï¸  è­¦å‘Šï¼šæ–‡å­— {i} éé•· ({len(text)} å­—ç¬¦)ï¼Œå°‡æˆªæ–·")
            valid_texts[i] = text[:8000]  # æˆªæ–·åˆ°å®‰å…¨é•·åº¦
    
    # é‡è©¦æ©Ÿåˆ¶
    for attempt in range(max_retries):
        try:
            response = requests.post(
                "https://api.jina.ai/v1/embeddings",
                headers={
                    "Authorization": f"Bearer {JINA_API_KEY}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": "jina-embeddings-v3",
                    "task": "retrieval.passage",  # ä¿®æ­£ï¼šä½¿ç”¨ retrieval.passage è€Œé retrieval.document
                    "dimensions": 1024,
                    "input": valid_texts
                },
                timeout=60
            )
            
            # è™•ç†é€Ÿç‡é™åˆ¶ï¼ˆ429ï¼‰
            if response.status_code == 429:
                error_data = response.json() if response.headers.get('content-type', '').startswith('application/json') else {}
                retry_after = int(response.headers.get('Retry-After', 60))  # é è¨­ 60 ç§’
                
                if attempt < max_retries - 1:
                    wait_time = retry_after + random.uniform(5, 15)  # é¡å¤–éš¨æ©Ÿå»¶é² 5-15 ç§’
                    print(f"   â³ é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time:.1f} ç§’å¾Œé‡è©¦ï¼ˆå˜—è©¦ {attempt + 1}/{max_retries}ï¼‰...")
                    time.sleep(wait_time)
                    continue
                else:
                    print(f"   âŒ é”åˆ°æœ€å¤§é‡è©¦æ¬¡æ•¸ï¼Œæ”¾æ£„æ­¤æ‰¹æ¬¡")
                    response.raise_for_status()
            
            # è©³ç´°éŒ¯èª¤è™•ç†
            if response.status_code != 200:
                print(f"âŒ Jina API éŒ¯èª¤: {response.status_code}")
                try:
                    error_data = response.json()
                    print(f"   éŒ¯èª¤è©³æƒ…: {json.dumps(error_data, indent=2, ensure_ascii=False)}")
                    # é¡¯ç¤ºç¬¬ä¸€å€‹è¼¸å…¥æ–‡å­—ï¼ˆç”¨æ–¼é™¤éŒ¯ï¼‰
                    if valid_texts:
                        print(f"   ç¬¬ä¸€å€‹è¼¸å…¥æ–‡å­—ï¼ˆå‰ 200 å­—ç¬¦ï¼‰: {valid_texts[0][:200]}")
                except:
                    print(f"   éŒ¯èª¤å›æ‡‰: {response.text[:500]}")
                response.raise_for_status()
            
            data = response.json()
            
            # è¨˜éŒ„å¯¦éš›ä½¿ç”¨çš„ tokensï¼ˆå¦‚æœ API æœ‰å›å‚³ï¼‰
            usage = data.get("usage", {})
            if usage:
                tokens_used = usage.get("total_tokens", 0)
                print(f"   âœ… Jina API æˆåŠŸï¼Œä½¿ç”¨ tokens: {tokens_used:,}")
            
            # æå–å‘é‡
            embeddings = [item["embedding"] for item in data["data"]]
            return embeddings
            
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 429 and attempt < max_retries - 1:
                continue  # ç¹¼çºŒé‡è©¦
            raise
        except Exception as e:
            if attempt < max_retries - 1:
                wait_time = (attempt + 1) * 5  # æŒ‡æ•¸é€€é¿
                print(f"   âš ï¸  éŒ¯èª¤: {e}ï¼Œç­‰å¾… {wait_time} ç§’å¾Œé‡è©¦...")
                time.sleep(wait_time)
                continue
            raise
    
    raise Exception("é”åˆ°æœ€å¤§é‡è©¦æ¬¡æ•¸ï¼Œç„¡æ³•å®Œæˆè«‹æ±‚")


def create_plant_text(plant: Dict[str, Any]) -> str:
    """
    å¾æ¤ç‰©è³‡æ–™å»ºç«‹æœå°‹æ–‡å­—ï¼ˆå„ªåŒ–ç‰ˆï¼šå„ªå…ˆä½¿ç”¨ summary å’Œ key_featuresï¼‰
    é©é… plants-forest-gov-tw.jsonl æ ¼å¼
    
    æ”¹é€²ç­–ç•¥ï¼š
    1. å„ªå…ˆä½¿ç”¨ morphology_summaryï¼ˆå¦‚æœå­˜åœ¨ï¼‰- ä¹¾æ·¨çš„æ‘˜è¦
    2. å…¶æ¬¡ä½¿ç”¨ summary å’Œ key_features
    3. æ¸›å°‘åŸå§‹ morphology çš„æ¬Šé‡ï¼ˆé¿å…å¸¸è¦‹è©æ·¹æ²’ï¼‰
    
    âš ï¸ é‡è¦ï¼štaxonomy.genus / taxonomy.family ä¸è¦æ”¾é€² embedding text
    ï¼ˆæœƒè®“èªæ„å¬å›ååˆ°æ‹‰ä¸å/ç§‘å±¬ç¾¤ï¼Œèˆ‡ç…§ç‰‡èƒå–çš„ä¸­æ–‡å½¢æ…‹ç‰¹å¾µä¸ä¸€è‡´ï¼‰
    """
    parts = []
    
    # åŸºæœ¬è³‡è¨Šï¼ˆä¿ç•™ï¼Œä½†æ¬Šé‡è¼ƒä½ï¼‰
    if plant.get("chinese_name"):
        parts.append(f"ä¸­æ–‡åï¼š{plant['chinese_name']}")
    if plant.get("scientific_name"):
        parts.append(f"å­¸åï¼š{plant['scientific_name']}")
    
    # åˆ†é¡è³‡è¨Šï¼ˆå„ªå…ˆä½¿ç”¨ä¹¾æ·¨çš„æ‘˜è¦ï¼‰
    identification = plant.get("identification", {})
    if isinstance(identification, dict):
        # 0. æœ€å„ªå…ˆä½¿ç”¨ query_text_zhï¼ˆæ¸…ç†å¾Œçš„ç°¡çŸ­æè¿°ï¼Œç”¨æ–¼ embeddingï¼‰
        if identification.get("query_text_zh"):
            parts.append(identification["query_text_zh"])
        # 1. å…¶æ¬¡ä½¿ç”¨ morphology_summaryï¼ˆéšæ®µäºŒï¼šå¦‚æœå­˜åœ¨ï¼‰
        elif identification.get("morphology_summary_zh"):
            parts.append(identification["morphology_summary_zh"])
        # 2. å†æ¬¡ä½¿ç”¨ summaryï¼ˆè¼ƒä¹¾æ·¨ï¼‰
        elif identification.get("summary"):
            summary = identification["summary"]
            if isinstance(summary, list):
                parts.append(" ".join(summary))
            else:
                parts.append(summary)
        
        # 3. åŠ å…¥ trait_tokensï¼ˆå¦‚æœå­˜åœ¨ï¼Œéšæ®µäºŒï¼‰
        trait_tokens = identification.get("trait_tokens", [])
        if trait_tokens and isinstance(trait_tokens, list):
            # åªå–å‰ 20 å€‹ tokenï¼Œé¿å…éé•·
            trait_tokens_limited = trait_tokens[:20]
            # è½‰æ›ç‚ºå¯è®€æ–‡å­—ï¼ˆç”¨æ–¼ embeddingï¼‰
            trait_text = " ".join(trait_tokens_limited)
            parts.append(f"ç‰¹å¾µï¼š{trait_text}")
        
        # 4. åŠ å…¥ key_featuresï¼ˆé«˜è¾¨è­˜åº¦ç‰¹å¾µï¼Œå¦‚æœæ²’æœ‰ trait_tokensï¼‰
        elif identification.get("key_features"):
            key_features = identification["key_features"]
            if isinstance(key_features, list):
                # åªå–å‰ 10 å€‹é—œéµç‰¹å¾µï¼Œé¿å…éé•·
                key_features_limited = key_features[:10]
                parts.append(f"é—œéµç‰¹å¾µï¼š{', '.join(key_features_limited)}")
            else:
                parts.append(f"é—œéµç‰¹å¾µï¼š{key_features}")
        
        # 5. ç”Ÿæ´»å‹ï¼ˆé‡è¦è­˜åˆ¥ç‰¹å¾µï¼‰
        if identification.get("life_form"):
            life_form = identification["life_form"]
            if isinstance(life_form, list):
                parts.append(f"ç”Ÿæ´»å‹ï¼š{', '.join(life_form)}")
            else:
                parts.append(f"ç”Ÿæ´»å‹ï¼š{life_form}")
        
        # 6. åŸå§‹ morphologyï¼ˆå‚™ç”¨ï¼Œæ¬Šé‡è¼ƒä½ï¼‰
        # åªåœ¨æ²’æœ‰ summary å’Œ morphology_summary æ™‚æ‰ä½¿ç”¨
        if not identification.get("morphology_summary_zh") and not identification.get("summary"):
            if identification.get("morphology"):
                morphology = identification["morphology"]
                if isinstance(morphology, list):
                    # åªå–å‰ 3 æ¢ï¼Œé¿å…éé•·
                    morphology_limited = morphology[:3]
                    parts.append(f"å½¢æ…‹ï¼š{', '.join(morphology_limited)}")
                else:
                    parts.append(f"å½¢æ…‹ï¼š{morphology}")
    
    # åˆ†å¸ƒè³‡è¨Šï¼ˆç§»é™¤ï¼Œé¿å…å¹²æ“¾ï¼‰
    # distribution = plant.get("distribution", {})
    # if isinstance(distribution, dict) and distribution.get("taiwan"):
    #     parts.append(f"å°ç£åˆ†å¸ƒï¼š{distribution['taiwan']}")
    
    return "\n".join(parts)


def load_progress() -> set:
    """è¼‰å…¥å·²è™•ç†çš„é€²åº¦"""
    if PROGRESS_FILE.exists():
        with open(PROGRESS_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
            # æª¢æŸ¥æ˜¯å¦ç‚ºèˆŠæ ¼å¼ï¼ˆä½¿ç”¨ source_urlï¼‰
            processed = data.get("processed", [])
            if processed and isinstance(processed[0], str):
                # èˆŠæ ¼å¼ï¼Œè¿”å›ç©ºé›†åˆä»¥é‡æ–°è™•ç†
                print("âš ï¸  æª¢æ¸¬åˆ°èˆŠæ ¼å¼çš„é€²åº¦æª”æ¡ˆï¼Œå°‡é‡æ–°è™•ç†æ‰€æœ‰è³‡æ–™")
                return set()
            return set(processed)
    return set()


def save_progress(processed: set):
    """å„²å­˜é€²åº¦"""
    with open(PROGRESS_FILE, 'w', encoding='utf-8') as f:
        json.dump({"processed": list(processed)}, f, ensure_ascii=False, indent=2)


def load_plants() -> List[Dict[str, Any]]:
    """è¼‰å…¥æ¤ç‰©è³‡æ–™"""
    if not DATA_FILE.exists():
        raise FileNotFoundError(f"è³‡æ–™æª”æ¡ˆä¸å­˜åœ¨: {DATA_FILE}")
    
    plants = []
    with open(DATA_FILE, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                plant = json.loads(line)
                plants.append(plant)
            except json.JSONDecodeError as e:
                print(f"âš ï¸  è·³éç„¡æ•ˆçš„ JSON è¡Œ: {e}")
                continue
    return plants


FORCE_RECREATE = os.environ.get("FORCE_RECREATE", "").lower() in ("1", "true", "yes")


def init_qdrant(client: QdrantClient):
    """åˆå§‹åŒ– Qdrant collection"""
    collections = client.get_collections().collections
    collection_names = [c.name for c in collections]

    if COLLECTION_NAME in collection_names:
        # P0 æ•´åº«é‡å»ºï¼šFORCE_RECREATE=1 æ™‚åˆªé™¤èˆŠ collection
        if FORCE_RECREATE:
            print(f"âš ï¸  FORCE_RECREATE=1ï¼Œåˆªé™¤èˆŠ collection ä¸¦é‡å»º...")
            client.delete_collection(collection_name=COLLECTION_NAME)
            print(f"   âœ… èˆŠ collection å·²åˆªé™¤")
        else:
            # æª¢æŸ¥ç¾æœ‰ collection çš„ç¶­åº¦
            existing_collection = client.get_collection(COLLECTION_NAME)
            existing_dim = existing_collection.config.params.vectors.size

            if existing_dim != EMBEDDING_DIM:
                print(f"âš ï¸  Collection {COLLECTION_NAME} å·²å­˜åœ¨ï¼Œä½†ç¶­åº¦ä¸åŒ¹é…ï¼ˆç¾æœ‰: {existing_dim}, éœ€è¦: {EMBEDDING_DIM}ï¼‰")
                print(f"   åˆªé™¤èˆŠ collection ä¸¦é‡æ–°å»ºç«‹...")
                client.delete_collection(collection_name=COLLECTION_NAME)
                print(f"   âœ… èˆŠ collection å·²åˆªé™¤")
            else:
                print(f"âœ… Collection {COLLECTION_NAME} å·²å­˜åœ¨ï¼ˆç¶­åº¦: {EMBEDDING_DIM}ï¼‰")
                return

    # å»ºç«‹æ–°çš„ collection
    print(f"å»ºç«‹ collection: {COLLECTION_NAME}ï¼ˆç¶­åº¦: {EMBEDDING_DIM}ï¼‰")
    client.create_collection(
        collection_name=COLLECTION_NAME,
        vectors_config=VectorParams(
            size=EMBEDDING_DIM,
            distance=Distance.COSINE,
        ),
        optimizers_config=OptimizersConfigDiff(
            indexing_threshold=0,  # ç«‹å³å»ºç«‹ç´¢å¼•
        ),
    )
    print(f"âœ… Collection {COLLECTION_NAME} å·²å»ºç«‹")


def main():
    print("=" * 60)
    mode_text = "Jina API" if USE_JINA_API else "æœ¬æ©Ÿæ¨¡å‹"
    print(f"ğŸŒ¿ æ¤ç‰©è³‡æ–™å‘é‡åŒ–ï¼ˆä½¿ç”¨ {mode_text}ï¼‰")
    print("=" * 60)
    
    if USE_JINA_API and not JINA_API_KEY:
        print("âŒ éŒ¯èª¤ï¼šJINA_API_KEY æœªè¨­å®š")
        print("   è«‹è¨­å®šç’°å¢ƒè®Šæ•¸ï¼šexport JINA_API_KEY='your_key'")
        sys.exit(1)
    
    if not USE_JINA_API:
        # æª¢æŸ¥æœ¬åœ°æ¨¡å‹ä¾è³´
        try:
            import sentence_transformers
        except ImportError:
            print("âŒ éŒ¯èª¤ï¼šæœªå®‰è£ sentence_transformers")
            print("   é¸é … 1ï¼šå®‰è£ä¾è³´ï¼špip install sentence-transformers")
            print("   é¸é … 2ï¼šä½¿ç”¨ Jina APIï¼ˆæ¨è–¦ï¼‰ï¼šexport USE_JINA_API=true && export JINA_API_KEY='your_key'")
            sys.exit(1)
    
    print(f"\nğŸ“¦ è³‡æ–™æª”æ¡ˆ: {DATA_FILE}")
    print(f"ğŸ“Š Collection: {COLLECTION_NAME}")
    print(f"ğŸ”— Qdrant URL: {QDRANT_URL}")
    print(f"   å‘é‡ç¶­åº¦: {EMBEDDING_DIM}")
    
    # è¼‰å…¥è³‡æ–™
    print(f"\nğŸ“– è¼‰å…¥æ¤ç‰©è³‡æ–™...")
    plants = load_plants()
    print(f"âœ… è¼‰å…¥ {len(plants)} ç­†æ¤ç‰©è³‡æ–™")
    
    # æ­¥é©Ÿ 5ï¼šè³‡æ–™åº«å»é‡ï¼ˆä»¥ canonical key ç‚ºä¸»éµï¼ŒåŒä¸€ç‰©ç¨®åªä¿ç•™ä¸€ç­†ï¼‰
    print(f"\nğŸ” åŸ·è¡Œè³‡æ–™å»é‡ï¼ˆä»¥å­¸åç‚ºä¸»éµï¼‰...")
    canonical_seen = {}
    deduplicated_plants = []
    duplicates_removed = 0
    for plant in plants:
        canonical_key = get_canonical_key(plant)
        if not canonical_key:
            # æ²’æœ‰ canonical key çš„è³‡æ–™ä¿ç•™ï¼ˆå¯èƒ½æ˜¯è³‡æ–™å“è³ªå•é¡Œï¼‰
            deduplicated_plants.append(plant)
            continue
        if canonical_key not in canonical_seen:
            canonical_seen[canonical_key] = plant
            deduplicated_plants.append(plant)
        else:
            duplicates_removed += 1
            # ä¿ç•™è³‡æ–™å“è³ªè¼ƒé«˜çš„ï¼ˆæœ‰ summary/key_features çš„å„ªå…ˆï¼‰
            existing = canonical_seen[canonical_key]
            existing_quality = len(existing.get("identification", {}).get("summary", "") or "")
            new_quality = len(plant.get("identification", {}).get("summary", "") or "")
            if new_quality > existing_quality:
                # æ›¿æ›æˆå“è³ªæ›´é«˜çš„
                deduplicated_plants.remove(existing)
                deduplicated_plants.append(plant)
                canonical_seen[canonical_key] = plant
    print(f"   âœ… å»é‡å®Œæˆï¼šåŸå§‹ {len(plants)} ç­† â†’ å»é‡å¾Œ {len(deduplicated_plants)} ç­†ï¼ˆç§»é™¤ {duplicates_removed} ç­†é‡è¤‡ï¼‰")
    # å°‡å»é‡å¾Œçš„è³‡æ–™å¯«å…¥å°ˆç”¨æª”æ¡ˆï¼Œæ–¹ä¾¿å¾ŒçºŒç‰¹å¾µæ¬Šé‡ç­‰æ¨¡çµ„å…±ç”¨åŒä¸€æ‰¹è³‡æ–™ï¼ˆç´„ 2759 ç­†ï¼‰
    try:
        with open(EMBED_DEDUP_FILE, "w", encoding="utf-8") as f:
            for plant in deduplicated_plants:
                f.write(json.dumps(plant, ensure_ascii=False) + "\n")
        print(f"   ğŸ’¾ å·²å°‡å»é‡å¾Œè³‡æ–™å¯«å…¥: {EMBED_DEDUP_FILE}ï¼ˆ{len(deduplicated_plants)} ç­†ï¼‰")
    except Exception as e:
        print(f"   âš ï¸ å¯«å…¥å»é‡å¾Œè³‡æ–™æª”å¤±æ•—ï¼ˆä¸å½±éŸ¿å‘é‡åŒ–æµç¨‹ï¼‰: {e}")
    plants = deduplicated_plants
    
    # è¼‰å…¥é€²åº¦
    processed = load_progress()
    print(f"ğŸ“‹ å·²è™•ç†: {len(processed)} ç­†")
    
    # é€£æ¥ Qdrant
    print(f"\nğŸ”— é€£æ¥ Qdrant...", flush=True)
    sys.stdout.flush()
    client = get_qdrant_client()
    print(f"   âœ… Qdrant é€£ç·šæˆåŠŸ", flush=True)
    init_qdrant(client)
    
    # è™•ç†è³‡æ–™
    remaining = [p for p in plants if get_plant_id(p) not in processed]
    print(f"\nğŸš€ é–‹å§‹å‘é‡åŒ– {len(remaining)} ç­†è³‡æ–™...")
    
    if not remaining:
        print("âœ… æ‰€æœ‰è³‡æ–™å·²è™•ç†å®Œæˆï¼")
        return
    
    if USE_JINA_API:
        # ä¼°ç®—ç¸½ tokensï¼ˆç²—ç•¥ä¼°ç®—ï¼‰
        print(f"\nğŸ’° Token æ¶ˆè€—ä¼°ç®—ï¼š")
        sample_texts = [create_plant_text(p) for p in remaining[:10]]
        avg_chars = sum(len(t) for t in sample_texts) / len(sample_texts) if sample_texts else 0
        estimated_total_tokens = int(len(remaining) * avg_chars / 1.5)  # ä¸­æ–‡å­—ç¬¦ç´„ 1.5 å­—ç¬¦ = 1 token
        print(f"   é ä¼°ç¸½ tokensï¼š{estimated_total_tokens:,} tokens")
        print(f"   æ‚¨ç›®å‰å‰©é¤˜ï¼š10,000,000 tokensï¼ˆå…è²»é¡åº¦ï¼‰")
        print(f"   é ä¼°æ¶ˆè€—æ¯”ä¾‹ï¼š{estimated_total_tokens / 10_000_000 * 100:.2f}%")
        print(f"   å‰©é¤˜ tokensï¼š{10_000_000 - estimated_total_tokens:,} tokens")
    # æ”¯æ´éäº’å‹•æ¨¡å¼ï¼ˆç’°å¢ƒè®Šæ•¸ AUTO_CONFIRM=true æˆ– CI=trueï¼‰
    auto_confirm = os.environ.get("AUTO_CONFIRM", "").lower() == "true" or os.environ.get("CI", "").lower() == "true"
    
    if auto_confirm:
        print(f"\n   âœ… è‡ªå‹•ç¢ºèªæ¨¡å¼ï¼Œé–‹å§‹å‘é‡åŒ–...")
        response = "yes"
    else:
        print(f"\n   ç¹¼çºŒå‘é‡åŒ–ï¼Ÿ(yes/no): ", end="")
        try:
            response = input().strip().lower()
        except (EOFError, KeyboardInterrupt):
            print("\n   âš ï¸  éäº’å‹•æ¨¡å¼ï¼Œä½¿ç”¨è‡ªå‹•ç¢ºèª")
            response = "yes"
    
    if response != 'yes':
        print("   å·²å–æ¶ˆæ“ä½œ")
        sys.exit(0)
    
    # æ‰¹æ¬¡è™•ç†
    for i in range(0, len(remaining), BATCH_SIZE):
        batch = remaining[i:i + BATCH_SIZE]
        batch_texts = [create_plant_text(p) for p in batch]
        batch_ids = [get_plant_id(p) for p in batch]
        
        # éæ¿¾ç©ºæ–‡å­—ï¼Œä¿æŒç´¢å¼•å°æ‡‰
        valid_indices = []
        valid_texts = []
        for idx, text in enumerate(batch_texts):
            if text and text.strip():
                valid_indices.append(idx)
                valid_texts.append(text)
        
        if not valid_texts:
            print(f"âš ï¸  æ‰¹æ¬¡ {i // BATCH_SIZE + 1} æ²’æœ‰æœ‰æ•ˆæ–‡å­—ï¼Œè·³é")
            continue
        
        try:
            # ä½¿ç”¨ Jina API ç·¨ç¢¼
            batch_num = i // BATCH_SIZE + 1
            total_batches = (len(remaining) + BATCH_SIZE - 1) // BATCH_SIZE
            print(f"\nğŸ“Š è™•ç†æ‰¹æ¬¡ {batch_num}/{total_batches} ({len(valid_texts)} ç­†æœ‰æ•ˆ/{len(batch)} ç­†ç¸½è¨ˆ)...", flush=True)
            sys.stdout.flush()
            if USE_JINA_API:
                vectors = encode_text_jina(valid_texts)
            else:
                vectors = encode_text_local(valid_texts)
            
            # å»ºç«‹ Qdrant pointsï¼ˆåªè™•ç†æœ‰æ•ˆçš„ï¼‰
            points = []
            for vec_idx, text_idx in enumerate(valid_indices):
                plant = batch[text_idx]
                plant_id = batch_ids[text_idx]
                vector = vectors[vec_idx]
                
                ident = plant.get("identification", {})
                payload = {
                    "chinese_name": plant.get("chinese_name", ""),
                    "scientific_name": plant.get("scientific_name", ""),
                    "family": plant.get("family", ""),
                    "life_form": ident.get("life_form", ""),
                    "summary": ident.get("summary", ""),
                    "key_features": ident.get("key_features", []),
                    "key_features_norm": ident.get("key_features_norm", []),
                    "trait_tokens": ident.get("trait_tokens", []),
                    "source": plant.get("source", "forest-gov-tw"),
                    "source_url": plant.get("source_url", ""),
                    "plant_id": plant_id,
                    "raw_data": plant
                }
                qs = plant.get("_quality_score")
                if qs is not None:
                    payload["quality_score"] = float(qs)
                points.append(PointStruct(id=hash(plant_id) % (2**63), vector=vector, payload=payload))
            
            # ä¸Šå‚³åˆ° Qdrant
            client.upsert(
                collection_name=COLLECTION_NAME,
                points=points
            )
            
            # æ›´æ–°é€²åº¦
            processed.update(batch_ids)
            save_progress(processed)
            
            print(f"âœ… æ‰¹æ¬¡å®Œæˆï¼Œå·²è™•ç† {len(processed)}/{len(plants)} ç­†")
            
            # æ‰¹æ¬¡ä¹‹é–“æ·»åŠ å»¶é²ï¼Œé¿å…é€Ÿç‡é™åˆ¶ï¼ˆæ¯åˆ†é˜ 100K tokensï¼‰
            # ä¼°ç®—ï¼šæ¯æ‰¹æ¬¡ç´„ 10K tokensï¼Œæ‰€ä»¥æ¯æ‰¹æ¬¡é–“éš”ç´„ 6 ç§’
            if batch_num < total_batches:  # æœ€å¾Œä¸€æ‰¹ä¸éœ€è¦å»¶é²
                delay = random.uniform(6, 10)  # éš¨æ©Ÿå»¶é² 6-10 ç§’
                print(f"   â¸ï¸  ç­‰å¾… {delay:.1f} ç§’ä»¥é¿å…é€Ÿç‡é™åˆ¶...")
                time.sleep(delay)
            
        except Exception as e:
            print(f"âŒ æ‰¹æ¬¡è™•ç†å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            print(f"   å·²è™•ç† {len(processed)} ç­†ï¼Œå¯é‡æ–°åŸ·è¡Œä»¥ç¹¼çºŒ")
            break
    
    print(f"\nğŸ‰ å‘é‡åŒ–å®Œæˆï¼å…±è™•ç† {len(processed)} ç­†è³‡æ–™")


def normalize_scientific_name(sci: str) -> str:
    """æ­£è¦åŒ–å­¸åï¼šç§»é™¤è®Šç¨®æ¨™è¨˜ï¼ˆvar./subsp./f.ï¼‰ä¸¦æ¨™æº–åŒ–æ ¼å¼"""
    if not sci:
        return ""
    sci = sci.strip()
    # ç§»é™¤å¸¸è¦‹çš„è®Šç¨®æ¨™è¨˜ï¼ˆvar. / subsp. / f. / cv. / 'ï¼‰
    import re
    # ç§»é™¤ var. / subsp. / f. / cv. åŠå…¶å¾Œé¢çš„å…§å®¹ï¼ˆä¿ç•™åˆ° species ç‚ºæ­¢ï¼‰
    sci = re.sub(r'\s+(var\.|subsp\.|ssp\.|f\.|cv\.|cultivar)', '', sci, flags=re.IGNORECASE)
    # ç§»é™¤å–®å¼•è™Ÿï¼ˆæ ½åŸ¹ç¨®æ¨™è¨˜ï¼‰
    sci = sci.replace("'", "").replace('"', '')
    # ç§»é™¤å¤šé¤˜ç©ºæ ¼
    sci = " ".join(sci.split())
    return sci.lower()


def get_canonical_key(plant: Dict[str, Any]) -> str:
    """å–å¾—æ¤ç‰©çš„ canonical keyï¼ˆç”¨æ–¼å»é‡ï¼‰ï¼šå„ªå…ˆå­¸åï¼Œfallback åˆ°ä¸­æ–‡å+ç§‘+å±¬"""
    sci = (plant.get("scientific_name") or "").strip()
    if sci:
        sci_normalized = normalize_scientific_name(sci)
        if sci_normalized:
            parts = sci_normalized.split()
            if len(parts) >= 2:
                # åªå– genus + speciesï¼ˆå¿½ç•¥è®Šç¨®ã€äºç¨®ç­‰ï¼‰
                return f"{parts[0]} {parts[1]}"
            return sci_normalized
    # Fallbackï¼šä¸­æ–‡å + ç§‘ + å±¬
    cname = (plant.get("chinese_name") or "").strip()
    family = (plant.get("family") or "").strip()
    genus = (plant.get("genus") or "").strip()
    import re
    if cname:
        cname = re.sub(r'[\s\-_]+', '', cname)
    key_parts = [p for p in (cname, family, genus) if p]
    return " | ".join(key_parts) if key_parts else ""


def get_plant_id(plant: Dict[str, Any]) -> str:
    """å–å¾—æ¤ç‰©çš„å”¯ä¸€ IDï¼ˆä¿ç•™åŸå§‹é‚è¼¯ç”¨æ–¼é€²åº¦è¿½è¹¤ï¼Œä½†å»é‡æ”¹ç”¨ canonical_keyï¼‰"""
    source_url = plant.get("source_url", "")
    chinese_name = plant.get("chinese_name", "")
    scientific_name = plant.get("scientific_name", "")
    return f"{source_url}|{chinese_name}|{scientific_name}"


if __name__ == "__main__":
    main()
