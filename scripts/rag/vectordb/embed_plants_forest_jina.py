#!/usr/bin/env python3
"""
æ¤ç‰©è³‡æ–™å‘é‡åŒ–è…³æœ¬ï¼ˆä½¿ç”¨ Jina APIï¼Œ1024 ç¶­ï¼‰
é©é…æ–°çš„ plants-forest-gov-tw.jsonl æ ¼å¼

**é‡è¦ï¼šæ­¤è…³æœ¬ä½¿ç”¨ Jina APIï¼ˆ1024 ç¶­ï¼‰ï¼Œæœƒæ¶ˆè€— Jina API tokens**
**ä½† 1024 ç¶­èƒ½æä¾›æ›´å¥½çš„ç´°ç¯€è¾¨è­˜ç²¾åº¦**

ä½¿ç”¨æ–¹å¼ï¼š
1. è¨­å®šç’°å¢ƒè®Šæ•¸ï¼š
   export QDRANT_URL="https://gps-task-qdrant.zeabur.app"
   export QDRANT_API_KEY="your_qdrant_api_key"
   export JINA_API_KEY="your_jina_api_key"

2. åŸ·è¡Œï¼š
   python embed_plants_forest_jina.py

3. ç”Ÿç”¢ç’°å¢ƒè¨­å®šï¼ˆZeaburï¼‰ï¼š
   - åœ¨ embedding-api æœå‹™ä¸­è¨­å®šï¼šUSE_JINA_API=trueï¼ˆæˆ– autoï¼‰
   - é€™æ¨£ç”Ÿç”¢ç’°å¢ƒä¹Ÿæœƒä½¿ç”¨ Jina APIï¼ˆ1024 ç¶­ï¼‰ï¼Œèˆ‡å‘é‡åŒ–è³‡æ–™åŒ¹é…

Token æ¶ˆè€—ä¼°ç®—ï¼š
   - ç´„ 4,670 ç­†è³‡æ–™
   - æ¯ç­†ç´„ 200-500 tokens
   - ç¸½è¨ˆç´„ 1,000,000 - 2,000,000 tokensï¼ˆç´„ 10-20% çš„å…è²»é¡åº¦ï¼‰
"""

import json
import os
import sys
import time
import random
import requests
from pathlib import Path
from typing import List, Dict, Any
from tqdm import tqdm

from qdrant_client import QdrantClient
from qdrant_client.models import (
    Distance,
    VectorParams,
    PointStruct,
    OptimizersConfigDiff,
)

# è¨­å®š
QDRANT_URL = os.environ.get("QDRANT_URL", "http://localhost:6333")
QDRANT_API_KEY = os.environ.get("QDRANT_API_KEY", None)
JINA_API_KEY = os.environ.get("JINA_API_KEY", None)
COLLECTION_NAME = "taiwan_plants"
EMBEDDING_DIM = 1024  # Jina embeddings-v3 ç¶­åº¦

BATCH_SIZE = 16  # æ¯æ‰¹è™•ç†çš„è³‡æ–™æ•¸é‡ï¼ˆé™ä½ä»¥é¿å…é€Ÿç‡é™åˆ¶ï¼šæ¯åˆ†é˜ 100K tokensï¼‰

# è³‡æ–™è·¯å¾‘
SCRIPT_DIR = Path(__file__).parent
# å„ªå…ˆä½¿ç”¨ enhanced è³‡æ–™ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œå¦å‰‡ä½¿ç”¨åŸå§‹è³‡æ–™
ENHANCED_DATA_FILE = SCRIPT_DIR.parent / "data" / "plants-forest-gov-tw-enhanced.jsonl"
DATA_FILE = SCRIPT_DIR.parent / "data" / "plants-forest-gov-tw.jsonl"
PROGRESS_FILE = SCRIPT_DIR / "embed_plants_forest_jina_progress.json"

# é¸æ“‡è³‡æ–™æª”æ¡ˆï¼ˆå„ªå…ˆä½¿ç”¨ enhancedï¼‰
if ENHANCED_DATA_FILE.exists():
    DATA_FILE = ENHANCED_DATA_FILE
    print(f"âœ… ä½¿ç”¨å¢å¼·è³‡æ–™ï¼š{ENHANCED_DATA_FILE}")
else:
    print(f"âš ï¸  å¢å¼·è³‡æ–™ä¸å­˜åœ¨ï¼Œä½¿ç”¨åŸå§‹è³‡æ–™ï¼š{DATA_FILE}")


def get_qdrant_client():
    """å»ºç«‹ Qdrant å®¢æˆ¶ç«¯ï¼Œè‡ªå‹•è™•ç† HTTP/HTTPS"""
    from urllib.parse import urlparse
    parsed = urlparse(QDRANT_URL)

    is_https = parsed.scheme == 'https'
    host = parsed.hostname or 'localhost'
    port = parsed.port or (443 if is_https else 6333)

    if QDRANT_API_KEY:
        return QdrantClient(
            host=host,
            port=port,
            api_key=QDRANT_API_KEY,
            https=is_https,
            prefer_grpc=False,
            timeout=120
        )
    else:
        return QdrantClient(
            host=host,
            port=port,
            https=is_https,
            prefer_grpc=False,
            timeout=120
        )


def encode_text_jina(texts: List[str], max_retries: int = 3) -> List[List[float]]:
    """
    ä½¿ç”¨ Jina API å°‡æ–‡å­—ç·¨ç¢¼ç‚ºå‘é‡ï¼ˆå¸¶é‡è©¦æ©Ÿåˆ¶ï¼‰
    
    Args:
        texts: æ–‡å­—åˆ—è¡¨
        max_retries: æœ€å¤§é‡è©¦æ¬¡æ•¸
        
    Returns:
        å‘é‡åˆ—è¡¨
    """
    if not JINA_API_KEY:
        raise ValueError("JINA_API_KEY æœªè¨­å®š")
    
    # éæ¿¾ç©ºå­—ä¸²ä¸¦æª¢æŸ¥é•·åº¦
    valid_texts = [t for t in texts if t and t.strip()]
    if not valid_texts:
        raise ValueError("æ²’æœ‰æœ‰æ•ˆçš„æ–‡å­—è¼¸å…¥")
    
    # æª¢æŸ¥æ–‡å­—é•·åº¦ï¼ˆJina API å¯èƒ½æœ‰é•·åº¦é™åˆ¶ï¼‰
    for i, text in enumerate(valid_texts):
        if len(text) > 8192:  # Jina API é€šå¸¸é™åˆ¶åœ¨ 8192 tokens
            print(f"âš ï¸  è­¦å‘Šï¼šæ–‡å­— {i} éé•· ({len(text)} å­—ç¬¦)ï¼Œå°‡æˆªæ–·")
            valid_texts[i] = text[:8000]  # æˆªæ–·åˆ°å®‰å…¨é•·åº¦
    
    # é‡è©¦æ©Ÿåˆ¶
    for attempt in range(max_retries):
        try:
            response = requests.post(
                "https://api.jina.ai/v1/embeddings",
                headers={
                    "Authorization": f"Bearer {JINA_API_KEY}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": "jina-embeddings-v3",
                    "task": "retrieval.passage",  # ä¿®æ­£ï¼šä½¿ç”¨ retrieval.passage è€Œé retrieval.document
                    "dimensions": 1024,
                    "input": valid_texts
                },
                timeout=60
            )
            
            # è™•ç†é€Ÿç‡é™åˆ¶ï¼ˆ429ï¼‰
            if response.status_code == 429:
                error_data = response.json() if response.headers.get('content-type', '').startswith('application/json') else {}
                retry_after = int(response.headers.get('Retry-After', 60))  # é è¨­ 60 ç§’
                
                if attempt < max_retries - 1:
                    wait_time = retry_after + random.uniform(5, 15)  # é¡å¤–éš¨æ©Ÿå»¶é² 5-15 ç§’
                    print(f"   â³ é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time:.1f} ç§’å¾Œé‡è©¦ï¼ˆå˜—è©¦ {attempt + 1}/{max_retries}ï¼‰...")
                    time.sleep(wait_time)
                    continue
                else:
                    print(f"   âŒ é”åˆ°æœ€å¤§é‡è©¦æ¬¡æ•¸ï¼Œæ”¾æ£„æ­¤æ‰¹æ¬¡")
                    response.raise_for_status()
            
            # è©³ç´°éŒ¯èª¤è™•ç†
            if response.status_code != 200:
                print(f"âŒ Jina API éŒ¯èª¤: {response.status_code}")
                try:
                    error_data = response.json()
                    print(f"   éŒ¯èª¤è©³æƒ…: {json.dumps(error_data, indent=2, ensure_ascii=False)}")
                    # é¡¯ç¤ºç¬¬ä¸€å€‹è¼¸å…¥æ–‡å­—ï¼ˆç”¨æ–¼é™¤éŒ¯ï¼‰
                    if valid_texts:
                        print(f"   ç¬¬ä¸€å€‹è¼¸å…¥æ–‡å­—ï¼ˆå‰ 200 å­—ç¬¦ï¼‰: {valid_texts[0][:200]}")
                except:
                    print(f"   éŒ¯èª¤å›æ‡‰: {response.text[:500]}")
                response.raise_for_status()
            
            data = response.json()
            
            # è¨˜éŒ„å¯¦éš›ä½¿ç”¨çš„ tokensï¼ˆå¦‚æœ API æœ‰å›å‚³ï¼‰
            usage = data.get("usage", {})
            if usage:
                tokens_used = usage.get("total_tokens", 0)
                print(f"   âœ… Jina API æˆåŠŸï¼Œä½¿ç”¨ tokens: {tokens_used:,}")
            
            # æå–å‘é‡
            embeddings = [item["embedding"] for item in data["data"]]
            return embeddings
            
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 429 and attempt < max_retries - 1:
                continue  # ç¹¼çºŒé‡è©¦
            raise
        except Exception as e:
            if attempt < max_retries - 1:
                wait_time = (attempt + 1) * 5  # æŒ‡æ•¸é€€é¿
                print(f"   âš ï¸  éŒ¯èª¤: {e}ï¼Œç­‰å¾… {wait_time} ç§’å¾Œé‡è©¦...")
                time.sleep(wait_time)
                continue
            raise
    
    raise Exception("é”åˆ°æœ€å¤§é‡è©¦æ¬¡æ•¸ï¼Œç„¡æ³•å®Œæˆè«‹æ±‚")


def create_plant_text(plant: Dict[str, Any]) -> str:
    """
    å¾æ¤ç‰©è³‡æ–™å»ºç«‹æœå°‹æ–‡å­—ï¼ˆå„ªåŒ–ç‰ˆï¼šå„ªå…ˆä½¿ç”¨ summary å’Œ key_featuresï¼‰
    é©é… plants-forest-gov-tw.jsonl æ ¼å¼
    
    æ”¹é€²ç­–ç•¥ï¼š
    1. å„ªå…ˆä½¿ç”¨ morphology_summaryï¼ˆå¦‚æœå­˜åœ¨ï¼‰- ä¹¾æ·¨çš„æ‘˜è¦
    2. å…¶æ¬¡ä½¿ç”¨ summary å’Œ key_features
    3. æ¸›å°‘åŸå§‹ morphology çš„æ¬Šé‡ï¼ˆé¿å…å¸¸è¦‹è©æ·¹æ²’ï¼‰
    """
    parts = []
    
    # åŸºæœ¬è³‡è¨Šï¼ˆä¿ç•™ï¼Œä½†æ¬Šé‡è¼ƒä½ï¼‰
    if plant.get("chinese_name"):
        parts.append(f"ä¸­æ–‡åï¼š{plant['chinese_name']}")
    if plant.get("scientific_name"):
        parts.append(f"å­¸åï¼š{plant['scientific_name']}")
    
    # åˆ†é¡è³‡è¨Šï¼ˆå„ªå…ˆä½¿ç”¨ä¹¾æ·¨çš„æ‘˜è¦ï¼‰
    identification = plant.get("identification", {})
    if isinstance(identification, dict):
        # 1. å„ªå…ˆä½¿ç”¨ morphology_summaryï¼ˆéšæ®µäºŒï¼šå¦‚æœå­˜åœ¨ï¼‰
        if identification.get("morphology_summary_zh"):
            parts.append(identification["morphology_summary_zh"])
        # 2. å…¶æ¬¡ä½¿ç”¨ summaryï¼ˆè¼ƒä¹¾æ·¨ï¼‰
        elif identification.get("summary"):
            summary = identification["summary"]
            if isinstance(summary, list):
                parts.append(" ".join(summary))
            else:
                parts.append(summary)
        
        # 3. åŠ å…¥ trait_tokensï¼ˆå¦‚æœå­˜åœ¨ï¼Œéšæ®µäºŒï¼‰
        trait_tokens = identification.get("trait_tokens", [])
        if trait_tokens and isinstance(trait_tokens, list):
            # åªå–å‰ 20 å€‹ tokenï¼Œé¿å…éé•·
            trait_tokens_limited = trait_tokens[:20]
            # è½‰æ›ç‚ºå¯è®€æ–‡å­—ï¼ˆç”¨æ–¼ embeddingï¼‰
            trait_text = " ".join(trait_tokens_limited)
            parts.append(f"ç‰¹å¾µï¼š{trait_text}")
        
        # 4. åŠ å…¥ key_featuresï¼ˆé«˜è¾¨è­˜åº¦ç‰¹å¾µï¼Œå¦‚æœæ²’æœ‰ trait_tokensï¼‰
        elif identification.get("key_features"):
            key_features = identification["key_features"]
            if isinstance(key_features, list):
                # åªå–å‰ 10 å€‹é—œéµç‰¹å¾µï¼Œé¿å…éé•·
                key_features_limited = key_features[:10]
                parts.append(f"é—œéµç‰¹å¾µï¼š{', '.join(key_features_limited)}")
            else:
                parts.append(f"é—œéµç‰¹å¾µï¼š{key_features}")
        
        # 5. ç”Ÿæ´»å‹ï¼ˆé‡è¦è­˜åˆ¥ç‰¹å¾µï¼‰
        if identification.get("life_form"):
            life_form = identification["life_form"]
            if isinstance(life_form, list):
                parts.append(f"ç”Ÿæ´»å‹ï¼š{', '.join(life_form)}")
            else:
                parts.append(f"ç”Ÿæ´»å‹ï¼š{life_form}")
        
        # 6. åŸå§‹ morphologyï¼ˆå‚™ç”¨ï¼Œæ¬Šé‡è¼ƒä½ï¼‰
        # åªåœ¨æ²’æœ‰ summary å’Œ morphology_summary æ™‚æ‰ä½¿ç”¨
        if not identification.get("morphology_summary_zh") and not identification.get("summary"):
            if identification.get("morphology"):
                morphology = identification["morphology"]
                if isinstance(morphology, list):
                    # åªå–å‰ 3 æ¢ï¼Œé¿å…éé•·
                    morphology_limited = morphology[:3]
                    parts.append(f"å½¢æ…‹ï¼š{', '.join(morphology_limited)}")
                else:
                    parts.append(f"å½¢æ…‹ï¼š{morphology}")
    
    # åˆ†å¸ƒè³‡è¨Šï¼ˆç§»é™¤ï¼Œé¿å…å¹²æ“¾ï¼‰
    # distribution = plant.get("distribution", {})
    # if isinstance(distribution, dict) and distribution.get("taiwan"):
    #     parts.append(f"å°ç£åˆ†å¸ƒï¼š{distribution['taiwan']}")
    
    return "\n".join(parts)


def load_progress() -> set:
    """è¼‰å…¥å·²è™•ç†çš„é€²åº¦"""
    if PROGRESS_FILE.exists():
        with open(PROGRESS_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
            # æª¢æŸ¥æ˜¯å¦ç‚ºèˆŠæ ¼å¼ï¼ˆä½¿ç”¨ source_urlï¼‰
            processed = data.get("processed", [])
            if processed and isinstance(processed[0], str):
                # èˆŠæ ¼å¼ï¼Œè¿”å›ç©ºé›†åˆä»¥é‡æ–°è™•ç†
                print("âš ï¸  æª¢æ¸¬åˆ°èˆŠæ ¼å¼çš„é€²åº¦æª”æ¡ˆï¼Œå°‡é‡æ–°è™•ç†æ‰€æœ‰è³‡æ–™")
                return set()
            return set(processed)
    return set()


def save_progress(processed: set):
    """å„²å­˜é€²åº¦"""
    with open(PROGRESS_FILE, 'w', encoding='utf-8') as f:
        json.dump({"processed": list(processed)}, f, ensure_ascii=False, indent=2)


def load_plants() -> List[Dict[str, Any]]:
    """è¼‰å…¥æ¤ç‰©è³‡æ–™"""
    if not DATA_FILE.exists():
        raise FileNotFoundError(f"è³‡æ–™æª”æ¡ˆä¸å­˜åœ¨: {DATA_FILE}")
    
    plants = []
    with open(DATA_FILE, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                plant = json.loads(line)
                plants.append(plant)
            except json.JSONDecodeError as e:
                print(f"âš ï¸  è·³éç„¡æ•ˆçš„ JSON è¡Œ: {e}")
                continue
    return plants


def init_qdrant(client: QdrantClient):
    """åˆå§‹åŒ– Qdrant collection"""
    collections = client.get_collections().collections
    collection_names = [c.name for c in collections]

    if COLLECTION_NAME in collection_names:
        # æª¢æŸ¥ç¾æœ‰ collection çš„ç¶­åº¦
        existing_collection = client.get_collection(COLLECTION_NAME)
        existing_dim = existing_collection.config.params.vectors.size
        
        if existing_dim != EMBEDDING_DIM:
            print(f"âš ï¸  Collection {COLLECTION_NAME} å·²å­˜åœ¨ï¼Œä½†ç¶­åº¦ä¸åŒ¹é…ï¼ˆç¾æœ‰: {existing_dim}, éœ€è¦: {EMBEDDING_DIM}ï¼‰")
            print(f"   åˆªé™¤èˆŠ collection ä¸¦é‡æ–°å»ºç«‹...")
            client.delete_collection(collection_name=COLLECTION_NAME)
            print(f"   âœ… èˆŠ collection å·²åˆªé™¤")
        else:
            print(f"âœ… Collection {COLLECTION_NAME} å·²å­˜åœ¨ï¼ˆç¶­åº¦: {EMBEDDING_DIM}ï¼‰")
            return

    # å»ºç«‹æ–°çš„ collection
    print(f"å»ºç«‹ collection: {COLLECTION_NAME}ï¼ˆç¶­åº¦: {EMBEDDING_DIM}ï¼‰")
    client.create_collection(
        collection_name=COLLECTION_NAME,
        vectors_config=VectorParams(
            size=EMBEDDING_DIM,
            distance=Distance.COSINE,
        ),
        optimizers_config=OptimizersConfigDiff(
            indexing_threshold=0,  # ç«‹å³å»ºç«‹ç´¢å¼•
        ),
    )
    print(f"âœ… Collection {COLLECTION_NAME} å·²å»ºç«‹")


def main():
    print("=" * 60)
    print("ğŸŒ¿ æ¤ç‰©è³‡æ–™å‘é‡åŒ–ï¼ˆä½¿ç”¨ Jina APIï¼‰")
    print("=" * 60)
    
    if not JINA_API_KEY:
        print("âŒ éŒ¯èª¤ï¼šJINA_API_KEY æœªè¨­å®š")
        print("   è«‹è¨­å®šç’°å¢ƒè®Šæ•¸ï¼šexport JINA_API_KEY='your_key'")
        sys.exit(1)
    
    print(f"\nğŸ“¦ è³‡æ–™æª”æ¡ˆ: {DATA_FILE}")
    print(f"ğŸ“Š Collection: {COLLECTION_NAME}")
    print(f"ğŸ”— Qdrant URL: {QDRANT_URL}")
    print(f"   å‘é‡ç¶­åº¦: {EMBEDDING_DIM}")
    
    # è¼‰å…¥è³‡æ–™
    print(f"\nğŸ“– è¼‰å…¥æ¤ç‰©è³‡æ–™...")
    plants = load_plants()
    print(f"âœ… è¼‰å…¥ {len(plants)} ç­†æ¤ç‰©è³‡æ–™")
    
    # è¼‰å…¥é€²åº¦
    processed = load_progress()
    print(f"ğŸ“‹ å·²è™•ç†: {len(processed)} ç­†")
    
    # é€£æ¥ Qdrant
    print(f"\nğŸ”— é€£æ¥ Qdrant...")
    client = get_qdrant_client()
    init_qdrant(client)
    
    # è™•ç†è³‡æ–™
    remaining = [p for p in plants if get_plant_id(p) not in processed]
    print(f"\nğŸš€ é–‹å§‹å‘é‡åŒ– {len(remaining)} ç­†è³‡æ–™...")
    
    if not remaining:
        print("âœ… æ‰€æœ‰è³‡æ–™å·²è™•ç†å®Œæˆï¼")
        return
    
    # ä¼°ç®—ç¸½ tokensï¼ˆç²—ç•¥ä¼°ç®—ï¼‰
    print(f"\nğŸ’° Token æ¶ˆè€—ä¼°ç®—ï¼š")
    sample_texts = [create_plant_text(p) for p in remaining[:10]]
    avg_chars = sum(len(t) for t in sample_texts) / len(sample_texts) if sample_texts else 0
    estimated_total_tokens = int(len(remaining) * avg_chars / 1.5)  # ä¸­æ–‡å­—ç¬¦ç´„ 1.5 å­—ç¬¦ = 1 token
    print(f"   é ä¼°ç¸½ tokensï¼š{estimated_total_tokens:,} tokens")
    print(f"   æ‚¨ç›®å‰å‰©é¤˜ï¼š10,000,000 tokensï¼ˆå…è²»é¡åº¦ï¼‰")
    print(f"   é ä¼°æ¶ˆè€—æ¯”ä¾‹ï¼š{estimated_total_tokens / 10_000_000 * 100:.2f}%")
    print(f"   å‰©é¤˜ tokensï¼š{10_000_000 - estimated_total_tokens:,} tokens")
    # æ”¯æ´éäº’å‹•æ¨¡å¼ï¼ˆç’°å¢ƒè®Šæ•¸ AUTO_CONFIRM=true æˆ– CI=trueï¼‰
    auto_confirm = os.environ.get("AUTO_CONFIRM", "").lower() == "true" or os.environ.get("CI", "").lower() == "true"
    
    if auto_confirm:
        print(f"\n   âœ… è‡ªå‹•ç¢ºèªæ¨¡å¼ï¼Œé–‹å§‹å‘é‡åŒ–...")
        response = "yes"
    else:
        print(f"\n   ç¹¼çºŒå‘é‡åŒ–ï¼Ÿ(yes/no): ", end="")
        try:
            response = input().strip().lower()
        except (EOFError, KeyboardInterrupt):
            print("\n   âš ï¸  éäº’å‹•æ¨¡å¼ï¼Œä½¿ç”¨è‡ªå‹•ç¢ºèª")
            response = "yes"
    
    if response != 'yes':
        print("   å·²å–æ¶ˆæ“ä½œ")
        sys.exit(0)
    
    # æ‰¹æ¬¡è™•ç†
    for i in range(0, len(remaining), BATCH_SIZE):
        batch = remaining[i:i + BATCH_SIZE]
        batch_texts = [create_plant_text(p) for p in batch]
        batch_ids = [get_plant_id(p) for p in batch]
        
        # éæ¿¾ç©ºæ–‡å­—ï¼Œä¿æŒç´¢å¼•å°æ‡‰
        valid_indices = []
        valid_texts = []
        for idx, text in enumerate(batch_texts):
            if text and text.strip():
                valid_indices.append(idx)
                valid_texts.append(text)
        
        if not valid_texts:
            print(f"âš ï¸  æ‰¹æ¬¡ {i // BATCH_SIZE + 1} æ²’æœ‰æœ‰æ•ˆæ–‡å­—ï¼Œè·³é")
            continue
        
        try:
            # ä½¿ç”¨ Jina API ç·¨ç¢¼
            batch_num = i // BATCH_SIZE + 1
            total_batches = (len(remaining) + BATCH_SIZE - 1) // BATCH_SIZE
            print(f"\nğŸ“Š è™•ç†æ‰¹æ¬¡ {batch_num}/{total_batches} ({len(valid_texts)} ç­†æœ‰æ•ˆ/{len(batch)} ç­†ç¸½è¨ˆ)...")
            vectors = encode_text_jina(valid_texts)
            
            # å»ºç«‹ Qdrant pointsï¼ˆåªè™•ç†æœ‰æ•ˆçš„ï¼‰
            points = []
            for vec_idx, text_idx in enumerate(valid_indices):
                plant = batch[text_idx]
                plant_id = batch_ids[text_idx]
                vector = vectors[vec_idx]
                
                points.append(PointStruct(
                    id=hash(plant_id) % (2**63),  # Qdrant ID å¿…é ˆæ˜¯ int64
                    vector=vector,
                    payload={
                        "chinese_name": plant.get("chinese_name", ""),
                        "scientific_name": plant.get("scientific_name", ""),
                        "family": plant.get("family", ""),
                        "life_form": plant.get("identification", {}).get("life_form", ""),
                        "summary": plant.get("identification", {}).get("summary", ""),
                        "key_features": plant.get("identification", {}).get("key_features", []),
                        "source": plant.get("source", "forest-gov-tw"),
                        "source_url": plant.get("source_url", ""),
                        "plant_id": plant_id,
                        "raw_data": plant
                    }
                ))
            
            # ä¸Šå‚³åˆ° Qdrant
            client.upsert(
                collection_name=COLLECTION_NAME,
                points=points
            )
            
            # æ›´æ–°é€²åº¦
            processed.update(batch_ids)
            save_progress(processed)
            
            print(f"âœ… æ‰¹æ¬¡å®Œæˆï¼Œå·²è™•ç† {len(processed)}/{len(plants)} ç­†")
            
            # æ‰¹æ¬¡ä¹‹é–“æ·»åŠ å»¶é²ï¼Œé¿å…é€Ÿç‡é™åˆ¶ï¼ˆæ¯åˆ†é˜ 100K tokensï¼‰
            # ä¼°ç®—ï¼šæ¯æ‰¹æ¬¡ç´„ 10K tokensï¼Œæ‰€ä»¥æ¯æ‰¹æ¬¡é–“éš”ç´„ 6 ç§’
            if batch_num < total_batches:  # æœ€å¾Œä¸€æ‰¹ä¸éœ€è¦å»¶é²
                delay = random.uniform(6, 10)  # éš¨æ©Ÿå»¶é² 6-10 ç§’
                print(f"   â¸ï¸  ç­‰å¾… {delay:.1f} ç§’ä»¥é¿å…é€Ÿç‡é™åˆ¶...")
                time.sleep(delay)
            
        except Exception as e:
            print(f"âŒ æ‰¹æ¬¡è™•ç†å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            print(f"   å·²è™•ç† {len(processed)} ç­†ï¼Œå¯é‡æ–°åŸ·è¡Œä»¥ç¹¼çºŒ")
            break
    
    print(f"\nğŸ‰ å‘é‡åŒ–å®Œæˆï¼å…±è™•ç† {len(processed)} ç­†è³‡æ–™")


def get_plant_id(plant: Dict[str, Any]) -> str:
    """å–å¾—æ¤ç‰©çš„å”¯ä¸€ ID"""
    source_url = plant.get("source_url", "")
    chinese_name = plant.get("chinese_name", "")
    scientific_name = plant.get("scientific_name", "")
    return f"{source_url}|{chinese_name}|{scientific_name}"


if __name__ == "__main__":
    main()
